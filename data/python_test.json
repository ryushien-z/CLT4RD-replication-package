[
    {
        "commit_hash": "f2e62708e84f2de78e957032b5d1cb5544a6320e",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "add_reduce",
            "container_name": "LogOperations",
            "source_code": "def add_reduce(self, x):\n        \"\"\"\n        Performs an `addition' reduction on `x`.\n\n        Assumption: y <= 0.\n\n        Returns\n        -------\n        z : float\n            The summation of the elements in `x`.\n\n        \"\"\"\n        if len(x) == 0:\n            # Since logaddexp.identity is None, we must handle it separately.\n            z = self.zero\n        else:\n            # Note, we are converting to a NumPy array, if necessary.\n            base = self.base\n            if base == 2:\n                z = np.logaddexp2.reduce(x, dtype=float)\n            elif base == 'e' or close(base, np.e):\n                z = np.logaddexp.reduce(x, dtype=float)\n            else:\n                # Change the base-2, add, and then convert back.\n                x2 = x * np.log2(base)\n                z = np.logaddexp2.reduce(x2, dtype=float)\n                z /= np.log2(base)\n\n        return z"
        },
        "original_method_after_refactoring": {
            "name": "add_reduce",
            "container_name": "Operations",
            "source_code": "def add_reduce(self, x):\n        raise NotImplementedError"
        },
        "newly_extracted_method": {
            "name": "set_add_reduce",
            "container_name": "ops",
            "source_code": "def set_add_reduce(ops):\n    \"\"\"\n    Set the add_reduce method on the LogOperations instance.\n\n    \"\"\"\n    base = ops.base\n    if base == 2:\n        def add_reduce(self, x, func=np.logaddexp2):\n            if len(x) == 0:\n                # Since logaddexp.identity is None, we handle it separately.\n                z = self.zero\n            else:\n                # Note, we are converting to a NumPy array, if necessary.\n                z = func.reduce(x, dtype=float)\n            return z\n\n    elif base == 'e' or close(base, np.e):\n        def add_reduce(self, x, func=np.logaddexp):\n            if len(x) == 0:\n                # Since logaddexp.identity is None, we handle it separately.\n                z = self.zero\n            else:\n                # Note, we are converting to a NumPy array, if necessary.\n                z = func.reduce(x, dtype=float)\n            return z\n\n    else:\n        def add_reduce(self, x):\n            if len(x) == 0:\n                # Since logaddexp.identity is None, we handle it separately.\n                z = self.zero\n            else:\n                # Note, we are converting to a NumPy array, if necessary.\n                # Change the base-2, add, and then convert back.\n                x2 = x * np.log2(base)\n                z = np.logaddexp2.reduce(x2, dtype=float)\n                z /= np.log2(base)\n            return z\n\n    add_reduce.__doc__ = \"\"\"\n    Performs an `addition' reduction on `x`.\n\n    Assumption: y <= 0.\n\n    Returns\n    -------\n    z : float\n        The summation of the elements in `x`.\n\n    \"\"\"\n    ops.add_reduce = MethodType(add_reduce, ops)"
        },
        "label": "negative",
        "id": "805be418-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2965
    },
    {
        "commit_hash": "683c1b13a82e2fa94d369ce275ebf439be943a88",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_image_regressor(auto_model, tmp_path):\n    image.ImageRegressor(directory=tmp_path, max_trials=2, seed=utils.SEED)\n    assert auto_model.called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/Before/tests#autokeras#tasks#image_test.py"
        },
        "refactored_code": {
            "source_code": "def test_img_reg_fit_call_auto_model_fit(fit, tmp_path):\n    auto_model = ak.ImageRegressor(directory=tmp_path, seed=utils.SEED)\n\n    auto_model.fit(\n        x=utils.generate_data(num_instances=100, shape=(32, 32, 3)),\n        y=utils.generate_data(num_instances=100, shape=(1,)))\n\n    assert fit.is_called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/After/tests#autokeras#tasks#image_test.py"
        },
        "variable_name": "auto_model",
        "label": "positive",
        "id": "8069bab6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 830
    },
    {
        "commit_hash": "cc4a397586c6dc8c2de95773572bf3ab318a8371",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def get_rnn_cell(hparams=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['cell']['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=utils.switch_dropout(d_hp[\"input_keep_prob\"]),\n                output_keep_prob=utils.switch_dropout(d_hp[\"output_keep_prob\"]),\n                state_keep_prob=utils.switch_dropout(d_hp[\"state_keep_prob\"]),\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/Before/texar#core#layers.py"
        },
        "refactored_code": {
            "source_code": "def get_rnn_cell(hparams=None, mode=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n        mode (optional): A member of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n            `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n            controlled by :func:`texar.context.global_mode`.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            input_keep_prob = utils.switch_dropout(d_hp[\"input_keep_prob\"],\n                                                   mode)\n            output_keep_prob = utils.switch_dropout(d_hp[\"output_keep_prob\"],\n                                                    mode)\n            state_keep_prob = utils.switch_dropout(d_hp[\"state_keep_prob\"],\n                                                   mode)\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=input_keep_prob,\n                output_keep_prob=output_keep_prob,\n                state_keep_prob=state_keep_prob,\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/After/texar#core#layers.py"
        },
        "variable_name": "state_keep_prob",
        "label": "positive",
        "id": "8069ba66-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 7611
    },
    {
        "commit_hash": "f0622cc5c1d6fc5c81b588a9c365731188fb5cae",
        "refactoring_type": "Rename Method",
        "original_method": {
            "name": "power_series",
            "container_name": "Electric",
            "source_code": "def power_series(self, **kwargs):\n        \"\"\"Get power Series.\n\n        Parameters\n        ----------\n        **kwargs :\n            Any other key word arguments are passed to self.load()\n\n        Returns\n        -------\n        generator of pd.Series of power measurements.\n        \"\"\"\n        # Select power column:\n        kwargs.update({'physical_quantity': 'power', 'ac_type': 'best'})\n\n        # Pull data through preprocessing pipeline\n        generator = self.load(**kwargs)\n        for chunk in generator:\n            chunk_to_yield = chunk.icol(0).dropna()\n            chunk_to_yield.timeframe = getattr(chunk, 'timeframe', None)\n            chunk_to_yield.look_ahead = getattr(chunk, 'look_ahead', None)\n            yield chunk_to_yield",
            "file_path": "commits/f0622cc5c1d6fc5c81b588a9c365731188fb5cae/Before/nilmtk#electric.py"
        },
        "renamed_method": {
            "name": "load_series",
            "container_name": "Electric",
            "source_code": "def load_series(self, **kwargs):\n        \"\"\"\n        Parameters\n        ----------\n        ac_type : str\n        physical_quantity : str\n            We sum across ac_types of this physical quantity.\n        **kwargs : passed through to load().\n\n        Returns\n        -------\n        generator of pd.Series\n        \"\"\"\n        # Pull data through preprocessing pipeline\n        physical_quantity = kwargs['physical_quantity']\n        generator = self.load(**kwargs)\n        for chunk in generator:\n            chunk_to_yield = chunk[physical_quantity].sum(axis=1)\n            chunk_to_yield.timeframe = getattr(chunk, 'timeframe', None)\n            chunk_to_yield.look_ahead = getattr(chunk, 'look_ahead', None)\n            yield chunk_to_yield",
            "file_path": "commits/f0622cc5c1d6fc5c81b588a9c365731188fb5cae/After/nilmtk#electric.py"
        },
        "label": "negative",
        "id": "8063cffc-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1974
    },
    {
        "commit_hash": "63352897d1db6a7a009a1097ee9b16be13fc53b3",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def complex_wavefunction_data(gpu, num_hidden):\n    with open(\n        os.path.join(__tests_location__, \"data\", \"test_grad_data.pkl\"), \"rb\"\n    ) as f:\n        test_data = pickle.load(f)\n\n    qucumber.set_random_seed(SEED, cpu=True, gpu=gpu, quiet=True)\n\n    data_bases = test_data[\"2qubits\"][\"train_bases\"]\n    data_samples = torch.tensor(\n        test_data[\"2qubits\"][\"train_samples\"], dtype=torch.double\n    )\n\n    bases_data = test_data[\"2qubits\"][\"bases\"]\n    target_psi_tmp = torch.tensor(\n        test_data[\"2qubits\"][\"target_psi\"], dtype=torch.double\n    )\n\n    num_visible = data_samples.shape[-1]\n\n    unitary_dict = unitaries.create_dict()\n    nn_state = ComplexWavefunction(\n        num_visible, num_hidden, unitary_dict=unitary_dict, gpu=gpu\n    )\n    CGU = ComplexGradsUtils(nn_state)\n\n    bases = CGU.transform_bases(bases_data)\n\n    psi_dict = CGU.load_target_psi(bases, target_psi_tmp)\n    vis = nn_state.generate_hilbert_space(num_visible)\n\n    data_samples = data_samples.to(device=nn_state.device)\n\n    unitary_dict = {b: v.to(device=nn_state.device) for b, v in unitary_dict.items()}\n    psi_dict = {b: v.to(device=nn_state.device) for b, v in psi_dict.items()}\n\n    ComplexWavefunctionFixture = namedtuple(\n        \"ComplexWavefunctionFixture\",\n        [\n            \"data_samples\",\n            \"data_bases\",\n            \"grad_utils\",\n            \"bases\",\n            \"psi_dict\",\n            \"vis\",\n            \"nn_state\",\n            \"unitary_dict\",\n        ],\n    )\n\n    return ComplexWavefunctionFixture(\n        data_samples=data_samples,\n        data_bases=data_bases,\n        grad_utils=CGU,\n        bases=bases,\n        psi_dict=psi_dict,\n        vis=vis,\n        nn_state=nn_state,\n        unitary_dict=unitary_dict,\n    )",
            "file_path": "commits/63352897d1db6a7a009a1097ee9b16be13fc53b3/Before/tests#test_grads.py"
        },
        "refactored_code": {
            "source_code": "def complex_wavefunction_data(gpu, num_hidden):\n    with open(\n        os.path.join(__tests_location__, \"data\", \"test_grad_data.pkl\"), \"rb\"\n    ) as f:\n        test_data = pickle.load(f)\n\n    qucumber.set_random_seed(SEED, cpu=True, gpu=gpu, quiet=True)\n\n    data_bases = test_data[\"2qubits\"][\"train_bases\"]\n    data_samples = torch.tensor(\n        test_data[\"2qubits\"][\"train_samples\"], dtype=torch.double\n    )\n\n    bases_data = test_data[\"2qubits\"][\"bases\"]\n    target_psi_tmp = torch.tensor(\n        test_data[\"2qubits\"][\"target_psi\"], dtype=torch.double\n    )\n\n    num_visible = data_samples.shape[-1]\n\n    unitary_dict = unitaries.create_dict()\n    nn_state = ComplexWaveFunction(\n        num_visible, num_hidden, unitary_dict=unitary_dict, gpu=gpu\n    )\n    CGU = ComplexGradsUtils(nn_state)\n\n    bases = CGU.transform_bases(bases_data)\n\n    psi_dict = CGU.load_target_psi(bases, target_psi_tmp)\n    vis = nn_state.generate_hilbert_space(num_visible)\n\n    data_samples = data_samples.to(device=nn_state.device)\n\n    unitary_dict = {b: v.to(device=nn_state.device) for b, v in unitary_dict.items()}\n    psi_dict = {b: v.to(device=nn_state.device) for b, v in psi_dict.items()}\n\n    ComplexWaveFunctionFixture = namedtuple(\n        \"ComplexWaveFunctionFixture\",\n        [\n            \"data_samples\",\n            \"data_bases\",\n            \"grad_utils\",\n            \"bases\",\n            \"psi_dict\",\n            \"vis\",\n            \"nn_state\",\n            \"unitary_dict\",\n        ],\n    )\n\n    return ComplexWaveFunctionFixture(\n        data_samples=data_samples,\n        data_bases=data_bases,\n        grad_utils=CGU,\n        bases=bases,\n        psi_dict=psi_dict,\n        vis=vis,\n        nn_state=nn_state,\n        unitary_dict=unitary_dict,\n    )",
            "file_path": "commits/63352897d1db6a7a009a1097ee9b16be13fc53b3/After/tests#test_grads.py"
        },
        "original_variable_name": "ComplexWavefunctionFixture",
        "new_variable_name": "ComplexWaveFunctionFixture",
        "label": "positive",
        "id": "8067a2e4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3994
    },
    {
        "commit_hash": "92bba3102bed7256aa22c0ab273139048aa23559",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def crplot(model, y_true, y_pred, **kwargs):\n    \"\"\"\n    Plots a classification report as a heatmap. (More to follow).\n    \"\"\"\n    viz = ClassifierReport(model, **kwargs)\n    viz.score(y_true, y_pred, **kwargs)\n\n    return viz.render()",
            "file_path": "commits/92bba3102bed7256aa22c0ab273139048aa23559/Before/yellowbrick#classifier.py"
        },
        "refactored_code": {
            "source_code": "def __init__(self, model):\n        \"\"\"\n        Check to see if model is an instance of a classifer.\n        Should return a metrics mismatch error if it isn't.\n        \"\"\"\n        pass",
            "file_path": "commits/92bba3102bed7256aa22c0ab273139048aa23559/After/yellowbrick#classifier.py"
        },
        "variable_name": "viz",
        "label": "negative",
        "id": "806ae896-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 767
    },
    {
        "commit_hash": "f69e046eef93af5a28de5330bfe15ee348520b2d",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir='TB',\n                 expand_nested=False,\n                 dpi=96,\n                 subgraph=False):\n    \"\"\"Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n        subgraph: whether to return a pydot.Cluster instance.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model or\n        a `pydot.Cluster` instance representing nested model if\n        `subgraph=True`.\n    \"\"\"\n    from ..layers.wrappers import Wrapper\n    from ..models import Model\n    from ..models import Sequential\n\n    _check_pydot()\n    if subgraph:\n        dot = pydot.Cluster(style='dashed')\n        dot.set('label', model.name)\n        dot.set('labeljust', 'l')\n    else:\n        dot = pydot.Dot()\n        dot.set('rankdir', rankdir)\n        dot.set('concentrate', True)\n        dot.set('dpi', dpi)\n        dot.set_node_defaults(shape='record')\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n    layers = model._layers\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Model):\n                submodel = model_to_dot(layer.layer, show_shapes,\n                                        show_layer_names, rankdir, expand_nested,\n                                        subgraph=True)\n                model_nodes = submodel.get_nodes()\n                dot.add_edge(pydot.Edge(layer_id, model_nodes[0].get_name()))\n                if len(layers) > i + 1:\n                    next_layer_id = str(id(layers[i + 1]))\n                    dot.add_edge(pydot.Edge(\n                        model_nodes[len(model_nodes) - 1].get_name(),\n                        next_layer_id))\n                dot.add_subgraph(submodel)\n            else:\n                layer_name = '{}({})'.format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = '{}({})'.format(class_name, child_class_name)\n\n        # Create node's label.\n        if show_layer_names:\n            label = '{}: {}'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = 'multiple'\n            if hasattr(layer, 'input_shape'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, 'input_shapes'):\n                inputlabels = ', '.join(\n                    [str(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = 'multiple'\n            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n        node = pydot.Node(layer_id, label=label)\n        dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + '_ib-' + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in node.inbound_layers:\n                    if not expand_nested or not (\n                            isinstance(inbound_layer, Wrapper) and\n                            isinstance(inbound_layer.layer, Model)):\n                        inbound_layer_id = str(id(inbound_layer))\n                        # Make sure that both nodes exist before connecting them with\n                        # an edge, as add_edge would otherwise\n                        # create any missing node.\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n    return dot",
            "file_path": "commits/f69e046eef93af5a28de5330bfe15ee348520b2d/Before/keras#utils#vis_utils.py"
        },
        "refactored_code": {
            "source_code": "def model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir='TB',\n                 expand_nested=False,\n                 dpi=96,\n                 subgraph=False):\n    \"\"\"Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n        subgraph: whether to return a pydot.Cluster instance.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model or\n        a `pydot.Cluster` instance representing nested model if\n        `subgraph=True`.\n    \"\"\"\n    from ..layers.wrappers import Wrapper\n    from ..models import Model\n    from ..models import Sequential\n\n    _check_pydot()\n    if subgraph:\n        dot = pydot.Cluster(style='dashed', graph_name=model.name)\n        dot.set('label', model.name)\n        dot.set('labeljust', 'l')\n    else:\n        dot = pydot.Dot()\n        dot.set('rankdir', rankdir)\n        dot.set('concentrate', True)\n        dot.set('dpi', dpi)\n        dot.set_node_defaults(shape='record')\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n    layers = model._layers\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Model):\n                submodel_wrapper = model_to_dot(layer.layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n                # sub_w : submodel_wrapper\n                sub_w_nodes = submodel_wrapper.get_nodes()\n                sub_w_first_node = sub_w_nodes[0]\n                sub_w_last_node = sub_w_nodes[len(sub_w_nodes) - 1]\n                dot.add_subgraph(submodel_wrapper)\n            else:\n                layer_name = '{}({})'.format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = '{}({})'.format(class_name, child_class_name)\n\n        if expand_nested and isinstance(layer, Model):\n            submodel_not_wrapper = model_to_dot(layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n            # sub_n : submodel_not_wrapper\n            sub_n_nodes = submodel_not_wrapper.get_nodes()\n            sub_n_first_node = sub_n_nodes[0]\n            sub_n_last_node = sub_n_nodes[len(sub_n_nodes) - 1]\n            dot.add_subgraph(submodel_not_wrapper)\n\n        # Create node's label.\n        if show_layer_names:\n            label = '{}: {}'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = 'multiple'\n            if hasattr(layer, 'input_shape'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, 'input_shapes'):\n                inputlabels = ', '.join(\n                    [str(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = 'multiple'\n            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n\n        if not expand_nested or not isinstance(layer, Model):\n            node = pydot.Node(layer_id, label=label)\n            dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + '_ib-' + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in node.inbound_layers:\n                    inbound_layer_id = str(id(inbound_layer))\n                    if not expand_nested:\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n                    else:\n                        # if inbound_layer is not Model or wrapped Model\n                        if not is_model(inbound_layer) and (\n                                not is_wrapped_model(inbound_layer)):\n                            # if current layer is not Model or wrapped Model\n                            if not is_model(layer) and (\n                                    not is_wrapped_model(layer)):\n                                assert dot.get_node(inbound_layer_id)\n                                assert dot.get_node(layer_id)\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                            # if current layer is Model\n                            elif is_model(layer):\n                                add_edge(dot, inbound_layer_id,\n                                         sub_n_first_node.get_name())\n                            # if current layer is wrapped Model\n                            elif is_wrapped_model(layer):\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                                dot.add_edge(pydot.Edge(layer_id,\n                                                        sub_w_first_node.get_name()))\n                        # if inbound_layer is Model\n                        elif is_model(inbound_layer):\n                            add_edge(dot, sub_n_last_node.get_name(), layer_id)\n                        # if inbound_layer is wrapped Model\n                        elif is_wrapped_model(inbound_layer):\n                            add_edge(dot, sub_w_last_node.get_name(), layer_id)\n    return dot",
            "file_path": "commits/f69e046eef93af5a28de5330bfe15ee348520b2d/After/keras#utils#vis_utils.py"
        },
        "original_variable_name": "submodel",
        "new_variable_name": "submodel_wrapper",
        "label": "positive",
        "id": "806790d8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 12166
    },
    {
        "commit_hash": "a124edcd95c1dcc16070e16244fdfcba6be169e3",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def _goal_distance(goal_a, goal_b):\n        assert goal_a.shape == goal_b.shape\n        return np.linalg.norm(goal_a - goal_b, axis=-1)",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#pick_and_place_env.py"
        },
        "refactored_code": {
            "source_code": "def compute_reward(self, achieved_goal, desired_goal, info: dict):\n        d = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n        if self._reward_type == 'sparse':\n            return (d < self._distance_threshold).astype(np.float32)\n\n        return -d",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/After/garage#envs#mujoco#sawyer#pick_and_place_env.py"
        },
        "variable_name": "d",
        "label": "positive",
        "id": "8069bc6e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 782
    },
    {
        "commit_hash": "187ff9cbb00a07c789897a717c65c8bbf3b21164",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "upgrade",
            "container_name": "RDBStorage",
            "source_code": "def upgrade(self):\n        # type: () -> None\n        \"\"\"Upgrade the storage schema.\"\"\"\n\n        config = self._create_alembic_config()\n        alembic.command.upgrade(config, 'head')"
        },
        "original_method_after_refactoring": {
            "name": "upgrade",
            "container_name": "RDBStorage",
            "source_code": "def upgrade(self):\n        # type: () -> None\n        \"\"\"Upgrade the storage schema.\"\"\"\n\n        self._version_manager._upgrade()"
        },
        "newly_extracted_method": {
            "name": "_upgrade",
            "container_name": "_VersionManager",
            "source_code": "def _upgrade(self):\n        # type: () -> None\n\n        config = self._create_alembic_config()\n        alembic.command.upgrade(config, 'head')"
        },
        "label": "positive",
        "id": "805bfe1c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 783
    },
    {
        "commit_hash": "8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "get_app",
            "container_name": "regression",
            "source_code": "def get_app():\n    (default_bad_date, default_good_date) = get_default_dates()\n    options = parse_args()\n    logger = commandline.setup_logging(\"mozregression\", options, {\"mach\": sys.stdout})\n\n    fetch_config = create_config(options.app, mozinfo.os, options.bits)\n\n    if fetch_config.is_inbound():\n        # this can be useful for both inbound and nightly, because we\n        # can go to inbound from nightly.\n        fetch_config.set_inbound_branch(options.inbound_branch)\n\n    cacheSession = limitedfilecache.get_cache(\n        options.http_cache_dir, one_gigabyte,\n        logger=get_default_logger('Limited File Cache'))\n\n    set_http_cache_session(cacheSession)\n\n    if options.inbound:\n        if not fetch_config.is_inbound():\n            sys.exit('Unable to bissect inbound for `%s`' % fetch_config.app_name)\n        if not options.last_good_revision or not options.first_bad_revision:\n            sys.exit(\"If bisecting inbound, both --good-rev and --bad-rev\"\n                     \" must be set\")\n        bisector = Bisector(fetch_config, options,\n                            last_good_revision=options.last_good_revision,\n                            first_bad_revision=options.first_bad_revision)\n        return bisector.bisect_inbound\n    else:\n        # TODO: currently every fetch_config is nightly aware. Shoud we test\n        # for this to be sure here ?\n        fetch_config.set_nightly_repo(options.repo)\n        if not options.bad_release and not options.bad_date:\n            options.bad_date = default_bad_date\n            logger.info(\"No 'bad' date specified, using %s\" % options.bad_date)\n        elif options.bad_release and options.bad_date:\n            sys.exit(\"Options '--bad_release' and '--bad_date' are\"\n                     \" incompatible.\")\n        elif options.bad_release:\n            options.bad_date = date_of_release(options.bad_release)\n            if options.bad_date is None:\n                sys.exit(\"Unable to find a matching date for release \"\n                         + str(options.bad_release))\n            logger.info(\"Using 'bad' date %s for release %s\"\n                        % (options.bad_date, options.bad_release))\n        if not options.good_release and not options.good_date:\n            options.good_date = default_good_date\n            logger.info(\"No 'good' date specified, using %s\"\n                        % options.good_date)\n        elif options.good_release and options.good_date:\n            sys.exit(\"Options '--good_release' and '--good_date'\"\n                     \" are incompatible.\")\n        elif options.good_release:\n            options.good_date = date_of_release(options.good_release)\n            if options.good_date is None:\n                sys.exit(\"Unable to find a matching date for release \"\n                         + str(options.good_release))\n            logger.info(\"Using 'good' date %s for release %s\"\n                        % (options.good_date, options.good_release))\n\n        bisector = Bisector(fetch_config, options)\n        return bisector.bisect_nightlies",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/Before/mozregression#regression.py"
        },
        "inlined_method": {
            "name": "get_default_dates",
            "container_name": "regression",
            "source_code": "def get_default_dates():\n    return (str(datetime.date.today()), \"2009-01-01\")",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/Before/mozregression#regression.py"
        },
        "caller": {
            "name": "get_app",
            "container_name": "regression",
            "source_code": "def get_app():\n    default_bad_date = str(datetime.date.today())\n    default_good_date = \"2009-01-01\"\n    options = parse_args()\n    logger = commandline.setup_logging(\"mozregression\", options, {\"mach\": sys.stdout})\n\n    fetch_config = create_config(options.app, mozinfo.os, options.bits)\n\n    if fetch_config.is_inbound():\n        # this can be useful for both inbound and nightly, because we\n        # can go to inbound from nightly.\n        fetch_config.set_inbound_branch(options.inbound_branch)\n\n    cacheSession = limitedfilecache.get_cache(\n        options.http_cache_dir, one_gigabyte,\n        logger=get_default_logger('Limited File Cache'))\n\n    set_http_cache_session(cacheSession)\n\n    if options.inbound:\n        if not fetch_config.is_inbound():\n            sys.exit('Unable to bissect inbound for `%s`' % fetch_config.app_name)\n        if not options.last_good_revision or not options.first_bad_revision:\n            sys.exit(\"If bisecting inbound, both --good-rev and --bad-rev\"\n                     \" must be set\")\n        bisector = Bisector(fetch_config, options,\n                            last_good_revision=options.last_good_revision,\n                            first_bad_revision=options.first_bad_revision)\n        return bisector.bisect_inbound\n    else:\n        # TODO: currently every fetch_config is nightly aware. Shoud we test\n        # for this to be sure here ?\n        fetch_config.set_nightly_repo(options.repo)\n        if not options.bad_release and not options.bad_date:\n            options.bad_date = default_bad_date\n            logger.info(\"No 'bad' date specified, using %s\" % options.bad_date)\n        elif options.bad_release and options.bad_date:\n            sys.exit(\"Options '--bad_release' and '--bad_date' are\"\n                     \" incompatible.\")\n        elif options.bad_release:\n            options.bad_date = date_of_release(options.bad_release)\n            if options.bad_date is None:\n                sys.exit(\"Unable to find a matching date for release \"\n                         + str(options.bad_release))\n            logger.info(\"Using 'bad' date %s for release %s\"\n                        % (options.bad_date, options.bad_release))\n        if not options.good_release and not options.good_date:\n            options.good_date = default_good_date\n            logger.info(\"No 'good' date specified, using %s\"\n                        % options.good_date)\n        elif options.good_release and options.good_date:\n            sys.exit(\"Options '--good_release' and '--good_date'\"\n                     \" are incompatible.\")\n        elif options.good_release:\n            options.good_date = date_of_release(options.good_release)\n            if options.good_date is None:\n                sys.exit(\"Unable to find a matching date for release \"\n                         + str(options.good_release))\n            logger.info(\"Using 'good' date %s for release %s\"\n                        % (options.good_date, options.good_release))\n\n        bisector = Bisector(fetch_config, options)\n        return bisector.bisect_nightlies",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/After/mozregression#regression.py"
        },
        "label": "positive",
        "id": "805edad8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 6982
    },
    {
        "commit_hash": "3eaa24ad14989863c9e4d566463d5e0974cde5d1",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "validate",
            "container_name": "Column",
            "source_code": "def validate(self, value):\n        \"\"\"If we are given a column list, make sure that the column provided is valid.\"\"\"\n        super(Column, self).validate(value)\n\n        if self.columns:\n            if type(value) in bokeh_integer_types:\n                if len(self.columns) > value:\n                    return\n                else:\n                    raise ValueError(\"Not a valid column selection.\")\n            else:\n                if value not in self.columns:\n                    raise ValueError(\"Column provided is not in the list of valid columns: %s\" % self.columns)"
        },
        "original_method_after_refactoring": {
            "name": "validate",
            "container_name": "Logical",
            "source_code": "def validate(self, value):\n        try:\n            super(Logical, self).validate(value)\n        except ValueError:\n            if isinstance(value, list):\n                value = np.array(value)\n\n            # If not a Bool, then look for psuedo-logical types\n            if isinstance(value, np.ndarray):\n                values = np.unique(value)\n                if len(values) == 2:\n                    return\n\n                raise ValueError('expected a Bool or array with 2 unique values, got %s' % value)"
        },
        "newly_extracted_method": {
            "name": "transform",
            "container_name": "Column",
            "source_code": "def transform(self, value):\n        if isinstance(value, pd.Series):\n            arr = value.values\n        else:\n            arr = value\n\n        trans_array = super(Column, self).transform(arr)\n        try:\n            return pd.Series(trans_array)\n        except ValueError:\n\n            raise ValueError(\"Could not transform %r\" % value)"
        },
        "label": "negative",
        "id": "805bffc0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1766
    },
    {
        "commit_hash": "b0b466618f669f87ecfe66b9dd655415ba88ed83",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def render(self, context):\n        from ..utils import autodiscover\n        autodiscover()\n        source_image = self.source_image.resolve(context)\n        spec_id = self.spec_id.resolve(context)\n        spec = specs.registry.get_spec(spec_id)\n        if callable(spec):\n            spec = spec()\n        file = ImageSpecCacheFile(spec, source_image)\n        if self.variable_name is not None:\n            variable_name = str(self.variable_name)\n            context[variable_name] = file\n            return ''\n\n        return mark_safe(u'<img src=\"%s\" />' % file.url)",
            "file_path": "commits/b0b466618f669f87ecfe66b9dd655415ba88ed83/Before/imagekit#templatetags#imagekit_tags.py"
        },
        "refactored_code": {
            "source_code": "def get_source_file(self, context):\n        return self._source_file.resolve(context)",
            "file_path": "commits/b0b466618f669f87ecfe66b9dd655415ba88ed83/After/imagekit#templatetags#imagekit_tags.py"
        },
        "variable_name": "spec_id",
        "label": "negative",
        "id": "806ae9fe-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1037
    },
    {
        "commit_hash": "2c16357cf3b2a5b1265caf7d89703ef253e39df3",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "get_gap_starts_and_gap_ends",
            "container_name": "single",
            "source_code": "def get_gap_starts_and_gap_ends(data, max_sample_period, \n                                window_start=None, window_end=None):\n    \"\"\"\n    Parameters\n    ---------\n    data : pandas.DataFrame or Series or DatetimeIndex\n\n    max_sample_period : int or float\n        Maximum allowed sample period in seconds.  \n\n    window_start, window_end : pd.Timestamp\n        The start and end of the window of interest.  If this window\n        is larger than the duration of `data` then gaps will be\n        appended to the front / back as necessary.  If this window\n        is shorter than the duration of `data` data will be cropped.\n\n    Returns\n    -------\n    gap_starts, gap_ends: DatetimeIndex\n    \"\"\"\n    try:\n        data = data.dropna()\n    except AttributeError:\n        # if data is DatetimeIndex then it has no `dropna()` method\n        pass\n    \n    index = _get_index(data)\n\n    # Handle window...\n    if window_start is not None:\n        if window_start >= index[0]:\n            index = index[index >= window_start]\n        else:\n            index = index.insert(0, window_start)\n\n    if window_end is not None:\n        if window_end <= index[-1]:\n            index = index[index <= window_end]\n        else:\n            index = index.insert(len(index), window_end)\n\n    timedeltas_sec = np.diff(index.values) / np.timedelta64(1, 's')\n    overlong_timedeltas = timedeltas_sec > max_sample_period\n    gap_starts = index[:-1][overlong_timedeltas]\n    gap_ends = index[1:][overlong_timedeltas]        \n\n    return gap_starts, gap_ends"
        },
        "original_method_after_refactoring": {
            "name": "get_gap_starts_and_gap_ends",
            "container_name": "single",
            "source_code": "def get_gap_starts_and_gap_ends(data, max_sample_period, \n                                window_start=None, window_end=None):\n    \"\"\"\n    Parameters\n    ---------\n    data : pandas.DataFrame or Series or DatetimeIndex\n\n    max_sample_period : int or float\n        Maximum allowed sample period in seconds.  \n\n    window_start, window_end : pd.Timestamp\n        The start and end of the window of interest.  If this window\n        is larger than the duration of `data` then gaps will be\n        appended to the front / back as necessary.  If this window\n        is shorter than the duration of `data` data will be cropped.\n\n    Returns\n    -------\n    gap_starts, gap_ends: DatetimeIndex\n    \"\"\"\n    try:\n        data = data.dropna()\n    except AttributeError:\n        # if data is DatetimeIndex then it has no `dropna()` method\n        pass\n    \n    index = _get_index(data)\n    index = reframe_index(index, window_start, window_end)\n    timedeltas_sec = np.diff(index.values) / np.timedelta64(1, 's')\n    overlong_timedeltas = timedeltas_sec > max_sample_period\n    gap_starts = index[:-1][overlong_timedeltas]\n    gap_ends = index[1:][overlong_timedeltas]        \n\n    return gap_starts, gap_ends"
        },
        "newly_extracted_method": {
            "name": "reframe_index",
            "container_name": "Unknown",
            "source_code": "def reframe_index(index, window_start=None, window_end=None):\n    \"\"\"\n    Parameters\n    ----------\n    index : pd.DatetimeIndex\n\n    window_start, window_end : pd.Timestamp\n        The start and end of the window of interest.  If this window\n        is larger than the duration of `data` then gaps will be\n        appended to the front / back as necessary.  If this window\n        is shorter than the duration of `data` data will be cropped.\n\n    Returns\n    -------\n    index : pd.DatetimeIndex\n    \"\"\"\n    # Handle window...\n    if window_start is not None:\n        if window_start >= index[0]:\n            index = index[index >= window_start]\n        else:\n            index = index.insert(0, window_start)\n\n    if window_end is not None:\n        if window_end <= index[-1]:\n            index = index[index <= window_end]\n        else:\n            index = index.insert(len(index), window_end)\n\n    return index"
        },
        "label": "positive",
        "id": "805be58a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4102
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    tmp = tf.tile(tf.range(label_shape[0]), max_num_labels_tns)\n    batch_array = tf.transpose(tf.reshape(tmp, reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n\n    indices = concatenate([batch_ind, label_ind], axis=0)\n    indices = tf.transpose(tf.reshape(indices, [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    indices = tf.to_int64(indices)\n    label_shape = tf.to_int64(label_shape)\n    return tf.SparseTensor(indices, vals_sparse, label_shape)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "indices",
        "label": "positive",
        "id": "8069bbd8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3393
    },
    {
        "commit_hash": "f1afb5df71893ff2770c7cc7ca83d2ac68f977d7",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_positive_wavefunction_psi():\n    nn_state = PositiveWaveFunction(10, gpu=False)\n\n    vis_state = torch.ones(10).to(dtype=torch.double)\n    actual_psi = nn_state.psi(vis_state)[1].to(vis_state)\n    expected_psi = torch.zeros(1).to(vis_state)\n\n    msg = \"PositiveWaveFunction is giving a non-zero imaginary part!\"\n    assert torch.equal(actual_psi, expected_psi), msg",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/Before/tests#test_models_misc.py"
        },
        "refactored_code": {
            "source_code": "def test_positive_wavefunction_psi():\n    nn_state = PositiveWaveFunction(10, gpu=False)\n\n    vis_state = torch.ones(10).to(dtype=torch.double)\n    actual_psi_im = cplx.imag(nn_state.psi(vis_state)).to(vis_state)\n    expected_psi_im = torch.zeros(1).squeeze().to(vis_state)\n\n    msg = \"PositiveWaveFunction is giving a non-zero imaginary part!\"\n    assert torch.equal(actual_psi_im, expected_psi_im), msg",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/After/tests#test_models_misc.py"
        },
        "original_variable_name": "expected_psi",
        "new_variable_name": "expected_psi_im",
        "label": "positive",
        "id": "80679614-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1153
    },
    {
        "commit_hash": "81d24be624d6a0fb05fac14ffac02280ed0b70ad",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_bindcallargs2():\n    out = ((0, 1, 2), {})\n    assert_equal(bindcallargs(F2, d=0, e=1, f=2), out)\n    out = ((0, 1, 5), {})\n    assert_equal(bindcallargs(F2, d=0, e=1), out)\n    assert_raises(TypeError, bindcallargs, F2, d=0, f=2)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/Before/dit#utils#tests#test_bindargs3.py"
        },
        "refactored_code": {
            "source_code": "def test_bindcallargs2():\n    out = bindcallargs(F2, d=0, e=1, f=2)\n    out_ = ((), {'d':0, 'e':1, 'f':2})\n    assert_equal(out, out_)\n    out = bindcallargs(F2, d=0, e=1)\n    out_ = ((), {'d':0, 'e':1, 'f':5})\n    assert_equal(out, out_)\n    assert_raises(TypeError, bindcallargs, F2, d=0, f=2)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/After/dit#utils#tests#test_bindargs3.py"
        },
        "variable_name": "out",
        "label": "positive",
        "id": "8069ba16-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 898
    },
    {
        "commit_hash": "dd7f9fa8b43d42edf20483b30ff7d4591270eaf6",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "resize",
            "container_name": "resize",
            "source_code": "def resize(img, size, interpolation=PIL.Image.BILINEAR):\n    \"\"\"Resize image to match the given shape.\n\n    The backend used by :func:`resize` is configured by\n    :obj:`chainer.global_config.cv_resize_backend`.\n    Two backends are supported: \"cv2\" and \"PIL\".\n\n    Args:\n        img (~numpy.ndarray): An array to be transformed.\n            This is in CHW format and the type should be :obj:`numpy.float32`.\n        size (tuple): This is a tuple of length 2. Its elements are\n            ordered as (height, width).\n        interpolation (int): Determines sampling strategy. This is one of\n            :obj:`PIL.Image.NEAREST`, :obj:`PIL.Image.BILINEAR`,\n            :obj:`PIL.Image.BICUBIC`, :obj:`PIL.Image.LANCZOS`.\n            Bilinear interpolation is the default strategy.\n\n    Returns:\n        ~numpy.ndarray: A resize array in CHW format.\n\n    \"\"\"\n    if len(img) == 0:\n        assert len(size) == 2\n        return np.empty((0,) + size, dtype=img.dtype)\n\n    backend = resize_backend()\n    if backend == 'cv2':\n        return _resize_cv2(img, size, interpolation)\n    elif backend == 'PIL':\n        return _resize_pil(img, size, interpolation)",
            "file_path": "commits/dd7f9fa8b43d42edf20483b30ff7d4591270eaf6/Before/chainercv#transforms#image#resize.py"
        },
        "inlined_method": {
            "name": "resize_backend",
            "container_name": "resize",
            "source_code": "def resize_backend():\n    if chainer.config.cv_resize_backend == 'cv2':\n        if _cv2_available:\n            return 'cv2'\n        else:\n            warnings.warn(\n                'Although `chainer.config.cv_resize_backend == \"cv2\"`, '\n                'cv2 is not found. As a fallback option, resize uses '\n                'PIL. Either install cv2 or set '\n                '`chainer.global_config.cv_resize_backend = \"PIL\"` to '\n                'suppress this warning.')\n            return 'PIL'\n    elif chainer.config.cv_resize_backend == 'PIL':\n        return 'PIL'\n    else:\n        raise ValueError('chainer.config.cv_resize_backend should be '\n                         'either \"cv2\" or \"PIL\".')",
            "file_path": "commits/dd7f9fa8b43d42edf20483b30ff7d4591270eaf6/Before/chainercv#transforms#image#resize.py"
        },
        "caller": {
            "name": "resize",
            "container_name": "resize",
            "source_code": "def resize(img, size, interpolation=PIL.Image.BILINEAR):\n    \"\"\"Resize image to match the given shape.\n\n    The backend used by :func:`resize` is configured by\n    :obj:`chainer.global_config.cv_resize_backend`.\n    Two backends are supported: \"cv2\" and \"PIL\".\n    If this is :obj:`None`, \"cv2\" is used whenever \"cv2\" is installed,\n    and \"PIL\" is used when \"cv2\" is not installed.\n\n    Args:\n        img (~numpy.ndarray): An array to be transformed.\n            This is in CHW format and the type should be :obj:`numpy.float32`.\n        size (tuple): This is a tuple of length 2. Its elements are\n            ordered as (height, width).\n        interpolation (int): Determines sampling strategy. This is one of\n            :obj:`PIL.Image.NEAREST`, :obj:`PIL.Image.BILINEAR`,\n            :obj:`PIL.Image.BICUBIC`, :obj:`PIL.Image.LANCZOS`.\n            Bilinear interpolation is the default strategy.\n\n    Returns:\n        ~numpy.ndarray: A resize array in CHW format.\n\n    \"\"\"\n    if len(img) == 0:\n        assert len(size) == 2\n        return np.empty((0,) + size, dtype=img.dtype)\n\n    if chainer.config.cv_resize_backend is None:\n        if _cv2_available:\n            return _resize_cv2(img, size, interpolation)\n        else:\n            return _resize_pil(img, size, interpolation)\n    elif chainer.config.cv_resize_backend == 'cv2':\n        if not _cv2_available:\n            raise ValueError('cv2 is not installed even though '\n                             'chainer.config.cv_resize_backend == \\'cv2\\'')\n        return _resize_cv2(img, size, interpolation)\n    elif chainer.config.cv_resize_backend == 'PIL':\n        return _resize_pil(img, size, interpolation)",
            "file_path": "commits/dd7f9fa8b43d42edf20483b30ff7d4591270eaf6/After/chainercv#transforms#image#resize.py"
        },
        "label": "positive",
        "id": "805ee05a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4274
    },
    {
        "commit_hash": "66069b9df68a1bd2379b9002d6edecec5d3cb772",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n            datasets.MNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n            batch_size=BATCHSIZE,\n            shuffle=True,\n        )",
            "file_path": "commits/66069b9df68a1bd2379b9002d6edecec5d3cb772/Before/examples#pytorch_lightning_simple.py"
        },
        "refactored_code": {
            "source_code": "def setup(self, stage: Optional[str] = None) -> None:\n        self.mnist_test = datasets.MNIST(\n            self.data_dir, train=False, download=True, transform=transforms.ToTensor()\n        )\n        mnist_full = datasets.MNIST(\n            self.data_dir, train=True, download=True, transform=transforms.ToTensor()\n        )\n        self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])",
            "file_path": "commits/66069b9df68a1bd2379b9002d6edecec5d3cb772/After/examples#pytorch_lightning_simple.py"
        },
        "variable_name": "mnist_full",
        "label": "positive",
        "id": "8069b976-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1019
    },
    {
        "commit_hash": "1c0d10f67e1c1f903c8dd23fa79b519c6a79b85e",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "__call__",
            "container_name": "_TuneCheckpointCallback",
            "source_code": "def __call__(self, env):\n        with tune.checkpoint_dir(step=env.iteration) as checkpoint_dir:\n            env.model.save_model(os.path.join(checkpoint_dir, self._filename))"
        },
        "original_method_after_refactoring": {
            "name": "__call__",
            "container_name": "_TuneCheckpointCallback",
            "source_code": "def __call__(self, env):\n        self._create_checkpoint(env, self._filename, self._frequency)"
        },
        "newly_extracted_method": {
            "name": "_create_checkpoint",
            "container_name": "_TuneCheckpointCallback",
            "source_code": "def _create_checkpoint(env, filename: str, frequency: int):\n        if env.iteration % frequency > 0:\n            return\n        with tune.checkpoint_dir(step=env.iteration) as checkpoint_dir:\n            env.model.save_model(os.path.join(checkpoint_dir, filename))"
        },
        "label": "positive",
        "id": "805c0092-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 901
    },
    {
        "commit_hash": "24d3656c6c4b3c6806954487720d53af775a1150",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "get_phrases",
            "container_name": "main",
            "source_code": "def get_phrases(top_n=100000):\n    global all_phrases\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        # Connect to server and send data\n        sock.connect((\"localhost\", 1111))\n        print('sending a get_vocab request')\n        sock.sendall(bytes('get_vocab' + \"\\n\", \"utf-8\"))\n        # Receive data from the server and shut down\n        data = b\"\"\n        while True:\n            packet = sock.recv(4096)\n            if not packet:\n                break\n            data += packet\n        received = pickle.loads(data)\n        all_phrases.extend(received)\n        print('vocab len = ' + str(len(all_phrases)))\n        # print(\"Received: {}\".format(received))\n\n    finally:\n        sock.close()"
        },
        "original_method_after_refactoring": {
            "name": "get_phrases",
            "container_name": "main",
            "source_code": "def get_phrases(top_n=100000):\n    global all_phrases\n    received = send_request_to_server('get_vocab')\n    # all_phrases.extend(x for x in received if len(x) < max_phrase_length)\n    all_phrases=received\n    for p in all_phrases:\n        if len(p) < max_phrase_length:\n            all_phrases_dict[p] = p\n            all_cut_phrases_dict[p] = p\n        else:\n            all_phrases_dict[p] = p[:max_phrase_length] + '...'\n            all_cut_phrases_dict[p[:max_phrase_length] + '...'] = p\n    print('done. vocab count = ' + str(len(all_phrases)))"
        },
        "newly_extracted_method": {
            "name": "send_request_to_server",
            "container_name": "main",
            "source_code": "def send_request_to_server(request):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        # Connect to server and send data\n        sock.connect((expand_host, port))\n        print('sending request')\n        sock.sendall(bytes(request + \"\\n\", \"utf-8\"))\n        # Receive data from the server and shut down\n        data = b\"\"\n        ctr = 0\n        while True:\n            packet = sock.recv(134217728)\n            print(str(ctr) + '. received: ' + str(len(packet)))\n            ctr += 1\n            if not packet:\n                break\n            data += packet\n        print('got response, uncompressing')\n        received = pickle.loads(data)\n        # print(\"Received: {}\".format(received))\n        return received\n\n    finally:\n        sock.close()"
        },
        "label": "positive",
        "id": "805be4e0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2438
    },
    {
        "commit_hash": "83bc799fc180ea9863fb0be1ab958d4223e1026c",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "img_data_to_arr",
            "container_name": "image",
            "source_code": "def img_data_to_arr(img_data):\n    f = io.BytesIO()\n    f.write(img_data)\n    img_arr = np.array(PIL.Image.open(f))\n    return img_arr"
        },
        "original_method_after_refactoring": {
            "name": "img_data_to_arr",
            "container_name": "image",
            "source_code": "def img_data_to_arr(img_data):\n    img_pil = img_data_to_pil(img_data)\n    img_arr = np.array(img_pil)\n    return img_arr"
        },
        "newly_extracted_method": {
            "name": "img_data_to_pil",
            "container_name": "image",
            "source_code": "def img_data_to_pil(img_data):\n    f = io.BytesIO()\n    f.write(img_data)\n    img_pil = PIL.Image.open(f)\n    return img_pil"
        },
        "label": "positive",
        "id": "805bef80-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 707
    },
    {
        "commit_hash": "e34b9ae9cf515e8c9c6b2f5d5d812eb5bd74d9d1",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def main():\n    graph_manager.create_graph(TaskParameters())\n    graph_manager.phase = RunPhase.TRAIN\n    graph_manager.act(EnvironmentEpisodes(num_steps=10))",
            "file_path": "commits/e34b9ae9cf515e8c9c6b2f5d5d812eb5bd74d9d1/Before/rl_coach#rollout_worker.py"
        },
        "refactored_code": {
            "source_code": "def rollout_worker(graph_manager):\n    task_parameters = TaskParameters()\n    task_parameters.checkpoint_restore_dir='/checkpoint'\n    graph_manager.create_graph(task_parameters)\n    graph_manager.phase = RunPhase.TRAIN\n    graph_manager.act(EnvironmentEpisodes(num_steps=10))",
            "file_path": "commits/e34b9ae9cf515e8c9c6b2f5d5d812eb5bd74d9d1/After/rl_coach#rollout_worker.py"
        },
        "variable_name": "task_parameters",
        "label": "positive",
        "id": "8069b6d8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 792
    },
    {
        "commit_hash": "d52eb0bf3d6df25c70933321a841dac157806479",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def _generate_anchors(self, feature_map_shape, anchor_reference):\n        \"\"\"Generate anchor for an image.\n\n        Using the feature map, the output of the pretrained network for an\n        image, and the anchor_reference generated using the anchor config\n        values. We generate a list of anchors.\n\n        Anchors are just fixed bounding boxes of different ratios and sizes\n        that are uniformly generated throught the image.\n\n        Args:\n            feature_map_shape: Shape of the convolutional feature map used as\n                input for the RPN. Should be (batch, height, width, depth).\n\n        Returns:\n            all_anchors: A flattened Tensor with all the anchors of shape\n                `(num_anchors_per_points * feature_width * feature_height, 4)`\n                using the (x1, y1, x2, y2) convention.\n        \"\"\"\n        with tf.variable_scope('generate_anchors'):\n            shift_x = tf.range(feature_map_shape[1])\n            shift_y = tf.range(feature_map_shape[0])\n            shift_x, shift_y = tf.meshgrid(shift_x, shift_y)\n\n            shift_x = tf.reshape(shift_x, [-1])\n            shift_y = tf.reshape(shift_y, [-1])\n\n            shifts = tf.stack(\n                [shift_x, shift_y, shift_x, shift_y],\n                axis=0\n            )\n\n            shifts = tf.transpose(shifts)\n            # Shifts now is a (H x W, 4) Tensor\n\n            # Expand dims to use broadcasting sum.\n            all_anchors = (\n                tf.expand_dims(anchor_reference, axis=0) +\n                tf.cast(tf.expand_dims(shifts, axis=1), tf.float64)\n            )\n\n            # Flatten\n            all_anchors = tf.reshape(\n                all_anchors, (-1, 4)\n            )\n            return all_anchors",
            "file_path": "commits/d52eb0bf3d6df25c70933321a841dac157806479/Before/luminoth#models#ssd#ssd.py"
        },
        "refactored_code": {
            "source_code": "def _generate_anchors(self, feature_map_shape, anchor_reference):\n        \"\"\"Generate anchor for an image.\n\n        Using the feature map, the output of the pretrained network for an\n        image, and the anchor_reference generated using the anchor config\n        values. We generate a list of anchors.\n\n        Anchors are just fixed bounding boxes of different ratios and sizes\n        that are uniformly generated throught the image.\n\n        Args:\n            feature_map_shape: Shape of the convolutional feature map used as\n                input for the RPN. Should be (batch, height, width, depth).\n\n        Returns:\n            all_anchors: A flattened Tensor with all the anchors of shape\n                `(num_anchors_per_points * feature_width * feature_height, 4)`\n                using the (x1, y1, x2, y2) convention.\n        \"\"\"\n        with tf.variable_scope('generate_anchors'):\n            shift_x = np.arange(feature_map_shape[1])\n            shift_y = np.arange(feature_map_shape[0])\n            shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n\n            shift_x = np.reshape(shift_x, [-1])\n            shift_y = np.reshape(shift_y, [-1])\n\n            shifts = np.stack(\n                [shift_x, shift_y, shift_x, shift_y],\n                axis=0\n            )\n\n            shifts = np.transpose(shifts)\n            # Shifts now is a (H x W, 4) Tensor\n\n            # Expand dims to use broadcasting sum.\n            all_anchors = (\n                np.expand_dims(anchor_reference, axis=0) +\n                np.expand_dims(shifts, axis=1)\n            )\n            # Flatten\n            return np.reshape(all_anchors, (-1, 4))",
            "file_path": "commits/d52eb0bf3d6df25c70933321a841dac157806479/After/luminoth#models#ssd#ssd.py"
        },
        "variable_name": "all_anchors",
        "label": "positive",
        "id": "806ae36e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3823
    },
    {
        "commit_hash": "8166563234323a086cd5045dee6eb88f05ce39bf",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "open_browser",
            "container_name": "util",
            "source_code": "def open_browser(url):\n    \"\"\"Open a web browser pointing to a given URL.\n\n    We use this function instead of Python's `webbrowser` module because this\n    way we can capture stdout/stderr to avoid polluting the terminal with the\n    browser's messages. For example, Chrome always prints things like \"Created\n    new window in existing browser session\", and those get on the user's way.\n\n    url : str\n        The URL. Must include the protocol.\n\n    \"\"\"\n\n    if env_util.IS_WINDOWS:\n        # Treat Windows separately because:\n        # 1. /dev/null doesn't exist.\n        # 2. subprocess.Popen(['start', url]) doesn't actually pop up the\n        #    browser even though 'start url' works from the command prompt.\n        # Fun!\n        import webbrowser\n\n        webbrowser.open(url)\n        return\n\n    # We don't use the webbrowser module on Linux and Mac because some browsers\n    # (ahem... Chrome) always print \"Opening in existing browser session\" to\n    # the terminal, which is spammy and annoying. So instead we start the\n    # browser ourselves and send all its output to /dev/null.\n\n    if env_util.IS_LINUX_OR_BSD:\n        cmd = [\"xdg-open\", url]\n    elif env_util.IS_DARWIN:\n        cmd = [\"open\", url]\n    else:\n        raise Error('Cannot open browser in platform \"%s\"' % system)\n\n    with open(os.devnull, \"w\") as devnull:\n        subprocess.Popen(cmd, stdout=devnull, stderr=subprocess.STDOUT)"
        },
        "original_method_after_refactoring": {
            "name": "open_browser",
            "container_name": "util",
            "source_code": "def open_browser(url):\n    \"\"\"Open a web browser pointing to a given URL.\n\n    We use this function instead of Python's `webbrowser` module because this\n    way we can capture stdout/stderr to avoid polluting the terminal with the\n    browser's messages. For example, Chrome always prints things like \"Created\n    new window in existing browser session\", and those get on the user's way.\n\n    url : str\n        The URL. Must include the protocol.\n\n    \"\"\"\n\n    # Treat Windows separately because:\n    # 1. /dev/null doesn't exist.\n    # 2. subprocess.Popen(['start', url]) doesn't actually pop up the\n    #    browser even though 'start url' works from the command prompt.\n    # Fun!\n    # Also, use webbrowser if we are on Linux and xdg-open is not installed.\n    #\n    # We don't use the webbrowser module on Linux and Mac because some browsers\n    # (ahem... Chrome) always print \"Opening in existing browser session\" to\n    # the terminal, which is spammy and annoying. So instead we start the\n    # browser ourselves and send all its output to /dev/null.\n\n    if env_util.IS_WINDOWS:\n        _open_browser_with_webbrowser(url)\n        return\n    if env_util.IS_LINUX_OR_BSD:\n        if env_util.is_executable_in_path(\"xdg-open\"):\n            _open_browser_with_command(\"xdg-open\", url)\n            return\n        _open_browser_with_webbrowser(url)\n        return\n    if env_util.IS_DARWIN:\n        _open_browser_with_command(\"open\", url)\n        return\n\n    import platform\n\n    raise Error('Cannot open browser in platform \"%s\"' % platform.system())"
        },
        "newly_extracted_method": {
            "name": "_open_browser_with_command",
            "container_name": "util",
            "source_code": "def _open_browser_with_command(command, url):\n    cmd_line = [command, url]\n    with open(os.devnull, \"w\") as devnull:\n        subprocess.Popen(cmd_line, stdout=devnull, stderr=subprocess.STDOUT)"
        },
        "label": "positive",
        "id": "805c02fe-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3587
    },
    {
        "commit_hash": "be65ce986a45bf2f35b5494db3fa6e993b905aeb",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "NFFM",
            "container_name": "nffm",
            "source_code": "def NFFM(feature_dim_dict, embedding_size=4, dnn_hidden_units=(128, 128),\n         l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, dnn_dropout=0,\n         init_std=0.0001, seed=1024, include_linear=True, use_bn=True, reduce_sum=False, task='binary',\n         ):\n    \"\"\"Instantiates the Field-aware Neural Factorization Machine architecture.\n\n    :param feature_dim_dict: dict,to indicate sparse field and dense field like {'sparse':{'field_1':4,'field_2':3,'field_3':2},'dense':['field_4','field_5']}\n    :param embedding_size: positive integer,sparse feature embedding_size\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param l2_reg_linear: float. L2 regularizer strength applied to linear part.\n    :param l2_reg_dnn: float . L2 regularizer strength applied to DNN\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param include_linear: bool,whether include linear term or not\n    :param use_bn: bool,whether use bn after ffm out or not\n    :param reduce_sum: bool,whether apply reduce_sum on cross vector\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n    \"\"\"\n\n    check_feature_config_dict(feature_dim_dict)\n    if 'sequence' in feature_dim_dict and len(feature_dim_dict['sequence']) > 0:\n        raise ValueError(\"now sequence input is not supported in NFFM\")#TODO:support sequence input\n\n    sparse_input_dict, dense_input_dict = create_singlefeat_inputdict(\n        feature_dim_dict)\n\n    sparse_embedding, dense_embedding, linear_embedding = create_embedding_dict(\n        feature_dim_dict, embedding_size, init_std, seed, l2_reg_embedding, l2_reg_linear, )\n\n    embed_list = []\n    for i, j in itertools.combinations(feature_dim_dict['sparse'], 2):\n        i_input = sparse_input_dict[i.name]\n        if i.hash_flag:\n            i_input = Hash(i.dimension)(i_input)\n        j_input = sparse_input_dict[j.name]\n        if j.hash_flag:\n            j_input = Hash(j.dimension)(j_input)\n\n        element_wise_prod = multiply([sparse_embedding[i.name][j.name](i_input), sparse_embedding[j.name][i.name](j_input)])\n        if reduce_sum:\n            element_wise_prod = Lambda(lambda element_wise_prod: K.sum(\n                element_wise_prod, axis=-1))(element_wise_prod)\n        embed_list.append(element_wise_prod)\n    for i, j in itertools.combinations(feature_dim_dict['dense'], 2):\n        element_wise_prod = multiply([dense_embedding[i.name][j.name](\n            dense_input_dict[i.name]), dense_embedding[j.name][i.name](dense_input_dict[j.name])])\n        if reduce_sum:\n            element_wise_prod = Lambda(lambda element_wise_prod: K.sum(\n                element_wise_prod, axis=-1))(element_wise_prod)\n        embed_list.append(\n            Lambda(lambda x: K.expand_dims(x, axis=1))(element_wise_prod))\n\n    for i in feature_dim_dict['sparse']:\n        i_input = sparse_input_dict[i.name]\n        if i.hash_flag:\n            i_input = Hash(i.dimension)(i_input)\n        for j in feature_dim_dict['dense']:\n            element_wise_prod = multiply([sparse_embedding[i.name][j.name](i_input),\n                                          dense_embedding[j.name][i.name](dense_input_dict[j.name])])\n\n            if reduce_sum:\n                element_wise_prod = Lambda(lambda element_wise_prod: K.sum(element_wise_prod, axis=-1))(\n                    element_wise_prod)\n            embed_list.append(element_wise_prod)\n\n    ffm_out = tf.keras.layers.Flatten()(concat_fun(embed_list, axis=1))\n    if use_bn:\n        ffm_out = tf.keras.layers.BatchNormalization()(ffm_out)\n    ffm_out = DNN(dnn_hidden_units, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout)(ffm_out)\n    final_logit = Dense(1, use_bias=False)(ffm_out)\n\n    linear_emb_list = get_embedding_vec_list(\n        linear_embedding, sparse_input_dict, feature_dim_dict['sparse'])\n\n    linear_logit = get_linear_logit(\n        linear_emb_list, dense_input_dict, l2_reg_linear)\n\n    if include_linear:\n        final_logit = add([final_logit, linear_logit])\n\n    output = PredictionLayer(task)(final_logit)\n\n    inputs_list = get_inputs_list(\n        [sparse_input_dict, dense_input_dict])\n    model = Model(inputs=inputs_list, outputs=output)\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/Before/deepctr#models#nffm.py"
        },
        "inlined_method": {
            "name": "create_embedding_dict",
            "container_name": "nffm",
            "source_code": "def create_embedding_dict(feature_dim_dict, embedding_size, init_std, seed, l2_rev_V, l2_reg_w, ):\n    sparse_embedding = {j.name: {feat.name: Embedding(j.dimension, embedding_size,\n                                                      embeddings_initializer=RandomNormal(\n                                                          mean=0.0, stddev=0.0001, seed=seed),\n                                                      embeddings_regularizer=l2(\n                                                          l2_rev_V),\n                                                      name='sparse_emb_' + str(j.name) + '_' + str(\n                                                          i) + '-' + feat.name) for i, feat in\n                                 enumerate(feature_dim_dict[\"sparse\"] + feature_dim_dict['dense'])} for j in\n                        feature_dim_dict[\"sparse\"]}\n\n    dense_embedding = {\n        j.name: {feat.name: Dense(embedding_size, kernel_initializer=RandomNormal(mean=0.0, stddev=0.0001,\n                                                                                  seed=seed), use_bias=False,\n                                  kernel_regularizer=l2(l2_rev_V), name='sparse_emb_' + str(j.name) + '_' + str(\n                i) + '-' + feat.name) for i, feat in\n                 enumerate(feature_dim_dict[\"sparse\"] + feature_dim_dict[\"dense\"])} for j in feature_dim_dict[\"dense\"]}\n\n    linear_embedding = {feat.name: Embedding(feat.dimension, 1,\n                                             embeddings_initializer=RandomNormal(\n                                                 mean=0.0, stddev=init_std, seed=seed),\n                                             embeddings_regularizer=l2(\n                                                 l2_reg_w),\n                                             name='linear_emb_' + str(i) + '-' + feat.name) for\n                        i, feat in enumerate(feature_dim_dict[\"sparse\"])}\n\n    return sparse_embedding, dense_embedding, linear_embedding",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/Before/deepctr#models#nffm.py"
        },
        "caller": {
            "name": "NFFM",
            "container_name": "nffm",
            "source_code": "def NFFM(linear_feature_columns, dnn_feature_columns, embedding_size=4, dnn_hidden_units=(128, 128),\n         l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, dnn_dropout=0,\n         init_std=0.0001, seed=1024, include_linear=True, use_bn=True, reduce_sum=False, task='binary',\n         ):\n    \"\"\"Instantiates the Operation-aware Neural Networks  architecture.\n\n    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param embedding_size: positive integer,sparse feature embedding_size\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param l2_reg_linear: float. L2 regularizer strength applied to linear part.\n    :param l2_reg_dnn: float . L2 regularizer strength applied to DNN\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param include_linear: bool,whether include linear term or not\n    :param use_bn: bool,whether use bn after ffm out or not\n    :param reduce_sum: bool,whether apply reduce_sum on cross vector\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n    \"\"\"\n\n\n    #todo \u9700\u8981\u4fee\u6539\n    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n\n    if len(varlen_sparse_feature_columns)> 0:\n        raise ValueError(\"VarLenSparseFeat is not supported in ONN now\")#TODO:support sequence input\n\n\n    features = build_input_features(linear_feature_columns + dnn_feature_columns)\n\n    inputs_list = list(features.values())\n\n    linear_logit = get_linear_logit(features, linear_feature_columns, l2_reg=l2_reg_linear, init_std=init_std,\n                                    seed=seed, prefix='linear')\n\n    sparse_feature_columns = list(filter(lambda x:isinstance(x,SparseFeat),dnn_feature_columns)) if dnn_feature_columns else []\n    #varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n\n\n\n    sparse_embedding = {fc_j.embedding_name: {fc_i.embedding_name: Embedding(fc_j.dimension, embedding_size,\n                                                      embeddings_initializer=RandomNormal(\n                                                          mean=0.0, stddev=0.0001, seed=seed),\n                                                      embeddings_regularizer=l2(\n                                                          l2_reg_embedding),\n                                                      name='sparse_emb_' + str(fc_j.embedding_name) + '_' + str(\n                                                          i) + '-' + fc_i.embedding_name) for i, fc_i in\n                                 enumerate(sparse_feature_columns)} for fc_j in\n                        sparse_feature_columns}\n\n\n    dense_value_list = get_dense_input(features,dnn_feature_columns)\n\n\n    embed_list = []\n    for fc_i, fc_j in itertools.combinations(sparse_feature_columns, 2):\n        i_input = features[fc_i.name]\n        if fc_i.use_hash:\n            i_input = Hash(fc_i.dimension)(i_input)\n        j_input = features[fc_j.name]\n        if fc_j.use_hash:\n            j_input = Hash(fc_j.dimension)(j_input)\n\n        element_wise_prod = multiply([sparse_embedding[fc_i.name][fc_j.name](i_input), sparse_embedding[fc_j.name][fc_i.name](j_input)])\n        if reduce_sum:\n            element_wise_prod = Lambda(lambda element_wise_prod: K.sum(\n                element_wise_prod, axis=-1))(element_wise_prod)\n        embed_list.append(element_wise_prod)\n\n    ffm_out = tf.keras.layers.Flatten()(concat_fun(embed_list, axis=1))\n    if use_bn:\n        ffm_out = tf.keras.layers.BatchNormalization()(ffm_out)\n    dnn_input = combined_dnn_input([ffm_out],dense_value_list)\n    dnn_out = DNN(dnn_hidden_units, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout)(dnn_input)\n    final_logit = Dense(1, use_bias=False)(dnn_out)\n\n    if include_linear:\n        final_logit = add([final_logit, linear_logit])\n\n    output = PredictionLayer(task)(final_logit)\n\n    model = Model(inputs=inputs_list, outputs=output)\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/After/deepctr#models#nffm.py"
        },
        "label": "positive",
        "id": "805edf2e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 11978
    },
    {
        "commit_hash": "9f352f5072543a5a47b78943bf9a729eb18502c6",
        "refactoring_type": "Rename Method",
        "original_method": {
            "name": "test_forward_acbs",
            "container_name": "DRIT",
            "source_code": "def test_forward_acbs(self, image_ac, image_bs):\n    self.zs_ac, self.zs_as = self.enc_c.forward(image_ac, image_bs)\n    self.mu_as, self.logvar_as, self.mu_bs, self.logvar_bs = self.enc_a.forward(image_bs, image_bs)\n    std_b = self.logvar_bs.mul(0.5).exp_()\n    eps = self.get_z_random(std_b.size(0), std_b.size(1), 'gauss')\n    self.z_attr_bs = eps.mul(std_b).add_(self.mu_bs)\n    image = self.gen.forward_b(self.zs_ac, self.z_attr_bs)\n    return image",
            "file_path": "commits/9f352f5072543a5a47b78943bf9a729eb18502c6/Before/src#model.py"
        },
        "renamed_method": {
            "name": "interpolate",
            "container_name": "DRIT_concat",
            "source_code": "def interpolate(self, image, npfile1, npfile2, a2b=True):\n    z1 = np.load(npfile1)\n    z2 = np.load(npfile2)\n    num = 3\n    z_diff = (z2 - z1) / float(num)\n    self.z_content_a, self.z_content_b = self.enc_c.forward(image, image)\n    image_out = []\n    for i in range(num + 1):\n      z = torch.FloatTensor(z1 + z_diff * i).cuda()\n      if a2b:\n        image_out.append(self.gen.forward_b(self.z_content_a, z))\n      else:\n        image_out.append(self.gen.forward_a(self.z_content_b, z))\n    return image_out",
            "file_path": "commits/9f352f5072543a5a47b78943bf9a729eb18502c6/After/src#model.py"
        },
        "label": "negative",
        "id": "8063f3f6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1400
    },
    {
        "commit_hash": "fe6a63f124f897fa24e0be6dfc2d20082896b95d",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def __init__(\n        self,\n        file_name: Optional[str] = None,\n        worker_id: int = 0,\n        base_port: Optional[int] = None,\n        seed: int = 0,\n        no_graphics: bool = False,\n        timeout_wait: int = 60,\n        args: Optional[List[str]] = None,\n        side_channels: Optional[List[SideChannel]] = None,\n    ):\n        \"\"\"\n        Starts a new unity environment and establishes a connection with the environment.\n        Notice: Currently communication between Unity and Python takes place over an open socket without authentication.\n        Ensure that the network where training takes place is secure.\n\n        :string file_name: Name of Unity environment binary.\n        :int base_port: Baseline port number to connect to Unity environment over. worker_id increments over this.\n        If no environment is specified (i.e. file_name is None), the DEFAULT_EDITOR_PORT will be used.\n        :int worker_id: Offset from base_port. Used for training multiple environments simultaneously.\n        :bool no_graphics: Whether to run the Unity simulator in no-graphics mode\n        :int timeout_wait: Time (in seconds) to wait for connection from environment.\n        :list args: Addition Unity command line arguments\n        :list side_channels: Additional side channel for no-rl communication with Unity\n        \"\"\"\n        args = args or []\n        atexit.register(self._close)\n        # If base port is not specified, use BASE_ENVIRONMENT_PORT if we have\n        # an environment, otherwise DEFAULT_EDITOR_PORT\n        if base_port is None:\n            base_port = (\n                self.BASE_ENVIRONMENT_PORT if file_name else self.DEFAULT_EDITOR_PORT\n            )\n        self.port = base_port + worker_id\n        self._buffer_size = 12000\n        # If true, this means the environment was successfully loaded\n        self._loaded = False\n        # The process that is started. If None, no process was started\n        self.proc1 = None\n        self.timeout_wait: int = timeout_wait\n        self.communicator = self.get_communicator(worker_id, base_port, timeout_wait)\n        self.worker_id = worker_id\n        self.side_channels: Dict[uuid.UUID, SideChannel] = {}\n        if side_channels is not None:\n            for _sc in side_channels:\n                if _sc.channel_id in self.side_channels:\n                    raise UnityEnvironmentException(\n                        \"There cannot be two side channels with the same channel id {0}.\".format(\n                            _sc.channel_id\n                        )\n                    )\n                self.side_channels[_sc.channel_id] = _sc\n\n        # If the environment name is None, a new environment will not be launched\n        # and the communicator will directly try to connect to an existing unity environment.\n        # If the worker-id is not 0 and the environment name is None, an error is thrown\n        if file_name is None and worker_id != 0:\n            raise UnityEnvironmentException(\n                \"If the environment name is None, \"\n                \"the worker-id must be 0 in order to connect with the Editor.\"\n            )\n        if file_name is not None:\n            self.executable_launcher(file_name, no_graphics, args)\n        else:\n            logger.info(\n                f\"Listening on port {self.port}. \"\n                f\"Start training by pressing the Play button in the Unity Editor.\"\n            )\n        self._loaded = True\n\n        rl_init_parameters_in = UnityRLInitializationInputProto(\n            seed=seed,\n            communication_version=self.API_VERSION,\n            package_version=mlagents_envs.__version__,\n        )\n        try:\n            aca_output = self.send_academy_parameters(rl_init_parameters_in)\n            aca_params = aca_output.rl_initialization_output\n        except UnityTimeOutException:\n            self._close(0)\n            raise\n\n        unity_communicator_version = aca_params.communication_version\n        if unity_communicator_version != UnityEnvironment.API_VERSION:\n            self._close(0)\n            raise UnityEnvironmentException(\n                f\"The communication API version is not compatible between Unity and python. \"\n                f\"Python API: {UnityEnvironment.API_VERSION}, Unity API: {unity_communicator_version}.\\n \"\n                f\"Please go to https://github.com/Unity-Technologies/ml-agents/releases/tag/latest_release \"\n                f\"to download the latest version of ML-Agents.\"\n            )\n        else:\n            logger.info(\n                f\"Connected to Unity environment with package version {aca_params.package_version} \"\n                f\"and communication version {aca_params.communication_version}\"\n            )\n        self._env_state: Dict[str, Tuple[DecisionSteps, TerminalSteps]] = {}\n        self._env_specs: Dict[str, BehaviorSpec] = {}\n        self._env_actions: Dict[str, np.ndarray] = {}\n        self._is_first_message = True\n        self._update_behavior_specs(aca_output)",
            "file_path": "commits/fe6a63f124f897fa24e0be6dfc2d20082896b95d/Before/ml-agents-envs#mlagents_envs#environment.py"
        },
        "refactored_code": {
            "source_code": "def __init__(\n        self,\n        file_name: Optional[str] = None,\n        worker_id: int = 0,\n        base_port: Optional[int] = None,\n        seed: int = 0,\n        no_graphics: bool = False,\n        timeout_wait: int = 60,\n        args: Optional[List[str]] = None,\n        side_channels: Optional[List[SideChannel]] = None,\n    ):\n        \"\"\"\n        Starts a new unity environment and establishes a connection with the environment.\n        Notice: Currently communication between Unity and Python takes place over an open socket without authentication.\n        Ensure that the network where training takes place is secure.\n\n        :string file_name: Name of Unity environment binary.\n        :int base_port: Baseline port number to connect to Unity environment over. worker_id increments over this.\n        If no environment is specified (i.e. file_name is None), the DEFAULT_EDITOR_PORT will be used.\n        :int worker_id: Offset from base_port. Used for training multiple environments simultaneously.\n        :bool no_graphics: Whether to run the Unity simulator in no-graphics mode\n        :int timeout_wait: Time (in seconds) to wait for connection from environment.\n        :list args: Addition Unity command line arguments\n        :list side_channels: Additional side channel for no-rl communication with Unity\n        \"\"\"\n        args = args or []\n        atexit.register(self._close)\n        # If base port is not specified, use BASE_ENVIRONMENT_PORT if we have\n        # an environment, otherwise DEFAULT_EDITOR_PORT\n        if base_port is None:\n            base_port = (\n                self.BASE_ENVIRONMENT_PORT if file_name else self.DEFAULT_EDITOR_PORT\n            )\n        self.port = base_port + worker_id\n        self._buffer_size = 12000\n        # If true, this means the environment was successfully loaded\n        self._loaded = False\n        # The process that is started. If None, no process was started\n        self.proc1 = None\n        self.timeout_wait: int = timeout_wait\n        self.communicator = self.get_communicator(worker_id, base_port, timeout_wait)\n        self.worker_id = worker_id\n        self.side_channels: Dict[uuid.UUID, SideChannel] = {}\n        if side_channels is not None:\n            for _sc in side_channels:\n                if _sc.channel_id in self.side_channels:\n                    raise UnityEnvironmentException(\n                        \"There cannot be two side channels with the same channel id {0}.\".format(\n                            _sc.channel_id\n                        )\n                    )\n                self.side_channels[_sc.channel_id] = _sc\n\n        # If the environment name is None, a new environment will not be launched\n        # and the communicator will directly try to connect to an existing unity environment.\n        # If the worker-id is not 0 and the environment name is None, an error is thrown\n        if file_name is None and worker_id != 0:\n            raise UnityEnvironmentException(\n                \"If the environment name is None, \"\n                \"the worker-id must be 0 in order to connect with the Editor.\"\n            )\n        if file_name is not None:\n            self.executable_launcher(file_name, no_graphics, args)\n        else:\n            logger.info(\n                f\"Listening on port {self.port}. \"\n                f\"Start training by pressing the Play button in the Unity Editor.\"\n            )\n        self._loaded = True\n\n        rl_init_parameters_in = UnityRLInitializationInputProto(\n            seed=seed,\n            communication_version=self.API_VERSION,\n            package_version=mlagents_envs.__version__,\n        )\n        try:\n            aca_output = self.send_academy_parameters(rl_init_parameters_in)\n            aca_params = aca_output.rl_initialization_output\n        except UnityTimeOutException:\n            self._close(0)\n            raise\n\n        if not UnityEnvironment.check_communication_compatibility(\n            aca_params.communication_version,\n            UnityEnvironment.API_VERSION,\n            aca_params.package_version,\n        ):\n            self._close(0)\n            UnityEnvironment._raise_version_exception(aca_params.communication_version)\n\n        self._env_state: Dict[str, Tuple[DecisionSteps, TerminalSteps]] = {}\n        self._env_specs: Dict[str, BehaviorSpec] = {}\n        self._env_actions: Dict[str, np.ndarray] = {}\n        self._is_first_message = True\n        self._update_behavior_specs(aca_output)",
            "file_path": "commits/fe6a63f124f897fa24e0be6dfc2d20082896b95d/After/ml-agents-envs#mlagents_envs#environment.py"
        },
        "variable_name": "unity_communicator_version",
        "label": "positive",
        "id": "806aeb16-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 10058
    },
    {
        "commit_hash": "73a5213bfbe7c40079102dfebe0cc12ab17135be",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "frame",
            "container_name": "conftest",
            "source_code": "def frame():\n    \"\"\"Make mocked frame as fixture.\"\"\"\n    return _create_frame()",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/Before/pandas#tests#window#conftest.py"
        },
        "inlined_method": {
            "name": "_create_frame",
            "container_name": "conftest",
            "source_code": "def _create_frame():\n    \"\"\"Internal function to mock DataFrame.\"\"\"\n    return DataFrame(\n        np.random.randn(100, 10),\n        index=bdate_range(datetime(2009, 1, 1), periods=100),\n        columns=np.arange(10),\n    )",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/Before/pandas#tests#window#conftest.py"
        },
        "caller": {
            "name": "frame",
            "container_name": "conftest",
            "source_code": "def frame():\n    \"\"\"Make mocked frame as fixture.\"\"\"\n    return DataFrame(\n        np.random.randn(100, 10),\n        index=bdate_range(datetime(2009, 1, 1), periods=100),\n        columns=np.arange(10),\n    )",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/After/pandas#tests#window#conftest.py"
        },
        "label": "positive",
        "id": "805edaec-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1135
    },
    {
        "commit_hash": "13c14eac076c81227a96e24f749392f5b75aa2ce",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "init",
            "container_name": "async_api",
            "source_code": "def init():\n    \"\"\"\n    Initialize synchronously.\n    \"\"\"\n    assert ray.is_initialized(), \"Please call ray.init before async_api.init\"\n\n    # Noop when handler is set.\n    if handler is not None:\n        return\n\n    loop = asyncio.get_event_loop()\n    if loop.is_running():\n        if loop._thread_id != threading.get_ident():\n            # If the loop is runing outside current thread, we actually need\n            # to do this to make sure the context is initialized.\n            asyncio.run_coroutine_threadsafe(_async_init(), loop=loop)\n        else:\n            async_init_done = asyncio.get_event_loop().create_task(\n                _async_init())\n            # Block until the async init finishes.\n            async_init_done.done()\n    else:\n        asyncio.get_event_loop().run_until_complete(_async_init())",
            "file_path": "commits/13c14eac076c81227a96e24f749392f5b75aa2ce/Before/python#ray#experimental#async_api.py"
        },
        "inlined_method": {
            "name": "_async_init",
            "container_name": "async_api",
            "source_code": "def _async_init():\n    global handler\n    if handler is None:\n        worker = ray.worker.global_worker\n        loop = asyncio.get_event_loop()\n        handler = PlasmaEventHandler(loop, worker)\n        worker.core_worker.set_plasma_added_callback(handler)\n        logger.debug(\"AsyncPlasma Connection Created!\")",
            "file_path": "commits/13c14eac076c81227a96e24f749392f5b75aa2ce/Before/python#ray#experimental#async_api.py"
        },
        "caller": {
            "name": "init",
            "container_name": "async_api",
            "source_code": "def init():\n    \"\"\"Initialize plasma event handlers for asyncio support.\"\"\"\n    assert ray.is_initialized(), \"Please call ray.init before async_api.init\"\n\n    global handler\n    if handler is None:\n        worker = ray.worker.global_worker\n        loop = asyncio.get_event_loop()\n        handler = PlasmaEventHandler(loop, worker)\n        worker.core_worker.set_plasma_added_callback(handler)\n        logger.debug(\"AsyncPlasma Connection Created!\")",
            "file_path": "commits/13c14eac076c81227a96e24f749392f5b75aa2ce/After/python#ray#experimental#async_api.py"
        },
        "label": "positive",
        "id": "805eddb2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2244
    },
    {
        "commit_hash": "4850f1e47db0e2ee9b881e92a5bb6e873f12b417",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def sample(self, sample_shape=(1,)):\n    \"\"\"Sample from the rejection sampling distribution.\n\n    For ease of implementation, draw the maximum number of proposal samples.\n\n    Args:\n      sample_shape: Shape of samples to draw.\n\n    Returns:\n      samples: Tensor of samples from the distribution, sample_shape + data_dim\n    \"\"\"\n    sample_shape = list(sample_shape)\n    shape = sample_shape + [self.T]\n    proposal_samples = self.proposal.sample(\n        shape)  # sample_shape + [T] + data_dim\n\n    # Work in the batched space\n    batched_proposal_samples = tf.reshape(proposal_samples[:, :-1],\n                                          [-1] + self.data_dim)\n    logit_accept = self.logit_accept_fn(batched_proposal_samples)\n    accept_samples = tfd.Bernoulli(logits=logit_accept).sample()\n\n    # Reshape and add accept to last sample to ensure truncation\n    accept_samples = tf.concat([\n        tf.reshape(accept_samples, sample_shape + [self.T - 1]),\n        tf.ones(sample_shape + [1], dtype=accept_samples.dtype)\n    ],\n                               axis=-1)\n\n    # For each of sample_shape, find the first nonzero accept\n    def get_first_nonzero_index(t):\n      # t is batch_dims + [T], t is binary.\n      _, indices = tf.math.top_k(t, k=1, sorted=False)\n      return indices\n\n    accept_indices = get_first_nonzero_index(accept_samples)  # sample_shape\n    samples = tf.batch_gather(proposal_samples, accept_indices)\n    return tf.squeeze(samples, axis=len(sample_shape))",
            "file_path": "commits/4850f1e47db0e2ee9b881e92a5bb6e873f12b417/Before/eim#models#rejection_sampling.py"
        },
        "refactored_code": {
            "source_code": "def sample(self, num_samples=1):\n    \"\"\"Sample from the rejection sampling distribution.\n\n    For ease of implementation, draw the maximum number of proposal samples.\n\n    Args:\n      num_samples: integer, number of samples to draw.\n\n    Returns:\n      samples: Tensor of samples from the distribution, [num_samples] + data_dim\n    \"\"\"\n    flat_proposal_samples = self.proposal.sample(num_samples * self.T)\n    proposal_samples = tf.reshape(flat_proposal_samples,\n                                  [num_samples, self.T] + self.data_dim)\n    flat_logit_accept = self.logit_accept_fn(flat_proposal_samples)\n    logit_accept = tf.reshape(flat_logit_accept, [num_samples, self.T])\n    accept_samples = tfd.Bernoulli(logits=logit_accept[:, :-1]).sample()\n\n    # Add forced accept to last sample to ensure truncation\n    accept_samples = tf.concat([\n        accept_samples,\n        tf.ones([num_samples, 1], dtype=accept_samples.dtype)\n    ], axis=-1)\n\n    # For each of sample_shape, find the first nonzero accept\n    def get_first_nonzero_index(t):\n      # t is batch_dims + [T], t is binary.\n      _, indices = tf.math.top_k(t, k=1, sorted=False)\n      return indices\n\n    accept_indices = get_first_nonzero_index(accept_samples)  # sample_shape\n    samples = tf.batch_gather(proposal_samples, accept_indices)\n    return tf.squeeze(samples, axis=1)  # Squeeze the selected dim",
            "file_path": "commits/4850f1e47db0e2ee9b881e92a5bb6e873f12b417/After/eim#models#rejection_sampling.py"
        },
        "original_variable_name": "logit_accept",
        "new_variable_name": "flat_logit_accept",
        "label": "negative",
        "id": "806793b2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3300
    },
    {
        "commit_hash": "b09454afb34000634c8a77050135e3201f6f365d",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def assert_is_semantic_segmentation_dataset(dataset, n_class, repeat=10):\n    \"\"\"Checks if a dataset satisfies semantic segmentation dataset APIs.\n\n    This function checks if a given dataset satisfies semantic segmentation\n    dataset dataset APIs or not.\n    If the dataset does not satifiy the APIs, this function raises an\n    :class:`AssertionError`.\n\n    Args:\n        dataset: A dataset to be checked.\n        n_class (int): The number of classes including background.\n        repeat (int): The number of trials. This function picks\n            an example randomly and checks it. This argmuments determines,\n            how many times this function picks and checks.\n            The default value is :obj:`10`.\n    \"\"\"\n\n    assert len(dataset) > 0, 'The length of dataset must be greater than zero.'\n\n    for _ in six.moves.range(repeat):\n        i = np.random.randint(0, len(dataset))\n        sample = dataset[i]\n\n        assert len(sample) >= 2, \\\n            'Each example must have at least two elements:' \\\n            'img and label.'\n\n        img, label = sample[:2]\n\n        assert_is_image(img, color=True)\n\n        assert isinstance(label, np.ndarray), \\\n            'label must be a numpy.ndarray.'\n        assert label.dtype == np.int32, \\\n            'The type of label must be numpy.int32.'\n        assert label.shape == img.shape[1:], \\\n            'The shape of label must be (H, W).'\n        assert label.min() >= -1 and label.max() < n_class, \\\n            'The value of label must be in [-1, n_class - 1].'",
            "file_path": "commits/b09454afb34000634c8a77050135e3201f6f365d/Before/chainercv#utils#testing#assertions#assert_is_semantic_segmentation_dataset.py"
        },
        "refactored_code": {
            "source_code": "def assert_is_semantic_segmentation_dataset(dataset, n_class, n_example=None):\n    \"\"\"Checks if a dataset satisfies semantic segmentation dataset APIs.\n\n    This function checks if a given dataset satisfies semantic segmentation\n    dataset dataset APIs or not.\n    If the dataset does not satifiy the APIs, this function raises an\n    :class:`AssertionError`.\n\n    Args:\n        dataset: A dataset to be checked.\n        n_class (int): The number of classes including background.\n        n_example (int): The number of examples to be checked.\n            If this argument is specified, this function picks\n            examples ramdomly and checks them. Otherwise,\n            this function checks all examples.\n\n    \"\"\"\n\n    assert len(dataset) > 0, 'The length of dataset must be greater than zero.'\n\n    if n_example:\n        for _ in six.moves.range(n_example):\n            i = np.random.randint(0, len(dataset))\n            _check_example(dataset[i], n_class)\n    else:\n        for i in six.moves.range(len(dataset)):\n            _check_example(dataset[i], n_class)",
            "file_path": "commits/b09454afb34000634c8a77050135e3201f6f365d/After/chainercv#utils#testing#assertions#assert_is_semantic_segmentation_dataset.py"
        },
        "variable_name": "sample",
        "label": "positive",
        "id": "806ae760-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3130
    },
    {
        "commit_hash": "5861cf12fd51a5ca2841b50940263506e273dc4f",
        "refactoring_type": "Rename Method",
        "original_method": {
            "name": "test_estimator_class",
            "container_name": "ModelNameTests",
            "source_code": "def test_estimator_class(self):\n        \"\"\"\n        Test that isestimator works for classes\n        \"\"\"\n        self.assertTrue(LinearRegression)",
            "file_path": "commits/5861cf12fd51a5ca2841b50940263506e273dc4f/Before/tests#test_utils.py"
        },
        "renamed_method": {
            "name": "test_estimator_alias",
            "container_name": "ModelUtilityTests",
            "source_code": "def test_estimator_alias(self):\n        \"\"\"\n        Assert is_estimator aliases isestimator\n        \"\"\"\n        self.assertEqual(\n            is_estimator(LinearRegression), isestimator(LinearRegression)\n        )",
            "file_path": "commits/5861cf12fd51a5ca2841b50940263506e273dc4f/After/tests#test_utils.py"
        },
        "label": "negative",
        "id": "8063f4b4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 825
    },
    {
        "commit_hash": "7c4f035497540e3217042201d08693a5ecc12b55",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_resampler_3d_replicate_cubic_correctness(self):\n        self._test_correctness(input=self.get_3d_input1(),\n                               grid=tf.constant(\n                                   [[[.25,.25,.25],[.25,.75,.25]],\n                                   [[.75,.25,.25],[.25,.25,.75]]],\n                                   dtype=tf.float32),\n                               interpolation='BSPLINE',\n                               boundary='REPLICATE',\n                               expected_value=[[[3.20869954],[3.93501790]],\n                                               [[12.63008626],[10.33280436]]])",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/Before/tests#resampler_test.py"
        },
        "refactored_code": {
            "source_code": "def test_resampler_3d_multivariate_replicate_linear_correctness(self):\n        test_grid = tf.constant(\n            [[[.25, .25, .25], [.25, .75, .25]],\n             [[.75, .25, .25], [.25, .25, .75]]],\n            dtype=tf.float32)\n        expected = [[[2.75, 102.75], [3.75, 103.75]],\n                    [[12.75, 112.75], [11.25, 111.25]]]\n        self._test_correctness(input=self.get_3d_input2(),\n                               grid=test_grid,\n                               interpolation='LINEAR',\n                               boundary='REPLICATE',\n                               expected_value=expected)",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/After/tests#resampler_test.py"
        },
        "variable_name": "test_grid",
        "label": "negative",
        "id": "8069bcbe-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1586
    },
    {
        "commit_hash": "77c16db8bf8cbc0548e37b5b5622644c8e243e8b",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def load_datalist(dir, shuffle=False):\n    files = os.listdir(dir)\n    datalist = []\n    for file in files:\n        datalist.append(os.path.join(dir, file))\n    if shuffle:\n        random.shuffle(datalist)\n    return datalist",
            "file_path": "commits/77c16db8bf8cbc0548e37b5b5622644c8e243e8b/Before/lib#utils.py"
        },
        "refactored_code": {
            "source_code": "def load_datalist(dir, shuffle=False):\n    files = os.listdir(dir)\n    datalist = []\n    for file in files:\n        path = os.path.join(dir, file)\n        if os.path.isfile(path):\n            datalist.append(path)\n    if shuffle:\n        random.shuffle(datalist)\n    return datalist",
            "file_path": "commits/77c16db8bf8cbc0548e37b5b5622644c8e243e8b/After/lib#utils.py"
        },
        "variable_name": "path",
        "label": "positive",
        "id": "8069bfb6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 834
    },
    {
        "commit_hash": "a299033a771822e5176d3eff54c63798bc9675af",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "build_model_from_config",
            "container_name": "infer",
            "source_code": "def build_model_from_config(config_path):\n    set_usr_dir(config_path, paths.USR_PATH)\n    vocab_path = set_vocab_path()\n    model = _get_model(config_path, vocab_path)\n    return model",
            "file_path": "commits/a299033a771822e5176d3eff54c63798bc9675af/Before/deeppavlov#core#commands#infer.py"
        },
        "inlined_method": {
            "name": "_get_model",
            "container_name": "infer",
            "source_code": "def _get_model(config_path, vocab_path):\n    config = read_json(config_path)\n    model_config = config['model']\n    model_name = model_config['name']\n    model = from_params(_REGISTRY[model_name], model_config, vocab_path=vocab_path)\n    model.reset()\n    return model",
            "file_path": "commits/a299033a771822e5176d3eff54c63798bc9675af/Before/deeppavlov#core#commands#infer.py"
        },
        "caller": {
            "name": "build_model_from_config",
            "container_name": "infer",
            "source_code": "def build_model_from_config(config_path):\n    set_usr_dir(config_path, paths.USR_PATH)\n    vocab_path = set_vocab_path()\n\n    config = read_json(config_path)\n    model_config = config['model']\n    model_name = model_config['name']\n    model = from_params(_REGISTRY[model_name], model_config, vocab_path=vocab_path)\n    model.reset()\n\n    return model",
            "file_path": "commits/a299033a771822e5176d3eff54c63798bc9675af/After/deeppavlov#core#commands#infer.py"
        },
        "label": "positive",
        "id": "805ee0dc-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1467
    },
    {
        "commit_hash": "fb62cf7fa1ae6d5382ba0c3aafc75893f4fa6444",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "load",
            "container_name": "MeterGroup",
            "source_code": "def load(self, sample_period=None, **kwargs):\n        \"\"\"Returns a generator of DataFrames loaded from the DataStore.\n\n        By default, `load` will load all available columns from the DataStore.  \n        Specific columns can be selected in one or two mutually exclusive ways:\n\n        1. specify a list of column names using the `cols` parameter.\n        2. specify a `physical_quantity` and/or an `ac_type` parameter to ask \n           `load` to automatically select columns.\n\n        Each meter in the MeterGroup will first be reindexed before being added.\n\n        Note that we just use forward filling to reindex.\n\n        Also note that the timeframe will be the *union* of the timeframes of\n        all individual meters.\n\n        Also note that `chunksize` refers to the chunksize for each individual\n        meter.  If those chunks span a large timeframe then the timeframe of\n        the returned data will be large.\n\n        Parameters\n        ----------\n        sample_period : number, seconds, optional\n            The sample_period to reindex all meters to.  If not specified then\n            will use the max of all meters' sample_periods.\n\n        physical_quantity : string or list of strings\n            e.g. 'power' or 'voltage' or 'energy' or ['power', 'energy'].\n            If a single string then load columns only for that physical quantity.\n            If a list of strings then load columns for all those physical \n            quantities.\n\n        ac_type : string or list of strings, defaults to None\n            Where 'ac_type' is short for 'alternating current type'.  e.g. \n            'reactive' or 'active' or 'apparent'.\n            If set to None then will load all AC types per physical quantity.\n            If set to 'best' then load the single best AC type per \n            physical quantity.\n            If set to a single AC type then load just that single AC type per \n            physical quantity, else raise an Exception.\n            If set to a list of AC type strings then will load all those \n            AC types and will raise an Exception if any cannot be found.\n\n        cols : list of tuples, using NILMTK's vocabulary for measurements.\n            e.g. [('power', 'active'), ('voltage', ''), ('energy', 'reactive')]\n            `cols` can't be used if `ac_type` and/or `physical_quantity` are set.\n\n        preprocessing : list of Node subclass instances\n            e.g. [Clip()]\n\n        **kwargs : any other key word arguments to pass to `self.store.load()`\n\n        Returns\n        ---------\n        Always return a generator of DataFrames (even if it only has a single \n        column).\n\n        .. note:: Different AC types will be treated separately.\n        \"\"\"\n        if kwargs.has_key('preprocessing'):\n            warn(\"If you are using `preprocessing` to resample then please\"\n                 \" do not!  Instead, please use the `sample_period` parameter.\")\n\n        # Get a list of generators\n        generators = []\n        for meter in self.meters:\n            try:\n                generator = meter.load(**kwargs)\n            except MeasurementError as e:\n                warn(\"Ignoring meter '{}' because it does not have the correct\"\n                     \" measurements.  The MeasurementError was: '{}'\"\n                     .format(meter.identifier, e))\n            else:\n                generators.append(generator)\n\n        if sample_period is None:\n            sample_period = self.sample_period()\n\n        # Load each generator and yield the sum or the mean\n        while True:\n            chunk = combine_chunks_from_generators(generators, sample_period)\n            if chunk.empty:\n                break\n            yield chunk"
        },
        "original_method_after_refactoring": {
            "name": "load",
            "container_name": "MeterGroup",
            "source_code": "def load(self, sample_period=None, **kwargs):\n        \"\"\"Returns a generator of DataFrames loaded from the DataStore.\n\n        By default, `load` will load all available columns from the DataStore.  \n        Specific columns can be selected in one or two mutually exclusive ways:\n\n        1. specify a list of column names using the `cols` parameter.\n        2. specify a `physical_quantity` and/or an `ac_type` parameter to ask \n           `load` to automatically select columns.\n\n        Each meter in the MeterGroup will first be reindexed before being added.\n\n        Note that we just use forward filling to reindex.\n\n        Also note that the timeframe will be the *union* of the timeframes of\n        all individual meters.\n\n        Also note that `chunksize` refers to the chunksize for each individual\n        meter.  If those chunks span a large timeframe then the timeframe of\n        the returned data will be large.\n\n        Parameters\n        ----------\n        sample_period : number, seconds, optional\n            The sample_period to reindex all meters to.  If not specified then\n            will use the max of all meters' sample_periods.\n\n        physical_quantity : string or list of strings\n            e.g. 'power' or 'voltage' or 'energy' or ['power', 'energy'].\n            If a single string then load columns only for that physical quantity.\n            If a list of strings then load columns for all those physical \n            quantities.\n\n        ac_type : string or list of strings, defaults to None\n            Where 'ac_type' is short for 'alternating current type'.  e.g. \n            'reactive' or 'active' or 'apparent'.\n            If set to None then will load all AC types per physical quantity.\n            If set to 'best' then load the single best AC type per \n            physical quantity.\n            If set to a single AC type then load just that single AC type per \n            physical quantity, else raise an Exception.\n            If set to a list of AC type strings then will load all those \n            AC types and will raise an Exception if any cannot be found.\n\n        cols : list of tuples, using NILMTK's vocabulary for measurements.\n            e.g. [('power', 'active'), ('voltage', ''), ('energy', 'reactive')]\n            `cols` can't be used if `ac_type` and/or `physical_quantity` are set.\n\n        preprocessing : list of Node subclass instances\n            e.g. [Clip()]\n\n        **kwargs : any other key word arguments to pass to `self.store.load()`\n\n        Returns\n        ---------\n        Always return a generator of DataFrames (even if it only has a single \n        column).\n\n        .. note:: Different AC types will be treated separately.\n        \"\"\"\n        if kwargs.has_key('preprocessing'):\n            warn(\"If you are using `preprocessing` to resample then please\"\n                 \" do not!  Instead, please use the `sample_period` parameter.\")\n\n        if sample_period is None:\n            sample_period = self.sample_period()\n\n        # Load each generator and yield the sum or the mean\n        _, generators = self._meter_generators(**kwargs)\n        while True:\n            chunk = combine_chunks_from_generators(generators, sample_period)\n            if chunk.empty:\n                break\n            yield chunk"
        },
        "newly_extracted_method": {
            "name": "_meter_generators",
            "container_name": "MeterGroup",
            "source_code": "def _meter_generators(self, **kwargs):\n        \"\"\"Returns (list of identifiers, list of generators).\"\"\"\n        generators = []\n        identifiers = []\n        for meter in self.meters:\n            try:\n                generator = meter.load(**deepcopy(kwargs))\n            except MeasurementError as e:\n                warn(\"Ignoring meter '{}' because it does not have the correct\"\n                     \" measurements.  The MeasurementError was: '{}'\"\n                     .format(meter.identifier, e))\n            else:\n                generators.append(generator)\n                identifiers.append(meter.identifier)\n\n        return identifiers, generators"
        },
        "label": "positive",
        "id": "805be508-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 8240
    },
    {
        "commit_hash": "57a45aaf7e82a826e1bffb133c328f913844bd4c",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def hybrid_forward(self, F, step_input, states, mask=None, position_weight=None):\n        #pylint: disable=arguments-differ\n        \"\"\"\n\n        Parameters\n        ----------\n        step_input : NDArray or Symbol, Shape (batch_size, length, C_in)\n        states : list of NDArray or Symbol\n        mask : NDArray or Symbol\n        position_weight : NDArray or Symbol\n\n        Returns\n        -------\n        step_output : NDArray or Symbol\n            The output of the decoder. Shape is (batch_size, length, C_out)\n        step_additional_outputs : list\n            Either be an empty list or contains the attention weights in this step.\n            The attention weights will have shape (batch_size, length, mem_length) or\n            (batch_size, num_heads, length, mem_length)\n\n        \"\"\"\n        has_mem_mask = (len(states) == 3)\n        if has_mem_mask:\n            mem_value, mem_mask, steps = states\n        else:\n            mem_value, steps = states\n            mem_mask = None\n        # Positional Encoding\n        step_input = F.broadcast_add(step_input,\n                                     F.expand_dims(F.Embedding(steps,\n                                                               position_weight,\n                                                               self._max_length,\n                                                               self._units),\n                                                   axis=0))\n        if self._dropout:\n            step_input = self.dropout_layer(step_input)\n        step_input = self.layer_norm(step_input)\n        inputs = step_input\n        outputs = inputs\n        step_additional_outputs = []\n        attention_weights_l = []\n        for cell in self.transformer_cells:\n            outputs, attention_weights = cell(inputs, mem_value, mask, mem_mask)\n            if self._output_attention:\n                attention_weights_l.append(attention_weights)\n            inputs = outputs\n        if self._output_attention:\n            step_additional_outputs.extend(attention_weights_l)\n        return outputs, step_additional_outputs",
            "file_path": "commits/57a45aaf7e82a826e1bffb133c328f913844bd4c/Before/src#gluonnlp#model#transformer.py"
        },
        "refactored_code": {
            "source_code": "def hybrid_forward(self, F, inputs, states, valid_length=None, position_weight=None):\n        #pylint: disable=arguments-differ\n        \"\"\"Decode the decoder inputs. This function is only used for training.\n\n        Parameters\n        ----------\n        inputs : NDArray, Shape (batch_size, length, C_in)\n        states : list of NDArrays or None\n            Initial states. The list of decoder states\n        valid_length : NDArray or None\n            Valid lengths of each sequence. This is usually used when part of sequence has\n            been padded. Shape (batch_size,)\n\n        Returns\n        -------\n        output : NDArray, Shape (batch_size, length, C_out)\n        states : list\n            The decoder states:\n            - mem_value : NDArray\n            - mem_masks : NDArray or None\n        additional_outputs : list of list\n            Either be an empty list or contains the attention weights in this step.\n            The attention weights will have shape (batch_size, length, mem_length) or\n            (batch_size, num_heads, length, mem_length)\n        \"\"\"\n\n        length_array = F.contrib.arange_like(inputs, axis=1)\n        mask = F.broadcast_lesser_equal(length_array.reshape((1, -1)),\n                                        length_array.reshape((-1, 1)))\n        if valid_length is not None:\n            batch_mask = F.broadcast_lesser(length_array.reshape((1, -1)),\n                                            valid_length.reshape((-1, 1)))\n            batch_mask = F.expand_dims(batch_mask, -1)\n            mask = F.broadcast_mul(batch_mask, F.expand_dims(mask, 0))\n        else:\n            mask = F.expand_dims(mask, axis=0)\n            mask = F.broadcast_like(mask, inputs, lhs_axes=(0, ), rhs_axes=(0, ))\n\n        mem_value, mem_mask = states\n        if mem_mask is not None:\n            mem_mask = F.expand_dims(mem_mask, axis=1)\n            mem_mask = F.broadcast_like(mem_mask, inputs, lhs_axes=(1, ), rhs_axes=(1, ))\n\n        if self._scale_embed:\n            # XXX: input.shape[-1] and self._units are expected to be the same\n            inputs = inputs * math.sqrt(self._units)\n\n        # Positional Encoding\n        steps = F.contrib.arange_like(inputs, axis=1)\n        positional_embed = F.Embedding(steps, position_weight, self._max_length, self._units)\n        inputs = F.broadcast_add(inputs, F.expand_dims(positional_embed, axis=0))\n\n        if self._dropout:\n            inputs = self.dropout_layer(inputs)\n        inputs = self.layer_norm(inputs)\n        additional_outputs = []\n        attention_weights_l = []\n        outputs = inputs\n        for cell in self.transformer_cells:\n            outputs, attention_weights = cell(outputs, mem_value, mask, mem_mask)\n            if self._output_attention:\n                attention_weights_l.append(attention_weights)\n        if self._output_attention:\n            additional_outputs.extend(attention_weights_l)\n\n        if valid_length is not None:\n            outputs = F.SequenceMask(outputs, sequence_length=valid_length,\n                                     use_sequence_length=True, axis=1)\n        return outputs, states, additional_outputs",
            "file_path": "commits/57a45aaf7e82a826e1bffb133c328f913844bd4c/After/src#gluonnlp#model#transformer.py"
        },
        "original_variable_name": "step_input",
        "new_variable_name": "inputs",
        "label": "negative",
        "id": "80679308-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5714
    },
    {
        "commit_hash": "6887ad8bac178483b7debcefa1c52de979ec0085",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def __repr__(self):\n        formatted_props = ['{!r}'.format(arg) for arg in self.args]\n        formatted_props += ['{}={!r}'.format(key, self.kwargs[key]) for key in sorted(self.kwargs)]\n        return '{}({}) <{}>'.format(self.name, ', '.join(formatted_props), self.short_hash)",
            "file_path": "commits/6887ad8bac178483b7debcefa1c52de979ec0085/Before/ffmpeg#dag.py"
        },
        "refactored_code": {
            "source_code": "def long_repr(self, include_hash=True):\n        formatted_props = ['{!r}'.format(arg) for arg in self.args]\n        formatted_props += ['{}={!r}'.format(key, self.kwargs[key]) for key in sorted(self.kwargs)]\n        out = '{}({})'.format(self.name, ', '.join(formatted_props))\n        if include_hash:\n            out += ' <{}>'.format(self.short_hash)\n        return out",
            "file_path": "commits/6887ad8bac178483b7debcefa1c52de979ec0085/After/ffmpeg#dag.py"
        },
        "variable_name": "out",
        "label": "positive",
        "id": "8069bcdc-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 971
    },
    {
        "commit_hash": "a124edcd95c1dcc16070e16244fdfcba6be169e3",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "compute_reward",
            "container_name": "ReacherEnv",
            "source_code": "def compute_reward(self, achieved_goal, goal, info):\n        # Compute distance between goal and the achieved goal.\n        d = self._goal_distance(achieved_goal, goal)\n        if self._sparse_reward:\n            reward = -(d > self._distance_threshold).astype(np.float32)\n        else:\n            reward = -d\n\n        if d < self._distance_threshold:\n            reward += 500  # Completion\n        return reward",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#reacher_env.py"
        },
        "inlined_method": {
            "name": "_goal_distance",
            "container_name": "ReacherEnv",
            "source_code": "def _goal_distance(goal_a, goal_b):\n        \"\"\"\n        Calculate the distance between two goals.\n\n        :param goal_a: first goal.\n        :param goal_b: second goal.\n        :return: distance between goal a and b.\n        \"\"\"\n        assert goal_a.shape == goal_b.shape\n        return np.linalg.norm(goal_a - goal_b, axis=-1)",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#reacher_env.py"
        },
        "caller": {
            "name": "compute_reward",
            "container_name": "ReacherEnv",
            "source_code": "def compute_reward(self, achieved_goal, desired_goal, info: dict):\n        d = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n        if self._reward_type == 'sparse':\n            return (d < self._distance_threshold).astype(np.float32)\n\n        return .01 - d",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/After/garage#envs#mujoco#sawyer#reacher_env.py"
        },
        "label": "positive",
        "id": "805edd58-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1699
    },
    {
        "commit_hash": "cc4a397586c6dc8c2de95773572bf3ab318a8371",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def get_rnn_cell(hparams=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['cell']['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=utils.switch_dropout(d_hp[\"input_keep_prob\"]),\n                output_keep_prob=utils.switch_dropout(d_hp[\"output_keep_prob\"]),\n                state_keep_prob=utils.switch_dropout(d_hp[\"state_keep_prob\"]),\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/Before/texar#core#layers.py"
        },
        "refactored_code": {
            "source_code": "def get_rnn_cell(hparams=None, mode=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n        mode (optional): A member of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n            `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n            controlled by :func:`texar.context.global_mode`.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            input_keep_prob = utils.switch_dropout(d_hp[\"input_keep_prob\"],\n                                                   mode)\n            output_keep_prob = utils.switch_dropout(d_hp[\"output_keep_prob\"],\n                                                    mode)\n            state_keep_prob = utils.switch_dropout(d_hp[\"state_keep_prob\"],\n                                                   mode)\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=input_keep_prob,\n                output_keep_prob=output_keep_prob,\n                state_keep_prob=state_keep_prob,\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/After/texar#core#layers.py"
        },
        "variable_name": "output_keep_prob",
        "label": "positive",
        "id": "8069ba52-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 7612
    },
    {
        "commit_hash": "55f6f1ab292abe7a10a93982fa6df48f8d4c4854",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "perturbation",
            "container_name": "aitchison",
            "source_code": "def perturbation(x, dx):\n    \"\"\"Returns the perturbation of `x` by `dx`.\n\n    Perturbation is the closure of the element-wise product. It is equivalent\n    to translation (inner sum) in standard Euclidean space.\n\n    Parameters\n    ----------\n    x : NumPy array, shape (n,) or (k,n)\n        The composition (or k compositions) to be perturbed.\n    dx : NumPy array\n        The perturbation composition or (k perturbation compositions).\n\n    Returns\n    -------\n    px : NumPy array, shape (n,) or (k,n)\n        The perturbation of `x` by `dx`.\n\n    \"\"\"\n    if len(x.shape) == 1:\n        single = True\n    else:\n        single = False\n\n    x = np.atleast_2d(x)\n    dx = np.atleast_2d(dx)\n    px = _closure(x * dx)\n\n    if single:\n        px = px[0]\n\n    return px"
        },
        "original_method_after_refactoring": {
            "name": "perturbation",
            "container_name": "aitchison",
            "source_code": "def perturbation(x, dx):\n    \"\"\"Returns the perturbation of `x` by `dx`.\n\n    Perturbation is the closure of the element-wise product. It is equivalent\n    to translation (inner sum) in standard Euclidean space.\n\n    Parameters\n    ----------\n    x : NumPy array, shape (n,) or (k,n)\n        The composition (or k compositions) to be perturbed.\n    dx : NumPy array\n        The perturbation composition or (k perturbation compositions).\n\n    Returns\n    -------\n    px : NumPy array, shape (n,) or (k,n)\n        The perturbation of `x` by `dx`.\n\n    \"\"\"\n    px = closure(x * dx)\n\n    return px"
        },
        "newly_extracted_method": {
            "name": "power",
            "container_name": "aitchison",
            "source_code": "def power(x, a):\n    \"\"\"Returns the result of powering `x` by `a`.\n\n    The power transformation is the closure of raising each element to the\n    `a`th power. It is equivalent to scalar multiplication (outer product).\n\n    Parameters\n    ----------\n    x : NumPy array, shape (n,) or (k,n)\n        The composition (or k compositions) which will be powered.\n    a : NumPy array, shape () or (k,)\n        The power (or k powers) to which the composition(s) is raised.\n\n    Returns\n    -------\n    px : NumPy array, shape (n,) or (k,n)\n        The result of powering `x` by `a`.\n\n    \"\"\"\n    a = np.ravel(a)[..., np.newaxis]\n    px = closure(x**a)\n    if len(x.shape) == 1:\n        px = px[0]\n\n    return px"
        },
        "label": "negative",
        "id": "805bfd36-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2450
    },
    {
        "commit_hash": "8693c776ce2822ae96f81990dc3c434e311ce624",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "eval_metric",
            "container_name": "_RankingLoss",
            "source_code": "def eval_metric(self, labels, logits, weights):\n    \"\"\"Computes the eval metric for the loss in tf.estimator (not tf.keras).\n\n    Note that this function is not compatible with keras.\n\n    Args:\n      labels: A `Tensor` of the same shape as `logits` representing graded\n        relevance.\n      logits: A `Tensor` with shape [batch_size, list_size]. Each value is the\n        ranking score of the corresponding item.\n      weights: A scalar, a `Tensor` with shape [batch_size, 1] for list-wise\n        weights, or a `Tensor` with shape [batch_size, list_size] for item-wise\n        weights.\n\n    Returns:\n      A metric op.\n    \"\"\"\n    losses, weights = self.eval_metric_unreduced(labels, logits, weights)\n    return tf.compat.v1.metrics.mean(losses, weights)",
            "file_path": "commits/8693c776ce2822ae96f81990dc3c434e311ce624/Before/tensorflow_ranking#python#losses_impl.py"
        },
        "inlined_method": {
            "name": "eval_metric_unreduced",
            "container_name": "_RankingLoss",
            "source_code": "def eval_metric_unreduced(self, labels, logits, weights):\n    \"\"\"Computes the unreduced eval metric for the loss.\n\n    Args:\n      labels: A `Tensor` of the same shape as `logits` representing graded\n        relevance.\n      logits: A `Tensor` with shape [batch_size, list_size]. Each value is the\n        ranking score of the corresponding item.\n      weights: A scalar, a `Tensor` with shape [batch_size, 1] for list-wise\n        weights, or a `Tensor` with shape [batch_size, list_size] for item-wise\n        weights.\n\n    Returns:\n      A pair of `Tensor` objects containing losses and weights for use in\n      a weighted average.\n    \"\"\"\n    losses, loss_weights = self.compute_unreduced_loss(labels, logits)\n    weights = tf.multiply(self.normalize_weights(labels, weights), loss_weights)\n    return losses, weights",
            "file_path": "commits/8693c776ce2822ae96f81990dc3c434e311ce624/Before/tensorflow_ranking#python#losses_impl.py"
        },
        "caller": {
            "name": "eval_metric",
            "container_name": "_RankingLoss",
            "source_code": "def eval_metric(self, labels, logits, weights):\n    \"\"\"Computes the eval metric for the loss in tf.estimator (not tf.keras).\n\n    Note that this function is not compatible with keras.\n\n    Args:\n      labels: A `Tensor` of the same shape as `logits` representing graded\n        relevance.\n      logits: A `Tensor` with shape [batch_size, list_size]. Each value is the\n        ranking score of the corresponding item.\n      weights: A scalar, a `Tensor` with shape [batch_size, 1] for list-wise\n        weights, or a `Tensor` with shape [batch_size, list_size] for item-wise\n        weights.\n\n    Returns:\n      A metric op.\n    \"\"\"\n    losses, loss_weights = self.compute_unreduced_loss(labels, logits)\n    weights = tf.multiply(self.normalize_weights(labels, weights), loss_weights)\n    return tf.compat.v1.metrics.mean(losses, weights)",
            "file_path": "commits/8693c776ce2822ae96f81990dc3c434e311ce624/After/tensorflow_ranking#python#losses_impl.py"
        },
        "label": "positive",
        "id": "805ede02-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3143
    },
    {
        "commit_hash": "4850f1e47db0e2ee9b881e92a5bb6e873f12b417",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "log_prob",
            "container_name": "HIS",
            "source_code": "def log_prob(self, data, num_samples=1):\n    batch_shape = tf.shape(data)[0:-1]\n    reshaped_data = tf.reshape(\n        data, [tf.math.reduce_prod(batch_shape), self.data_dim])\n    log_prob = self._log_prob(reshaped_data, num_samples=num_samples)\n    log_prob = tf.reshape(log_prob, batch_shape)\n    return log_prob",
            "file_path": "commits/4850f1e47db0e2ee9b881e92a5bb6e873f12b417/Before/eim#models#his.py"
        },
        "inlined_method": {
            "name": "_log_prob",
            "container_name": "HIS",
            "source_code": "def _log_prob(self, x_final, num_samples=1):\n    \"\"\"Compute log probability.\n\n    Args:\n      x_final: [batch_size, data_dims] tensor.\n      num_samples: Optional number of samples to compute bounds.\n    Returns:\n      log probability lower bound.\n    \"\"\"\n    q = self.q(x_final)\n    rho_final = q.sample([num_samples])  # [num_samples, batch_size, data_dim]\n    x_final = tf.tile(x_final[tf.newaxis, :, :], [num_samples, 1, 1])\n\n    x_0, rho_0 = self._reverse_hamiltonian_dynamics(x_final, rho_final)\n    elbo = (\n        self.proposal.log_prob(x_0) + self.momentum_proposal.log_prob(rho_0) -\n        q.log_prob(rho_final))\n    return tf.reduce_logsumexp(elbo, axis=0) - tf.log(tf.to_float(num_samples))",
            "file_path": "commits/4850f1e47db0e2ee9b881e92a5bb6e873f12b417/Before/eim#models#his.py"
        },
        "caller": {
            "name": "log_prob",
            "container_name": "HIS",
            "source_code": "def log_prob(self, x_final, num_samples=1):\n    \"\"\"Compute log probability lower bound on x_final.\n\n    Args:\n      x_final: [batch_size] + data_dim tensor.\n      num_samples: Optional number of samples to compute bounds.\n    Returns:\n      log probability lower bound.\n    \"\"\"\n    tiled_x_final = tf.tile(x_final, [num_samples] + [1] * len(self.data_dim))\n    q = self.q(tiled_x_final)\n    rho_final = q.sample()  # [num_samples * batch_size, data_dim]\n\n    x_0, rho_0 = self._reverse_hamiltonian_dynamics(tiled_x_final, rho_final)\n    elbo = (\n        self.proposal.log_prob(x_0) + self.momentum_proposal.log_prob(rho_0) -\n        q.log_prob(rho_final))\n    iwae = (tf.reduce_logsumexp(tf.reshape(elbo, [num_samples, -1]), axis=0)\n            - tf.log(tf.to_float(num_samples)))\n    return iwae",
            "file_path": "commits/4850f1e47db0e2ee9b881e92a5bb6e873f12b417/After/eim#models#his.py"
        },
        "label": "negative",
        "id": "805edb6e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2416
    },
    {
        "commit_hash": "e24661a1aa2a86a6e69877c91a3c6803d78b3c22",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_pca_decomposition_quick_method(self):\n        \"\"\"\n        Test the quick method PCADecomposition visualizer 2 dimensions scaled.\n        \"\"\"\n        ax = pca_decomposition(\n            X=self.dataset.X, proj_dim=2, scale=True, random_state=28\n        )\n        self.assert_images_similar(ax=ax, tol=5)",
            "file_path": "commits/e24661a1aa2a86a6e69877c91a3c6803d78b3c22/Before/tests#test_features#test_pca.py"
        },
        "refactored_code": {
            "source_code": "def test_pca_decomposition_quick_method(self):\n        \"\"\"\n        Test the quick method PCA visualizer 2 dimensions scaled.\n        \"\"\"\n        visualizer = pca_decomposition(*self.binary, projection=2, scale=True, random_state=28)\n        self.assert_images_similar(visualizer)",
            "file_path": "commits/e24661a1aa2a86a6e69877c91a3c6803d78b3c22/After/tests#test_features#test_pca.py"
        },
        "original_variable_name": "ax",
        "new_variable_name": "visualizer",
        "label": "positive",
        "id": "80679a88-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 957
    },
    {
        "commit_hash": "c587e0e36a829cbd2133adeb5f20c1874f32880b",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "serialize_forward_msg",
            "container_name": "server_util",
            "source_code": "def serialize_forward_msg(msg):\n    \"\"\"Serialize a ForwardMsg to send to a client.\n\n    If the message is too large, it will be converted to an exception message\n    instead.\n\n    Parameters\n    ----------\n    msg : ForwardMsg\n        The message to serialize\n\n    Returns\n    -------\n    str\n        The serialized byte string to send\n\n    \"\"\"\n    populate_hash_if_needed(msg)\n    msg_str = msg.SerializeToString()\n\n    if len(msg_str) > MESSAGE_SIZE_LIMIT:\n        _convert_msg_to_exception_msg(msg, RuntimeError(\"Data too large\"))\n        msg_str = msg.SerializeToString()\n\n    return msg_str",
            "file_path": "commits/c587e0e36a829cbd2133adeb5f20c1874f32880b/Before/lib#streamlit#server#server_util.py"
        },
        "inlined_method": {
            "name": "_convert_msg_to_exception_msg",
            "container_name": "server_util",
            "source_code": "def _convert_msg_to_exception_msg(msg, e):\n    import streamlit.elements.exception_proto as exception_proto\n\n    delta_id = msg.metadata.delta_id\n    msg.Clear()\n    msg.metadata.delta_id = delta_id\n\n    exception_proto.marshall(msg.delta.new_element.exception, e)",
            "file_path": "commits/c587e0e36a829cbd2133adeb5f20c1874f32880b/Before/lib#streamlit#server#server_util.py"
        },
        "caller": {
            "name": "serialize_forward_msg",
            "container_name": "server_util",
            "source_code": "def serialize_forward_msg(msg):\n    \"\"\"Serialize a ForwardMsg to send to a client.\n\n    If the message is too large, it will be converted to an exception message\n    instead.\n\n    Parameters\n    ----------\n    msg : ForwardMsg\n        The message to serialize\n\n    Returns\n    -------\n    str\n        The serialized byte string to send\n\n    \"\"\"\n    populate_hash_if_needed(msg)\n    msg_str = msg.SerializeToString()\n\n    if len(msg_str) > MESSAGE_SIZE_LIMIT:\n        import streamlit.elements.exception_proto as exception_proto\n\n        error = RuntimeError(\n            f\"Data of size {len(msg_str)/1e6:.1f}MB exceeds write limit of {MESSAGE_SIZE_LIMIT/1e6}MB\"\n        )\n        # Overwrite the offending ForwardMsg.delta with an error to display.\n        # This assumes that the size limit wasn't exceeded due to metadata.\n        exception_proto.marshall(msg.delta.new_element.exception, error)\n        msg_str = msg.SerializeToString()\n\n    return msg_str",
            "file_path": "commits/c587e0e36a829cbd2133adeb5f20c1874f32880b/After/lib#streamlit#server#server_util.py"
        },
        "label": "positive",
        "id": "805edf92-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2564
    },
    {
        "commit_hash": "514b7f7c52d7231f1a3615819b1adb237de73004",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "test_guided_grad_modifier",
            "container_name": "test_backend",
            "source_code": "def test_guided_grad_modifier():\n    # Only test tensorflow implementation for now.\n    if K.backend() == 'theano':\n        return\n\n    # Create a simple linear sequence x -> linear(w1.x)\n    inp = Input(shape=(1, ))\n    out = Dense(1, activation='linear', use_bias=False, kernel_initializer=Constant(-1.))(inp)\n    model = Model(inp, out)\n\n    # Original model gradient is negative but the modified model should clip it.\n    assert _compute_grads(model, 1.) == -1\n\n    # Modified model should clip negative gradients.\n    modified_model = modify_model_backprop(model, 'guided')\n    assert _compute_grads(modified_model, 1.) == 0\n\n    # Ensure that the original model reference remains unchanged.\n    assert model.layers[1].activation == get('linear')\n    assert modified_model.layers[1].activation == get('relu')",
            "file_path": "commits/514b7f7c52d7231f1a3615819b1adb237de73004/Before/tests#vis#backend#test_backend.py"
        },
        "inlined_method": {
            "name": "test_rectified_grad_modifier",
            "container_name": "test_backend",
            "source_code": "def test_rectified_grad_modifier():\n    # Only test tensorflow implementation for now.\n    if K.backend() == 'theano':\n        return\n\n    # Create a simple model y = linear(w.x) where w = 1\n    inp = Input(shape=(1, ))\n    out = Dense(1, activation='linear', use_bias=False, kernel_initializer=Constant(-1.))(inp)\n    model = Model(inp, out)\n\n    # Original model gradient is negative but the modified model should clip it.\n    assert _compute_grads(model, 1.) == -1\n\n    # Modified model should clip negative gradients.\n    modified_model = modify_model_backprop(model, 'rectified')\n    assert _compute_grads(modified_model, 1.) == 0\n\n    # Ensure that the original model reference remains unchanged.\n    assert model.layers[1].activation == get('linear')\n    assert modified_model.layers[1].activation == get('relu')",
            "file_path": "commits/514b7f7c52d7231f1a3615819b1adb237de73004/Before/tests#vis#backend#test_backend.py"
        },
        "caller": {
            "name": "test_guided_grad_modifier",
            "container_name": "test_backend",
            "source_code": "def test_guided_grad_modifier():\n    # Only test tensorflow implementation for now.\n    if K.backend() == 'theano':\n        return\n\n    # Create a simple linear sequence x -> linear(w.x) with weights w1 = -1, w2 = 1.\n    inp = Input(shape=(2, ))\n    out = Dense(1, activation='linear', use_bias=False, kernel_initializer=Constant([-1., 1.]))(inp)\n    model = Model(inp, out)\n\n    # Original model gradient should be [w1, w2]\n    assert np.array_equal(_compute_grads(model, [1., -1.]), [-1., 1.])\n\n    # Original gradient is [-1, 1] but new gradient should be [0, 0]\n    # First one is clipped because of negative gradient while the second is clipped due to negative input.\n    modified_model = modify_model_backprop(model, 'guided')\n    assert np.array_equal(_compute_grads(modified_model, [1., -1.]), [0., 0.])\n\n    # Ensure that the original model reference remains unchanged.\n    assert model.layers[1].activation == get('linear')\n    assert modified_model.layers[1].activation == get('relu')",
            "file_path": "commits/514b7f7c52d7231f1a3615819b1adb237de73004/After/tests#vis#backend#test_backend.py"
        },
        "label": "negative",
        "id": "805ee0a0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3372
    },
    {
        "commit_hash": "25aec3291e63d54ad3f71b9ba95f9d5b9132793f",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "__init__",
            "container_name": "KernelCovariance",
            "source_code": "def __init__(self, xe, *, jacobian=None, inv_jacobian=None,\n                 kernel='bartlett', bandwidth=None, center=True,\n                 debiased=False, df=0):\n        super(KernelCovariance, self).__init__(xe, jacobian=jacobian,\n                                               inv_jacobian=inv_jacobian,\n                                               center=center,\n                                               debiased=debiased, df=df)\n        self._kernel = kernel.lower()\n        if self._kernel not in KERNEL_LOOKUP:\n            raise ValueError('Unknown kernel')\n        self._bandwidth = bandwidth\n        if bandwidth is not None:\n            if bandwidth < 0:\n                raise ValueError('bandwidth must be non-negative.')",
            "file_path": "commits/25aec3291e63d54ad3f71b9ba95f9d5b9132793f/Before/linearmodels#asset_pricing#covariance.py"
        },
        "inlined_method": {
            "name": "bandwidth",
            "container_name": "KernelCovariance",
            "source_code": "def bandwidth(self):\n        \"\"\"Bandwidth used in estimation\"\"\"\n        if self._bandwidth is None:\n            xe = self._xe\n            x = xe / xe.std(0)[None, :]\n            x = x.sum(1)\n            bw = kernel_optimal_bandwidth(x, kernel=self.kernel)\n            self._bandwidth = int(bw)\n\n        return self._bandwidth",
            "file_path": "commits/25aec3291e63d54ad3f71b9ba95f9d5b9132793f/Before/linearmodels#asset_pricing#covariance.py"
        },
        "caller": {
            "name": "__init__",
            "container_name": "KernelCovariance",
            "source_code": "def __init__(self, xe, *, jacobian=None, inv_jacobian=None,\n                 kernel='bartlett', bandwidth=None, center=True,\n                 debiased=False, df=0):\n        super(KernelCovariance, self).__init__(xe, jacobian=jacobian,\n                                               inv_jacobian=inv_jacobian,\n                                               center=center,\n                                               debiased=debiased, df=df)\n        self._check_kernel(kernel)\n        self._check_bandwidth(bandwidth)",
            "file_path": "commits/25aec3291e63d54ad3f71b9ba95f9d5b9132793f/After/linearmodels#asset_pricing#covariance.py"
        },
        "label": "positive",
        "id": "805edc04-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2283
    },
    {
        "commit_hash": "be65ce986a45bf2f35b5494db3fa6e993b905aeb",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def DSIN(feature_dim_dict, sess_feature_list, embedding_size=8, sess_max_count=5, sess_len_max=10, bias_encoding=False,\n         att_embedding_size=1, att_head_num=8, dnn_hidden_units=(200, 80), dnn_activation='sigmoid', dnn_dropout=0,\n         dnn_use_bn=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, init_std=0.0001, seed=1024, task='binary',\n         ):\n    \"\"\"Instantiates the Deep Session Interest Network architecture.\n\n    :param feature_dim_dict: dict,to indicate sparse field (**now only support sparse feature**)like {'sparse':{'field_1':4,'field_2':3,'field_3':2},'dense':[]}\n    :param sess_feature_list: list,to indicate session feature sparse field (**now only support sparse feature**),must be a subset of ``feature_dim_dict[\"sparse\"]``\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param sess_max_count: positive int, to indicate the max number of sessions\n    :param sess_len_max: positive int, to indicate the max length of each session\n    :param bias_encoding: bool. Whether use bias encoding or postional encoding\n    :param att_embedding_size: positive int, the embedding size of each attention head\n    :param att_head_num: positive int, the number of attention head\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param dnn_activation: Activation function to use in deep net\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n    check_feature_config_dict(feature_dim_dict)\n\n    if (att_embedding_size * att_head_num != len(sess_feature_list) * embedding_size):\n        raise ValueError(\n            \"len(session_feature_lsit) * embedding_size must equal to att_embedding_size * att_head_num ,got %d * %d != %d *%d\" % (\n            len(sess_feature_list), embedding_size, att_embedding_size, att_head_num))\n\n    sparse_input, dense_input, user_behavior_input_dict, _, user_sess_length = get_input(\n        feature_dim_dict, sess_feature_list, sess_max_count, sess_len_max)\n\n    sparse_embedding_dict = {feat.name: Embedding(feat.dimension, embedding_size,\n                                                  embeddings_initializer=RandomNormal(\n                                                      mean=0.0, stddev=init_std, seed=seed),\n                                                  embeddings_regularizer=l2(\n                                                      l2_reg_embedding),\n                                                  name='sparse_emb_' +\n                                                       str(i) + '-' + feat.name,\n                                                  mask_zero=(feat.name in sess_feature_list)) for i, feat in\n                             enumerate(feature_dim_dict[\"sparse\"])}\n\n    query_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_dim_dict[\"sparse\"],\n                                            sess_feature_list, sess_feature_list)\n\n    query_emb = concat_fun(query_emb_list)\n\n    deep_input_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_dim_dict[\"sparse\"],\n                                                 mask_feat_list=sess_feature_list)\n    deep_input_emb = concat_fun(deep_input_emb_list)\n    deep_input_emb = Flatten()(NoMask()(deep_input_emb))\n\n    tr_input = sess_interest_division(sparse_embedding_dict, user_behavior_input_dict, feature_dim_dict['sparse'],\n                                      sess_feature_list, sess_max_count, bias_encoding=bias_encoding)\n\n    Self_Attention = Transformer(att_embedding_size, att_head_num, dropout_rate=0, use_layer_norm=False,\n                                 use_positional_encoding=(not bias_encoding), seed=seed, supports_masking=True,\n                                 blinding=True)\n    sess_fea = sess_interest_extractor(\n        tr_input, sess_max_count, Self_Attention)\n\n    interest_attention_layer = AttentionSequencePoolingLayer(att_hidden_units=(64, 16), weight_normalization=True,\n                                                             supports_masking=False)(\n        [query_emb, sess_fea, user_sess_length])\n\n    lstm_outputs = BiLSTM(len(sess_feature_list) * embedding_size,\n                          layers=2, res_layers=0, dropout_rate=0.2, )(sess_fea)\n    lstm_attention_layer = AttentionSequencePoolingLayer(att_hidden_units=(64, 16), weight_normalization=True)(\n        [query_emb, lstm_outputs, user_sess_length])\n\n    deep_input_emb = Concatenate()(\n        [deep_input_emb, Flatten()(interest_attention_layer), Flatten()(lstm_attention_layer)])\n    if len(dense_input) > 0:\n        deep_input_emb = Concatenate()(\n            [deep_input_emb] + list(dense_input.values()))\n\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, dnn_use_bn, seed)(deep_input_emb)\n    output = Dense(1, use_bias=False, activation=None)(output)\n    output = PredictionLayer(task)(output)\n\n    sess_input_list = []\n    # sess_input_length_list = []\n    for i in range(sess_max_count):\n        sess_name = \"sess_\" + str(i)\n        sess_input_list.extend(get_inputs_list(\n            [user_behavior_input_dict[sess_name]]))\n        # sess_input_length_list.append(user_behavior_length_dict[sess_name])\n\n    model_input_list = get_inputs_list([sparse_input, dense_input]) + sess_input_list + [\n        user_sess_length]\n\n    model = Model(inputs=model_input_list, outputs=output)\n\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/Before/deepctr#models#dsin.py"
        },
        "refactored_code": {
            "source_code": "def DSIN(dnn_feature_columns, sess_feature_list, embedding_size=8, sess_max_count=5, sess_len_max=10, bias_encoding=False,\n         att_embedding_size=1, att_head_num=8, dnn_hidden_units=(200, 80), dnn_activation='sigmoid', dnn_dropout=0,\n         dnn_use_bn=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, init_std=0.0001, seed=1024, task='binary',\n         ):\n    \"\"\"Instantiates the Deep Session Interest Network architecture.\n\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.    :param sess_feature_list: list,to indicate session feature sparse field (**now only support sparse feature**),must be a subset of ``feature_dim_dict[\"sparse\"]``\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param sess_max_count: positive int, to indicate the max number of sessions\n    :param sess_len_max: positive int, to indicate the max length of each session\n    :param bias_encoding: bool. Whether use bias encoding or postional encoding\n    :param att_embedding_size: positive int, the embedding size of each attention head\n    :param att_head_num: positive int, the number of attention head\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param dnn_activation: Activation function to use in deep net\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n    #check_feature_config_dict(dnn_feature_columns)\n\n    if (att_embedding_size * att_head_num != len(sess_feature_list) * embedding_size):\n        raise ValueError(\n            \"len(session_feature_lsit) * embedding_size must equal to att_embedding_size * att_head_num ,got %d * %d != %d *%d\" % (\n            len(sess_feature_list), embedding_size, att_embedding_size, att_head_num))\n\n    # sparse_input, dense_input, user_behavior_input_dict, _, user_sess_length = get_input(\n    #     dnn_feature_columns, sess_feature_list, sess_max_count, sess_len_max)\n\n    # def get_input(feature_dim_dict, seq_feature_list, sess_max_count, seq_max_len):\n    #     sparse_input, dense_input = build_input_features(feature_dim_dict)\n    #     user_behavior_input = {}\n    #     for idx in range(sess_max_count):\n    #         sess_input = OrderedDict()\n    #         for i, feat in enumerate(seq_feature_list):\n    #             sess_input[feat] = Input(\n    #                 shape=(seq_max_len,), name='seq_' + str(idx) + str(i) + '-' + feat)\n    #\n    #         user_behavior_input[\"sess_\" + str(idx)] = sess_input\n    #\n    #     user_behavior_length = {\"sess_\" + str(idx): Input(shape=(1,), name='seq_length' + str(idx)) for idx in\n    #                             range(sess_max_count)}\n    #     user_sess_length = Input(shape=(1,), name='sess_length')\n    #\n    #     return sparse_input, dense_input, user_behavior_input, user_behavior_length, user_sess_length\n\n\n    features = build_input_features(dnn_feature_columns)\n\n    sparse_feature_columns = list(filter(lambda x:isinstance(x,SparseFeat),dnn_feature_columns)) if dnn_feature_columns else []\n    dense_feature_columns = list(\n        filter(lambda x: isinstance(x, DenseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n\n\n    history_feature_columns = []\n    sparse_varlen_feature_columns = []\n    history_fc_names = list(map(lambda x: \"sess\" + x, sess_feature_list))\n    #user_behavior_input_dict = {\"sess_\"+str(i):{} for i in range(sess_max_count)}\n    for fc in varlen_sparse_feature_columns:\n        feature_name = fc.name\n        if feature_name in history_fc_names:\n            continue\n            #history_feature_columns.append(fc)\n        else:\n            sparse_varlen_feature_columns.append(fc)\n\n\n    inputs_list = list(features.values())\n\n\n    user_behavior_input_dict = {}\n    for idx in range(sess_max_count):\n        sess_input = OrderedDict()\n        for i, feat in enumerate(sess_feature_list):\n            sess_input[feat] = features[\"sess_\"+str(idx)+\"_\"+feat]\n                #Input(shape=(seq_max_len,), name='seq_' + str(idx) + str(i) + '-' + feat)\n\n        user_behavior_input_dict[\"sess_\" + str(idx)] = sess_input\n\n\n    #user_behavior_length = {\"sess_\" + str(idx): Input(shape=(1,), name='seq_length' + str(idx)) for idx in\n    #                            range(sess_max_count)}\n    user_sess_length = Input(shape=(1,), name='sess_length')\n\n\n\n    embedding_dict = {feat.embedding_name: Embedding(feat.dimension, embedding_size,\n                                                  embeddings_initializer=RandomNormal(\n                                                      mean=0.0, stddev=init_std, seed=seed),\n                                                  embeddings_regularizer=l2(\n                                                      l2_reg_embedding),\n                                                  name='sparse_emb_' +\n                                                       str(i) + '-' + feat.name,\n                                                  mask_zero=(feat.name in sess_feature_list)) for i, feat in\n                             enumerate(sparse_feature_columns)}\n\n\n\n    query_emb_list = embedding_lookup(embedding_dict,features,sparse_feature_columns,sess_feature_list,sess_feature_list)#query\u662f\u5355\u72ec\u7684\n    keys_emb_list = embedding_lookup(embedding_dict, features, history_feature_columns, history_fc_names, history_fc_names)\n    dnn_input_emb_list = embedding_lookup(embedding_dict,features,sparse_feature_columns,mask_feat_list=sess_feature_list)\n    dense_value_list = get_dense_input(features, dense_feature_columns)\n\n\n\n\n    #query_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, dnn_feature_columns[\"sparse\"],\n    #                                        sess_feature_list, sess_feature_list)\n\n    query_emb = concat_fun(query_emb_list)\n\n    #dnn_input_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, dnn_feature_columns[\"sparse\"],\n    #                                             mask_feat_list=sess_feature_list)\n    dnn_input_emb = concat_fun(dnn_input_emb_list)\n    dnn_input_emb = Flatten()(NoMask()(dnn_input_emb))\n\n    tr_input = sess_interest_division(embedding_dict, user_behavior_input_dict, sparse_feature_columns,\n                                      sess_feature_list, sess_max_count, bias_encoding=bias_encoding)\n\n    Self_Attention = Transformer(att_embedding_size, att_head_num, dropout_rate=0, use_layer_norm=False,\n                                 use_positional_encoding=(not bias_encoding), seed=seed, supports_masking=True,\n                                 blinding=True)\n    sess_fea = sess_interest_extractor(\n        tr_input, sess_max_count, Self_Attention)\n\n    interest_attention_layer = AttentionSequencePoolingLayer(att_hidden_units=(64, 16), weight_normalization=True,\n                                                             supports_masking=False)(\n        [query_emb, sess_fea, user_sess_length])\n\n    lstm_outputs = BiLSTM(len(sess_feature_list) * embedding_size,\n                          layers=2, res_layers=0, dropout_rate=0.2, )(sess_fea)\n    lstm_attention_layer = AttentionSequencePoolingLayer(att_hidden_units=(64, 16), weight_normalization=True)(\n        [query_emb, lstm_outputs, user_sess_length])\n\n    dnn_input_emb = Concatenate()(\n        [dnn_input_emb, Flatten()(interest_attention_layer), Flatten()(lstm_attention_layer)])\n    # if len(dense_input) > 0:\n    #     deep_input_emb = Concatenate()(\n    #         [deep_input_emb] + list(dense_input.values()))\n    dnn_input_emb = combined_dnn_input([dnn_input_emb],dense_value_list)\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, dnn_use_bn, seed)(dnn_input_emb)\n    output = Dense(1, use_bias=False, activation=None)(output)\n    output = PredictionLayer(task)(output)\n\n    sess_input_list = []\n    # sess_input_length_list = []\n    for i in range(sess_max_count):\n        sess_name = \"sess_\" + str(i)\n        sess_input_list.extend(get_inputs_list(\n            [user_behavior_input_dict[sess_name]]))\n        # sess_input_length_list.append(user_behavior_length_dict[sess_name])\n\n    # model_input_list = get_inputs_list([sparse_input, dense_input]) + sess_input_list + [\n    #     user_sess_length]\n    #\n\n    model = Model(inputs=inputs_list+[user_sess_length], outputs=output)\n\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/After/deepctr#models#dsin.py"
        },
        "variable_name": "feature_name",
        "label": "negative",
        "id": "8069be12-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 15680
    },
    {
        "commit_hash": "3a230fa1a439a7c6b56099d450faf5702ac5b4ae",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "main",
            "container_name": "server",
            "source_code": "def main():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--host\", type=str, default=\"0.0.0.0\", help=\"Host IP to bind to\")\n    parser.add_argument(\n        \"-p\", \"--port\", type=int, default=50051, help=\"Port to bind to\")\n    parser.add_argument(\n        \"--redis-address\",\n        required=False,\n        type=str,\n        help=\"Address to use to connect to Ray\")\n    parser.add_argument(\n        \"--redis-password\",\n        required=False,\n        type=str,\n        help=\"Password for connecting to Redis\")\n    args = parser.parse_args()\n    logging.basicConfig(level=\"INFO\")\n    if args.redis_address:\n        if args.redis_password:\n            ray.init(\n                address=args.redis_address,\n                _redis_password=args.redis_password)\n        else:\n            ray.init(address=args.redis_address)\n    else:\n        ray.init()\n    hostport = \"%s:%d\" % (args.host, args.port)\n    logger.info(f\"Starting Ray Client server on {hostport}\")\n    server = serve(hostport)\n    try:\n        while True:\n            time.sleep(1000)\n    except KeyboardInterrupt:\n        server.stop(0)"
        },
        "original_method_after_refactoring": {
            "name": "main",
            "container_name": "server",
            "source_code": "def main():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--host\", type=str, default=\"0.0.0.0\", help=\"Host IP to bind to\")\n    parser.add_argument(\n        \"-p\", \"--port\", type=int, default=50051, help=\"Port to bind to\")\n    parser.add_argument(\n        \"--redis-address\",\n        required=False,\n        type=str,\n        help=\"Address to use to connect to Ray\")\n    parser.add_argument(\n        \"--redis-password\",\n        required=False,\n        type=str,\n        help=\"Password for connecting to Redis\")\n    args = parser.parse_args()\n    logging.basicConfig(level=\"INFO\")\n\n    ray_connect_handler = create_ray_handler(args.redis_address,\n                                             args.redis_password)\n\n    hostport = \"%s:%d\" % (args.host, args.port)\n    logger.info(f\"Starting Ray Client server on {hostport}\")\n    server = serve(hostport, ray_connect_handler)\n    try:\n        while True:\n            time.sleep(1000)\n    except KeyboardInterrupt:\n        server.stop(0)"
        },
        "newly_extracted_method": {
            "name": "ray_connect_handler",
            "container_name": "Unknown",
            "source_code": "def ray_connect_handler():\n        # Ray client will disconnect from ray when\n        # num_clients == 0.\n        if ray.is_initialized():\n            return info\n        else:\n            return ray.init(*args, **kwargs)"
        },
        "label": "positive",
        "id": "805bf53e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2763
    },
    {
        "commit_hash": "6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "conv3d",
            "container_name": "tensorflow_backend",
            "source_code": "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    # With 5d inputs, tf.nn.convolution only supports\n    # data_format NDHWC, so we transpose the inputs\n    # in case we are in data_format channels_first.\n    x = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format='NDHWC')\n    return _postprocess_conv3d_output(x, data_format)",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/Before/keras#backend#tensorflow_backend.py"
        },
        "inlined_method": {
            "name": "_postprocess_conv3d_output",
            "container_name": "tensorflow_backend",
            "source_code": "def _postprocess_conv3d_output(x, data_format):\n    \"\"\"Transpose and cast the output from conv3d if needed.\n\n    # Arguments\n        x: A tensor.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        A tensor.\n    \"\"\"\n    if data_format == 'channels_first':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n\n    if floatx() == 'float64':\n        x = tf.cast(x, 'float64')\n    return x",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/Before/keras#backend#tensorflow_backend.py"
        },
        "caller": {
            "name": "conv3d",
            "container_name": "tensorflow_backend",
            "source_code": "def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n           data_format=None, dilation_rate=(1, 1, 1)):\n    \"\"\"3D convolution.\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n        dilation_rate: tuple of 3 integers.\n\n    # Returns\n        A tensor, result of 3D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n\n    x, tf_data_format = _preprocess_conv3d_input(x, data_format)\n    padding = _preprocess_padding(padding)\n    x = tf.nn.convolution(\n        input=x,\n        filter=kernel,\n        dilation_rate=dilation_rate,\n        strides=strides,\n        padding=padding,\n        data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NDHWC':\n        x = tf.transpose(x, (0, 4, 1, 2, 3))\n    return x",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/After/keras#backend#tensorflow_backend.py"
        },
        "label": "positive",
        "id": "805ee186-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3880
    },
    {
        "commit_hash": "4671afa5049f7d3d7d1df76d02346bc6ac5166f7",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def apply(self, updates, parameters):\n    \"\"\"Applies updates to parameters.\n\n    By default it applies the momentum update rule for each update, parameter\n    pair:\n\n        accum_t <- momentum * accum_{t-1} + update\n        parameter <- parameter - learning_rate * accum_t\n\n    And when using Nesterov momentum (`use_nesterov=True`) it applies:\n\n        accum_t <- momentum * accum_{t-1} + update\n        parameter <- parameter - (learning_rate * update +\n                                  learning_rate * momentum * accum_t)\n\n    Args:\n      updates: A list of updates to apply to parameters. An update can be a\n        `Tensor`, `IndexedSlice`, or `None`. Updates are often gradients, as\n        returned by `tf.GradientTape.gradient`.\n      parameters: A list of parameters. A parameter is a `tf.Variable`.\n\n    Raises:\n      ValueError: If `updates` and `parameters` are empty, have different\n        lengths, or have inconsistent types.\n    \"\"\"\n    optimizer_utils.check_updates_parameters(updates, parameters)\n    self._initialize(parameters)\n    for update, parameter, accumulated_momentum in zip(\n        updates, parameters, self.accumulated_momentum):\n      # TODO(petebu): Add support for sparse tensors.\n      # TODO(petebu): Consider caching learning_rate cast.\n      # TODO(petebu): Consider the case when all updates are None.\n      if update is not None:\n        optimizer_utils.check_same_dtype(update, parameter)\n        learning_rate = tf.cast(self.learning_rate, update.dtype.base_dtype)\n        momentum = tf.cast(self.momentum, update.dtype.base_dtype)\n\n        accumulated_momentum.assign((momentum * accumulated_momentum) + update)\n        if self.use_nesterov:\n          parameter.assign_sub(learning_rate * update +\n                               learning_rate * momentum * accumulated_momentum)\n        else:\n          parameter.assign_sub(learning_rate * accumulated_momentum)",
            "file_path": "commits/4671afa5049f7d3d7d1df76d02346bc6ac5166f7/Before/sonnet#src#momentum.py"
        },
        "refactored_code": {
            "source_code": "def apply(self, updates, parameters):\n    \"\"\"Applies updates to parameters.\n\n    By default it applies the momentum update rule for each update, parameter\n    pair:\n\n        accum_t <- momentum * accum_{t-1} + update\n        parameter <- parameter - learning_rate * accum_t\n\n    And when using Nesterov momentum (`use_nesterov=True`) it applies:\n\n        accum_t <- momentum * accum_{t-1} + update\n        parameter <- parameter - (learning_rate * update +\n                                  learning_rate * momentum * accum_t)\n\n    Args:\n      updates: A list of updates to apply to parameters. An update can be a\n        `Tensor`, `IndexedSlice`, or `None`. Updates are often gradients, as\n        returned by `tf.GradientTape.gradient`.\n      parameters: A list of parameters. A parameter is a `tf.Variable`.\n\n    Raises:\n      ValueError: If `updates` and `parameters` are empty, have different\n        lengths, or have inconsistent types.\n    \"\"\"\n    optimizer_utils.check_updates_parameters(updates, parameters)\n    self._initialize(parameters)\n    for update, parameter, momentum in zip(\n        updates, parameters, self.accumulated_momentum):\n      # TODO(petebu): Consider caching learning_rate cast.\n      # TODO(petebu): Consider the case when all updates are None.\n      if update is not None:\n        optimizer_utils.check_same_dtype(update, parameter)\n        lr = tf.cast(self.learning_rate, update.dtype.base_dtype)\n        mu = tf.cast(self.momentum, update.dtype.base_dtype)\n        if isinstance(update, tf.IndexedSlices):\n          update, indices = optimizer_utils.deduplicate_indexed_slices(\n              update.values, update.indices)\n          sparse_momentum_update = (mu * momentum.gather_nd(indices)) + update\n          momentum.scatter_nd_update(indices, sparse_momentum_update)\n          if self.use_nesterov:\n            parameter.scatter_nd_sub(\n                indices, (lr * update) + (lr * mu * sparse_momentum_update))\n          else:\n            parameter.scatter_nd_sub(indices, lr * sparse_momentum_update)\n        else:\n          momentum.assign((mu * momentum) + update)\n          if self.use_nesterov:\n            parameter.assign_sub((lr * update) + (lr * mu * momentum))\n          else:\n            parameter.assign_sub(lr * momentum)",
            "file_path": "commits/4671afa5049f7d3d7d1df76d02346bc6ac5166f7/After/sonnet#src#momentum.py"
        },
        "original_variable_name": "momentum",
        "new_variable_name": "mu",
        "label": "positive",
        "id": "8067a53c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4611
    },
    {
        "commit_hash": "c270e59bf951bca41743bd03272e5b3f255be97c",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _populate_space(self, trial_id):\n        if not all(self._tried_initial_hps):\n            values = self._next_initial_hps()\n            return {\n                \"status\": kerastuner.engine.trial.TrialStatus.RUNNING,\n                \"values\": values,\n            }\n\n        for i in range(self._max_collisions):\n            hp_list = self._select_hps()\n            values = self._generate_hp_values(hp_list)\n            # Reached max collisions.\n            if values is None:\n                continue\n            # Values found.\n            return {\n                \"status\": kerastuner.engine.trial.TrialStatus.RUNNING,\n                \"values\": values,\n            }\n        # All stages reached max collisions.\n        return {\n            \"status\": kerastuner.engine.trial.TrialStatus.STOPPED,\n            \"values\": None,\n        }",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/Before/autokeras#tuners#greedy.py"
        },
        "refactored_code": {
            "source_code": "def _populate_space(self, trial_id):\n        if not all(self._tried_initial_hps):\n            values = self._next_initial_hps()\n            return {\n                \"status\": kerastuner.engine.trial.TrialStatus.RUNNING,\n                \"values\": values,\n            }\n\n        for i in range(self._max_collisions):\n            hp_names = self._select_hps()\n            values = self._generate_hp_values(hp_names)\n            # Reached max collisions.\n            if values is None:\n                continue\n            # Values found.\n            return {\n                \"status\": kerastuner.engine.trial.TrialStatus.RUNNING,\n                \"values\": values,\n            }\n        # All stages reached max collisions.\n        return {\n            \"status\": kerastuner.engine.trial.TrialStatus.STOPPED,\n            \"values\": None,\n        }",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/After/autokeras#tuners#greedy.py"
        },
        "original_variable_name": "hp_list",
        "new_variable_name": "hp_names",
        "label": "positive",
        "id": "8067a37a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2075
    },
    {
        "commit_hash": "5547b27d70a369d254c6a95a0c570fa382f8ef18",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def format_mrpc(data_dir, path_to_data):\n    print(\"Processing MRPC...\")\n    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n    if not os.path.isdir(mrpc_dir):\n        os.mkdir(mrpc_dir)\n    if path_to_data:\n        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n    else:\n        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n\n    dev_ids = []\n    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\")) as ids_fh:\n        for row in ids_fh:\n            dev_ids.append(row.strip().split('\\t'))\n\n    with open(mrpc_train_file) as data_fh, \\\n         open(os.path.join(mrpc_dir, \"train.tsv\"), 'w') as train_fh, \\\n         open(os.path.join(mrpc_dir, \"dev.tsv\"), 'w') as dev_fh:\n        header = data_fh.readline()\n        train_fh.write(header)\n        dev_fh.write(header)\n        for row in data_fh:\n            label, id1, id2, s1, s2 = row.strip().split('\\t')\n            if [id1, id2] in dev_ids:\n                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n            else:\n                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n    with open(mrpc_test_file) as data_fh, \\\n            open(os.path.join(mrpc_dir, \"test.tsv\"), 'w') as test_fh:\n        header = data_fh.readline()\n        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n        for idx, row in enumerate(data_fh):\n            label, id1, id2, s1, s2 = row.strip().split('\\t')\n            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n    print(\"\\tCompleted!\")",
            "file_path": "commits/5547b27d70a369d254c6a95a0c570fa382f8ef18/Before/examples#bert#data#download_glue_data.py"
        },
        "refactored_code": {
            "source_code": "def format_mrpc(data_dir, path_to_data):\n    print(\"Processing MRPC...\")\n    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n    if not os.path.isdir(mrpc_dir):\n        os.mkdir(mrpc_dir)\n    if path_to_data:\n        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n    else:\n        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n    assert os.path.isfile(mrpc_train_file), \\\n        \"Train data not found at %s\" % mrpc_train_file\n    assert os.path.isfile(mrpc_test_file), \\\n        \"Test data not found at %s\" % mrpc_test_file\n    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"],\n                               os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n\n    dev_ids = []\n    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\")) as ids_fh:\n        for row in ids_fh:\n            dev_ids.append(row.strip().split('\\t'))\n\n    with open(mrpc_train_file) as data_fh, \\\n            open(os.path.join(mrpc_dir, \"train.tsv\"), 'w') as train_fh, \\\n            open(os.path.join(mrpc_dir, \"dev.tsv\"), 'w') as dev_fh:\n        header = data_fh.readline()\n        train_fh.write(header)\n        dev_fh.write(header)\n        for row in data_fh:\n            label, id1, id2, s1, s2 = row.strip().split('\\t')\n            if [id1, id2] in dev_ids:\n                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n            else:\n                train_fh.write(\n                    \"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n    with open(mrpc_test_file) as data_fh, \\\n            open(os.path.join(mrpc_dir, \"test.tsv\"), 'w') as test_fh:\n        _ = data_fh.readline()\n        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n        for idx, row in enumerate(data_fh):\n            label, id1, id2, s1, s2 = row.strip().split('\\t')\n            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n    print(\"\\tCompleted!\")",
            "file_path": "commits/5547b27d70a369d254c6a95a0c570fa382f8ef18/After/examples#bert#data#download_glue_data.py"
        },
        "original_variable_name": "header",
        "new_variable_name": "_",
        "label": "positive",
        "id": "80679588-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4540
    },
    {
        "commit_hash": "44c217f45d9248aae9a6969751369606f2705108",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def normalize(ndarray):\n    \"\"\"Transform a ndarray that contains uint8 values to floats between 0. and 1.\n\n    :param ndarray:\n    :return:\n    \"\"\"\n    ndarray = ndarray.astype(numpy.float32)\n    return numpy.multiply(ndarray, 1.0 / 255.0)",
            "file_path": "commits/44c217f45d9248aae9a6969751369606f2705108/Before/nn_wtf#images_labels_data_set.py"
        },
        "refactored_code": {
            "source_code": "def normalize(ndarray):\n    \"\"\"Transform a ndarray that contains uint8 values to floats between 0. and 1.\n\n    :param ndarray:\n    :return:\n    \"\"\"\n    assert isinstance(ndarray, numpy.ndarray)\n    assert ndarray.dtype == numpy.uint8\n\n    return numpy.multiply(ndarray.astype(numpy.float32), 1.0/255.0)",
            "file_path": "commits/44c217f45d9248aae9a6969751369606f2705108/After/nn_wtf#images_labels_data_set.py"
        },
        "variable_name": "ndarray",
        "label": "positive",
        "id": "806aeada-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 910
    },
    {
        "commit_hash": "8ff9f408c66db2760dd74eb82b2f4a3273841b2f",
        "refactoring_type": "Rename Method",
        "original_method": {
            "name": "file_input",
            "container_name": "_ffmpeg",
            "source_code": "def file_input(filename):\n    \"\"\"Input file URL (ffmpeg ``-i`` option)\n\n    Official documentation: `Main options <https://ffmpeg.org/ffmpeg.html#Main-options>`__\n    \"\"\"\n    return InputNode(file_input.__name__, filename=filename)",
            "file_path": "commits/8ff9f408c66db2760dd74eb82b2f4a3273841b2f/Before/ffmpeg#_ffmpeg.py"
        },
        "renamed_method": {
            "name": "input",
            "container_name": "_ffmpeg",
            "source_code": "def input(filename):\n    \"\"\"Input file URL (ffmpeg ``-i`` option)\n\n    Official documentation: `Main options <https://ffmpeg.org/ffmpeg.html#Main-options>`__\n    \"\"\"\n    return InputNode(input.__name__, filename=filename)",
            "file_path": "commits/8ff9f408c66db2760dd74eb82b2f4a3273841b2f/After/ffmpeg#_ffmpeg.py"
        },
        "label": "negative",
        "id": "8063cdae-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 873
    },
    {
        "commit_hash": "a124edcd95c1dcc16070e16244fdfcba6be169e3",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "compute_reward",
            "container_name": "PickAndPlaceEnv",
            "source_code": "def compute_reward(self, achieved_goal, goal, info):\n        # Compute distance between goal and the achieved goal.\n        grasped = self._grasp()\n        reward = 0\n        gripper_pos = info['gripper_pos']\n        if not grasped:\n            # first phase: move towards the object\n            d = self._goal_distance(gripper_pos, achieved_goal)\n        else:\n            d = self._goal_distance(achieved_goal, goal)\n            reward += 30\n            self._grasped = True\n\n        if self._sparse_reward:\n            reward += -(d > self._distance_threshold).astype(np.float32)\n        else:\n            reward += -d\n        if grasped and d < self._distance_threshold:\n            reward += 4200\n        return reward",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#pick_and_place_env.py"
        },
        "inlined_method": {
            "name": "_goal_distance",
            "container_name": "PickAndPlaceEnv",
            "source_code": "def _goal_distance(goal_a, goal_b):\n        assert goal_a.shape == goal_b.shape\n        return np.linalg.norm(goal_a - goal_b, axis=-1)",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#pick_and_place_env.py"
        },
        "caller": {
            "name": "compute_reward",
            "container_name": "PickAndPlaceEnv",
            "source_code": "def compute_reward(self, achieved_goal, desired_goal, info: dict):\n        d = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n        if self._reward_type == 'sparse':\n            return (d < self._distance_threshold).astype(np.float32)\n\n        return -d",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/After/garage#envs#mujoco#sawyer#pick_and_place_env.py"
        },
        "label": "positive",
        "id": "805edd3a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1847
    },
    {
        "commit_hash": "92bba3102bed7256aa22c0ab273139048aa23559",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "__init__",
            "container_name": "classifier",
            "source_code": "def __init__(self, model, **kwargs):\n        self.model = model\n        self.cmap = kwargs.pop('cmap', ddlheatmap)\n        self.name = kwargs.pop('name', get_model_name(model))\n        self.report = None",
            "file_path": "commits/92bba3102bed7256aa22c0ab273139048aa23559/Before/yellowbrick#classifier.py"
        },
        "inlined_method": {
            "name": "crplot",
            "container_name": "classifier",
            "source_code": "def crplot(model, y_true, y_pred, **kwargs):\n    \"\"\"\n    Plots a classification report as a heatmap. (More to follow).\n    \"\"\"\n    viz = ClassifierReport(model, **kwargs)\n    viz.score(y_true, y_pred, **kwargs)\n\n    return viz.render()",
            "file_path": "commits/92bba3102bed7256aa22c0ab273139048aa23559/Before/yellowbrick#classifier.py"
        },
        "caller": {
            "name": "__init__",
            "container_name": "classifier",
            "source_code": "def __init__(self, model):\n        \"\"\"\n        Check to see if model is an instance of a classifer.\n        Should return a metrics mismatch error if it isn't.\n        \"\"\"\n        pass",
            "file_path": "commits/92bba3102bed7256aa22c0ab273139048aa23559/After/yellowbrick#classifier.py"
        },
        "label": "negative",
        "id": "805eddda-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1240
    },
    {
        "commit_hash": "514b7f7c52d7231f1a3615819b1adb237de73004",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def modify_model_backprop(model, backprop_modifier):\n    \"\"\"Creates a copy of model by modifying all activations to use a custom op to modify the backprop behavior.\n\n    Args:\n        model:  The `keras.models.Model` instance.\n        backprop_modifier: One of `{'guided', 'rectified'}`\n\n    Returns:\n        A copy of model with modified activations for backwards pass.\n    \"\"\"\n\n    # The general strategy is as follows:\n    # - Modify all activations in the model as ReLU.\n    # - Save a copy of model to temp file\n    # - Call backend specific function that registers the custom op and loads the model under modified context manager.\n    #\n    # This is done because setting the activation in a Keras layer doesnt actually change the graph. We have to\n    # iterate the entire graph and change the layer inbound and outbound nodes with modified tensors. This is doubly\n    # complicated in Keras 2.x since multiple inbound and outbound nodes are allowed with the Graph API.\n    #\n    # This is a reliable and future proof strategy to modify activations in static graph computational frameworks.\n\n    # Replace all layer activations with ReLU.\n    # We also don't want to mutate the original model as it will have unexpected consequences on upstream callers.\n    # For this reason we will maintain the set of original activations and restore it.\n    original_activations = []\n    for layer in model.layers[1:]:\n        if hasattr(layer, 'activation'):\n            original_activations.append(layer.activation)\n            layer.activation = tf.nn.relu\n\n    # Save model. This model should save with modified activation names.\n    # Upon loading, keras should rebuild the graph with modified activations.\n    model_path = '/tmp/' + next(tempfile._get_candidate_names()) + '.h5'\n    model.save(model_path)\n\n    # Restore original model to keep upstream callers unaffected.\n    idx = 0\n    for layer in model.layers[1:]:\n        if hasattr(layer, 'activation'):\n            layer.activation = original_activations[idx]\n            idx += 1\n\n    # Register modifier.\n    modifier_fn = _BACKPROP_MODIFIERS.get(backprop_modifier)\n    if modifier_fn is None:\n        raise ValueError(\"'{}' modifier is not supported\".format(backprop_modifier))\n    modifier_fn(backprop_modifier)\n\n    # Create graph under custom context manager.\n    try:\n        with tf.get_default_graph().gradient_override_map({'Relu': backprop_modifier}):\n            return load_model(model_path)\n    finally:\n        # Clean up temp file.\n        os.remove(model_path)",
            "file_path": "commits/514b7f7c52d7231f1a3615819b1adb237de73004/Before/vis#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def modify_model_backprop(model, backprop_modifier):\n    \"\"\"Creates a copy of model by modifying all activations to use a custom op to modify the backprop behavior.\n\n    Args:\n        model:  The `keras.models.Model` instance.\n        backprop_modifier: One of `{'guided', 'rectified'}`\n\n    Returns:\n        A copy of model with modified activations for backwards pass.\n    \"\"\"\n    # Retrieve from cache if previously modified.\n    modified_model = _MODIFIED_MODEL_CACHE.get((model, backprop_modifier))\n    if modified_model is not None:\n        return modified_model\n\n    # The general strategy is as follows:\n    # - Modify all activations in the model as ReLU.\n    # - Save a copy of model to temp file\n    # - Call backend specific function that registers the custom op and loads the model under modified context manager.\n    #\n    # This is done because setting the activation in a Keras layer doesnt actually change the graph. We have to\n    # iterate the entire graph and change the layer inbound and outbound nodes with modified tensors. This is doubly\n    # complicated in Keras 2.x since multiple inbound and outbound nodes are allowed with the Graph API.\n    #\n    # This is a reliable and future proof strategy to modify activations in static graph computational frameworks.\n\n    # Replace all layer activations with ReLU.\n    # We also don't want to mutate the original model as it will have unexpected consequences on upstream callers.\n    # For this reason we will maintain the set of original activations and restore it.\n    original_activations = []\n    for layer in model.layers[1:]:\n        if hasattr(layer, 'activation'):\n            original_activations.append(layer.activation)\n            layer.activation = tf.nn.relu\n\n    # Save model. This model should save with modified activation names.\n    # Upon loading, keras should rebuild the graph with modified activations.\n    model_path = '/tmp/' + next(tempfile._get_candidate_names()) + '.h5'\n    model.save(model_path)\n\n    # Restore original model to keep upstream callers unaffected.\n    idx = 0\n    for layer in model.layers[1:]:\n        if hasattr(layer, 'activation'):\n            layer.activation = original_activations[idx]\n            idx += 1\n\n    # Register modifier.\n    modifier_fn = _BACKPROP_MODIFIERS.get(backprop_modifier)\n    if modifier_fn is None:\n        raise ValueError(\"'{}' modifier is not supported\".format(backprop_modifier))\n    modifier_fn(backprop_modifier)\n\n    # Create graph under custom context manager.\n    try:\n        with tf.get_default_graph().gradient_override_map({'Relu': backprop_modifier}):\n            modified_model = load_model(model_path)\n\n            # Cache to impove subsequent call performance.\n            _MODIFIED_MODEL_CACHE[(model, backprop_modifier)] = modified_model\n            return modified_model\n    finally:\n        # Clean up temp file.\n        os.remove(model_path)",
            "file_path": "commits/514b7f7c52d7231f1a3615819b1adb237de73004/After/vis#backend#tensorflow_backend.py"
        },
        "variable_name": "modified_model",
        "label": "positive",
        "id": "8069bfd4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5958
    },
    {
        "commit_hash": "55f6f1ab292abe7a10a93982fa6df48f8d4c4854",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "closure",
            "container_name": "aitchison",
            "source_code": "def closure(x):\n    \"\"\"Returns the closure operation applied to the composition x.\n\n    The closure operation renormalizes `x` so that its components sum to one.\n\n    Parameters\n    ----------\n    x : NumPy array, shape (n,) or (k,n)\n        The array can be one- or two-dimensional.  If one-dimensional, it is\n        treated as a single composition. If two-dimensional, each row is\n        treated as a composition and will be normalized individually.\n\n    Returns\n    -------\n    cx : NumPy array, shape (n,) or (k,n)\n        The closure of `x`.\n\n    \"\"\"\n    if len(x.shape) == 1:\n        single = True\n    else:\n        single = False\n\n    x = np.atleast_2d(x)\n    cx = _closure(x)\n\n    if single:\n        cx = cx[0]\n\n    return cx",
            "file_path": "commits/55f6f1ab292abe7a10a93982fa6df48f8d4c4854/Before/dit#math#aitchison.py"
        },
        "inlined_method": {
            "name": "_closure",
            "container_name": "aitchison",
            "source_code": "def _closure(x):\n    \"\"\"Returns the closure operation applied to the rows of `x`.\n\n    Parameters\n    ----------\n    x : NumPy array, shape (k,n)\n        The k compositions to be closed.\n\n    Returns\n    -------\n    cx : NumPy array, shape (k,n)\n        The closures of the k compositions in `x`.\n\n    Notes\n    -----\n    The sum of the elements of the composition is assumed to be \\\\kappa = 1.\n\n    \"\"\"\n    s = x.sum(axis=1, dtype=float)\n    if np.any(s == 0.0):\n        raise ditException(\"x contains an unnormalizable distribution.\")\n    cx = x / s[:, np.newaxis]\n    return cx",
            "file_path": "commits/55f6f1ab292abe7a10a93982fa6df48f8d4c4854/Before/dit#math#aitchison.py"
        },
        "caller": {
            "name": "closure",
            "container_name": "aitchison",
            "source_code": "def closure(x):\n    \"\"\"Returns the closure operation applied to the composition x.\n\n    The closure operation renormalizes `x` so that its components sum to one.\n\n    Parameters\n    ----------\n    x : NumPy array, shape (n,) or (k,n)\n        The array can be one- or two-dimensional.  If one-dimensional, it is\n        treated as a single composition. If two-dimensional, each row is\n        treated as a composition and will be normalized individually.\n\n    Returns\n    -------\n    cx : NumPy array, shape (n,) or (k,n)\n        The closure of `x`.\n\n    \"\"\"\n    s = x.sum(axis=-1, dtype=float)\n    if np.any(s == 0.0):\n        raise ditException(\"x contains an unnormalizable distribution.\")\n    cx = x / s[..., np.newaxis]\n    return cx",
            "file_path": "commits/55f6f1ab292abe7a10a93982fa6df48f8d4c4854/After/dit#math#aitchison.py"
        },
        "label": "positive",
        "id": "805edfce-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2712
    },
    {
        "commit_hash": "09fe3365beaf43b9d7979399ce10efd086717b24",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def get_property_value(client_context, local, name):\n\n        if local is True:\n\n            value = None\n            #TODO Why would you need this test, when is get_conversation(clientid) == None ?\n            if client_context.bot.get_conversation(client_context) is not None:\n                if client_context.bot.get_conversation(client_context).has_current_question():\n                    value = client_context.bot.get_conversation(client_context).current_question().property(name)\n\n        else:\n\n            if name is not None and client_context.brain.dynamics.is_dynamic_var(name) is True:\n                value = client_context.brain.dynamics.dynamic_var(client_context, name)\n            else:\n                value = client_context.bot.get_conversation(client_context).property(name)\n                #if value is None:\n                #    value = bot.brain.properties.property(name)\n\n        if value is None:\n            YLogger.error(client_context, \"No property for [%s]\", name)\n\n            value = TemplateGetNode.get_default_value(client_context.bot)\n\n        return value",
            "file_path": "commits/09fe3365beaf43b9d7979399ce10efd086717b24/Before/src#programy#parser#template#nodes#get.py"
        },
        "refactored_code": {
            "source_code": "def get_property_value(client_context, local, name):\n\n        conversation = client_context.bot.get_conversation(client_context)\n\n        value = None\n        if local is True:\n\n            if conversation.has_current_question():\n                value = conversation.current_question().property(name)\n\n        else:\n\n            if name is not None and client_context.brain.dynamics.is_dynamic_var(name) is True:\n                value = client_context.brain.dynamics.dynamic_var(client_context, name)\n            else:\n                value = conversation.property(name)\n\n        if value is None:\n            YLogger.error(client_context, \"No property for [%s]\", name)\n\n            value = TemplateGetNode.get_default_value(client_context)\n\n        return value",
            "file_path": "commits/09fe3365beaf43b9d7979399ce10efd086717b24/After/src#programy#parser#template#nodes#get.py"
        },
        "variable_name": "conversation",
        "label": "positive",
        "id": "8069bd9a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2277
    },
    {
        "commit_hash": "e2b2766a4e970affc42ff8505a69a51eafea4e19",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def train(data_train, model, nsp_loss, mlm_loss, vocab_size, ctx):\n    \"\"\"Training function.\"\"\"\n    hvd.broadcast_parameters(model.collect_params(), root_rank=0)\n\n    mlm_metric = nlp.metric.MaskedAccuracy()\n    nsp_metric = nlp.metric.MaskedAccuracy()\n    mlm_metric.reset()\n    nsp_metric.reset()\n\n    logging.debug('Creating distributed trainer...')\n    lr = args.lr\n    optim_params = {'learning_rate': lr, 'epsilon': 1e-6, 'wd': 0.01}\n    if args.dtype == 'float16':\n        optim_params['multi_precision'] = True\n\n    dynamic_loss_scale = args.dtype == 'float16'\n    if dynamic_loss_scale:\n        loss_scale_param = {'scale_window': 2000 / num_workers}\n    else:\n        loss_scale_param = None\n    trainer = hvd.DistributedTrainer(model.collect_params(), 'bertadam', optim_params)\n    fp16_trainer = FP16Trainer(trainer, dynamic_loss_scale=dynamic_loss_scale,\n                               loss_scaler_params=loss_scale_param)\n\n    if args.start_step:\n        trainer.load_states(os.path.join(args.ckpt_dir, '%07d.states'%args.start_step))\n\n    accumulate = args.accumulate\n    num_train_steps = args.num_steps\n    warmup_ratio = args.warmup_ratio\n    num_warmup_steps = int(num_train_steps * warmup_ratio)\n    params = [p for p in model.collect_params().values() if p.grad_req != 'null']\n    param_dict = model.collect_params()\n\n    # Do not apply weight decay on LayerNorm and bias terms\n    for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n        v.wd_mult = 0.0\n    if accumulate > 1:\n        for p in params:\n            p.grad_req = 'add'\n\n    train_begin_time = time.time()\n    begin_time = time.time()\n    running_mlm_loss, running_nsp_loss = 0, 0\n    running_num_tks = 0\n    batch_num = 0\n    step_num = args.start_step\n\n    logging.debug('Training started')\n    while step_num < num_train_steps:\n        for _, dataloader in enumerate(data_train):\n            if step_num >= num_train_steps:\n                break\n\n            # create dummy data loader if needed\n            if args.dummy_data_len:\n                target_shape = (args.batch_size, args.dummy_data_len)\n                dataloader = get_dummy_dataloader(dataloader, target_shape)\n\n            for _, data_batch in enumerate(dataloader):\n                if step_num >= num_train_steps:\n                    break\n                if batch_num % accumulate == 0:\n                    step_num += 1\n                    # if accumulate > 1, grad_req is set to 'add', and zero_grad is required\n                    if accumulate > 1:\n                        param_dict.zero_grad()\n                    # update learning rate\n                    if step_num <= num_warmup_steps:\n                        new_lr = lr * step_num / num_warmup_steps\n                    else:\n                        offset = lr * step_num / num_train_steps\n                        new_lr = lr - offset\n                    trainer.set_learning_rate(new_lr)\n                    if args.profile:\n                        profile(step_num, 10, 14, profile_name=args.profile + str(rank))\n\n                # load data\n                if args.use_avg_len:\n                    data_list = [[seq.as_in_context(context) for seq in shard]\n                                 for context, shard in zip([ctx], data_batch)]\n                else:\n                    data_list = list(split_and_load(data_batch, [ctx]))\n                data = data_list[0]\n\n                # forward\n                with mx.autograd.record():\n                    (ls, ns_label, classified, masked_id, decoded, \\\n                     masked_weight, ls1, ls2, valid_len) = forward(data, model, mlm_loss,\n                                                                   nsp_loss, vocab_size, args.dtype)\n                    ls = ls / accumulate\n                    # backward\n                    if args.dtype == 'float16':\n                        fp16_trainer.backward(ls)\n                    else:\n                        ls.backward()\n\n                running_mlm_loss += ls1.as_in_context(mx.cpu())\n                running_nsp_loss += ls2.as_in_context(mx.cpu())\n                running_num_tks += valid_len.sum().as_in_context(mx.cpu())\n\n                # update\n                if (batch_num + 1) % accumulate == 0:\n                    # step() performs 3 things:\n                    # 1. allreduce gradients from all workers\n                    # 2. checking the global_norm of gradients and clip them if necessary\n                    # 3. averaging the gradients and apply updates\n                    fp16_trainer.step(1, max_norm=1*num_workers)\n\n                nsp_metric.update([ns_label], [classified])\n                mlm_metric.update([masked_id], [decoded], [masked_weight])\n\n                # logging\n                if (step_num + 1) % (args.log_interval) == 0 and (batch_num + 1) % accumulate == 0:\n                    log(begin_time, running_num_tks, running_mlm_loss / accumulate,\n                        running_nsp_loss / accumulate, step_num, mlm_metric, nsp_metric,\n                        trainer, args.log_interval)\n                    begin_time = time.time()\n                    running_mlm_loss = running_nsp_loss = running_num_tks = 0\n                    mlm_metric.reset_local()\n                    nsp_metric.reset_local()\n\n                # saving checkpoints\n                if (step_num + 1) % args.ckpt_interval == 0 \\\n                   and (batch_num + 1) % accumulate == 0 and local_rank == 0:\n                    save_params(step_num, model, trainer, args.ckpt_dir)\n\n                batch_num += 1\n\n    if local_rank == 0:\n        save_params(step_num, model, trainer, args.ckpt_dir)\n    mx.nd.waitall()\n    train_end_time = time.time()\n    logging.info('Train cost={:.1f}s'.format(train_end_time - train_begin_time))",
            "file_path": "commits/e2b2766a4e970affc42ff8505a69a51eafea4e19/Before/scripts#bert#run_pretraining_hvd.py"
        },
        "refactored_code": {
            "source_code": "def train(data_train, model, nsp_loss, mlm_loss, vocab_size, ctx):\n    \"\"\"Training function.\"\"\"\n    hvd.broadcast_parameters(model.collect_params(), root_rank=0)\n\n    mlm_metric = nlp.metric.MaskedAccuracy()\n    nsp_metric = nlp.metric.MaskedAccuracy()\n    mlm_metric.reset()\n    nsp_metric.reset()\n\n    logging.debug('Creating distributed trainer...')\n    lr = args.lr\n    optim_params = {'learning_rate': lr, 'epsilon': 1e-6, 'wd': 0.01}\n    if args.dtype == 'float16':\n        optim_params['multi_precision'] = True\n\n    dynamic_loss_scale = args.dtype == 'float16'\n    if dynamic_loss_scale:\n        loss_scale_param = {'scale_window': 2000 / num_workers}\n    else:\n        loss_scale_param = None\n    trainer = hvd.DistributedTrainer(model.collect_params(), 'bertadam', optim_params)\n    fp16_trainer = FP16Trainer(trainer, dynamic_loss_scale=dynamic_loss_scale,\n                               loss_scaler_params=loss_scale_param)\n\n    if args.start_step:\n        state_path = os.path.join(args.ckpt_dir, '%07d.states.%02d'%(args.start_step, local_rank))\n        logging.info('Loading trainer state from %s', state_path)\n        nlp.utils.load_states(trainer, state_path)\n\n    accumulate = args.accumulate\n    num_train_steps = args.num_steps\n    warmup_ratio = args.warmup_ratio\n    num_warmup_steps = int(num_train_steps * warmup_ratio)\n    params = [p for p in model.collect_params().values() if p.grad_req != 'null']\n    param_dict = model.collect_params()\n\n    # Do not apply weight decay on LayerNorm and bias terms\n    for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n        v.wd_mult = 0.0\n    if accumulate > 1:\n        for p in params:\n            p.grad_req = 'add'\n\n    train_begin_time = time.time()\n    begin_time = time.time()\n    running_mlm_loss, running_nsp_loss = 0, 0\n    running_num_tks = 0\n    batch_num = 0\n    step_num = args.start_step\n\n    logging.debug('Training started')\n    while step_num < num_train_steps:\n        for _, dataloader in enumerate(data_train):\n            if step_num >= num_train_steps:\n                break\n\n            # create dummy data loader if needed\n            if args.dummy_data_len:\n                target_shape = (args.batch_size, args.dummy_data_len)\n                dataloader = get_dummy_dataloader(dataloader, target_shape)\n\n            for _, data_batch in enumerate(dataloader):\n                if step_num >= num_train_steps:\n                    break\n                if batch_num % accumulate == 0:\n                    step_num += 1\n                    # if accumulate > 1, grad_req is set to 'add', and zero_grad is required\n                    if accumulate > 1:\n                        param_dict.zero_grad()\n                    # update learning rate\n                    if step_num <= num_warmup_steps:\n                        new_lr = lr * step_num / num_warmup_steps\n                    else:\n                        offset = lr * step_num / num_train_steps\n                        new_lr = lr - offset\n                    trainer.set_learning_rate(new_lr)\n                    if args.profile:\n                        profile(step_num, 10, 14, profile_name=args.profile + str(rank))\n\n                # load data\n                if args.use_avg_len:\n                    data_list = [[seq.as_in_context(context) for seq in shard]\n                                 for context, shard in zip([ctx], data_batch)]\n                else:\n                    data_list = list(split_and_load(data_batch, [ctx]))\n                data = data_list[0]\n\n                # forward\n                with mx.autograd.record():\n                    (ls, ns_label, classified, masked_id, decoded, \\\n                     masked_weight, ls1, ls2, valid_len) = forward(data, model, mlm_loss,\n                                                                   nsp_loss, vocab_size, args.dtype)\n                    ls = ls / accumulate\n                    # backward\n                    if args.dtype == 'float16':\n                        fp16_trainer.backward(ls)\n                    else:\n                        ls.backward()\n\n                running_mlm_loss += ls1.as_in_context(mx.cpu())\n                running_nsp_loss += ls2.as_in_context(mx.cpu())\n                running_num_tks += valid_len.sum().as_in_context(mx.cpu())\n\n                # update\n                if (batch_num + 1) % accumulate == 0:\n                    # step() performs 3 things:\n                    # 1. allreduce gradients from all workers\n                    # 2. checking the global_norm of gradients and clip them if necessary\n                    # 3. averaging the gradients and apply updates\n                    fp16_trainer.step(1, max_norm=1*num_workers)\n\n                nsp_metric.update([ns_label], [classified])\n                mlm_metric.update([masked_id], [decoded], [masked_weight])\n\n                # logging\n                if (step_num + 1) % (args.log_interval) == 0 and (batch_num + 1) % accumulate == 0:\n                    log(begin_time, running_num_tks, running_mlm_loss / accumulate,\n                        running_nsp_loss / accumulate, step_num, mlm_metric, nsp_metric,\n                        trainer, args.log_interval)\n                    begin_time = time.time()\n                    running_mlm_loss = running_nsp_loss = running_num_tks = 0\n                    mlm_metric.reset_local()\n                    nsp_metric.reset_local()\n\n                # saving checkpoints\n                if (step_num + 1) % args.ckpt_interval == 0 and (batch_num + 1) % accumulate == 0:\n                    if is_master_node:\n                        save_states(step_num, trainer, args.ckpt_dir, local_rank)\n                        if local_rank == 0:\n                            save_parameters(step_num, model, args.ckpt_dir)\n\n                batch_num += 1\n\n    if is_master_node:\n        save_states(step_num, trainer, args.ckpt_dir, local_rank)\n        if local_rank == 0:\n            save_parameters(step_num, model, args.ckpt_dir)\n    mx.nd.waitall()\n    train_end_time = time.time()\n    logging.info('Train cost={:.1f}s'.format(train_end_time - train_begin_time))",
            "file_path": "commits/e2b2766a4e970affc42ff8505a69a51eafea4e19/After/scripts#bert#run_pretraining_hvd.py"
        },
        "variable_name": "state_path",
        "label": "positive",
        "id": "8069be4e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 12637
    },
    {
        "commit_hash": "1073d248e60808a94fbe6c24fb717528529360af",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "gc",
            "container_name": "gcloud",
            "source_code": "def gc(job_id, project_id, service_account_json, bucket_name, config, dataset):\n    args = []\n\n    if not job_id:\n        job_id = 'train_{}'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n\n    # Define path in bucket to store job's config, logs, etc.\n    base_path = 'lumi_{}'.format(job_id)\n\n    # Check if absolute or relative dataset path\n    if not dataset.startswith('gs://'):\n        dataset = 'gs://{}'.format(dataset)\n\n    args.extend([\n        '--log-dir', 'gs://{}/{}/logs'.format(bucket_name, base_path),\n        '--model-dir', 'gs://{}/{}/model'.format(bucket_name, base_path),\n        '--override', 'dataset.dir={}'.format(dataset)\n    ])\n\n    # Creates bucket for logs and models if it doesn't exist\n    bucket = get_bucket(service_account_json, bucket_name)\n\n    if config:\n        # Upload config file to be used by the training job.\n        path = upload_file(bucket, base_path, config)\n        args.extend(['--config', 'gs://{}/{}'.format(bucket_name, path)])\n\n    credentials = service_account.Credentials.from_service_account_file(\n        service_account_json)\n    cloudml = discovery.build('ml', 'v1', credentials=credentials)\n\n    training_inputs = {\n        'scaleTier': 'BASIC_GPU',\n        'packageUris': ['gs://luminoth-config/luminoth-0.0.1-py2-none-any.whl'],\n        'pythonModule': 'luminoth.train',\n        'args': args,\n        'region': 'us-central1',\n        'jobDir': 'gs://{}/{}/train/'.format(bucket_name, base_path),\n        'runtimeVersion': '1.2'\n    }\n\n    job_spec = {\n        'jobId': job_id,\n        'trainingInput': training_inputs\n    }\n\n    request = cloudml.projects().jobs().create(\n        body=job_spec, parent='projects/{}'.format(project_id))\n\n    try:\n        click.echo('Submitting training job.')\n        request.execute()\n        click.echo('Job {} submitted successfully.'.format(job_id))\n    except Exception as err:\n        click.echo(\n            'There was an error creating the training job. '\n            'Check the details: \\n{}'.format(err._get_reason())\n        )"
        },
        "original_method_after_refactoring": {
            "name": "gc",
            "container_name": "gcloud",
            "source_code": "def gc():\n    pass"
        },
        "newly_extracted_method": {
            "name": "get_credentials",
            "container_name": "Unknown",
            "source_code": "def get_credentials(file):\n    return service_account.Credentials.from_service_account_file(file)"
        },
        "label": "positive",
        "id": "805bff3e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2574
    },
    {
        "commit_hash": "cc4a397586c6dc8c2de95773572bf3ab318a8371",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def get_rnn_cell(hparams=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['cell']['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=utils.switch_dropout(d_hp[\"input_keep_prob\"]),\n                output_keep_prob=utils.switch_dropout(d_hp[\"output_keep_prob\"]),\n                state_keep_prob=utils.switch_dropout(d_hp[\"state_keep_prob\"]),\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/Before/texar#core#layers.py"
        },
        "refactored_code": {
            "source_code": "def get_rnn_cell(hparams=None, mode=None):\n    \"\"\"Creates an RNN cell.\n\n    See :meth:`~texar.core.layers.default_rnn_cell_hparams` for all\n    hyperparameters and default values.\n\n    Args:\n        hparams (dict or HParams, optional): Cell hyperparameters. Missing\n            hyperparameters are set to default values. If\n            :attr:`hparams[\"type\"]` is a cell instance (rather\n            than the name or path to the cell class), then\n            :attr:`hparams[\"num_layers\"]` must be 1.\n        mode (optional): A member of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`, including\n            `TRAIN`, `EVAL`, and `PREDICT`. If `None`, dropout will be\n            controlled by :func:`texar.context.global_mode`.\n\n    Returns:\n        An instance of :tf_main:`RNNCell <contrib/rnn/RNNCell>`.\n\n    Raises:\n        ValueError: If :attr:`hparams[\"num_layers\"]` > 1 and\n            :attr:`hparams[\"type\"]` is not of type string.\n        ValueError: The cell is not an\n            :tf_main:`RNNCell <contrib/rnn/RNNCell>` instance.\n    \"\"\"\n    if hparams is None or isinstance(hparams, dict):\n        hparams = HParams(hparams, default_rnn_cell_hparams())\n\n    d_hp = hparams[\"dropout\"]\n    if d_hp[\"variational_recurrent\"] and \\\n            len(d_hp[\"input_size\"]) != hparams[\"num_layers\"]:\n        raise ValueError(\n            \"If variational_recurrent=True, input_size must be a list of \"\n            \"num_layers(%d) integers. Got len(input_size)=%d.\" %\n            (hparams[\"num_layers\"], len(d_hp[\"input_size\"])))\n\n    cells = []\n    cell_kwargs = hparams[\"kwargs\"].todict()\n    num_layers = hparams[\"num_layers\"]\n    for layer_i in range(num_layers):\n        # Create the basic cell\n        cell_type = hparams[\"type\"]\n        if utils.is_str_or_unicode(cell_type):\n            cell_modules = ['tensorflow.contrib.rnn', 'texar.custom']\n            cell = utils.get_instance(cell_type, cell_kwargs, cell_modules)\n        else:\n            if num_layers > 1:\n                raise ValueError(\n                    \"If `hparams['num_layers']`>1, then \"\n                    \"`hparams['type']` must be a string name or path \"\n                    \"to the class.\")\n            cell = cell_type\n        if not isinstance(cell, rnn.RNNCell):\n            raise ValueError(\"cell must be an instance of RNNCell.\")\n\n        # Optionally add dropout\n        if d_hp[\"input_keep_prob\"] < 1.0 or \\\n                d_hp[\"output_keep_prob\"] < 1.0 or \\\n                d_hp[\"state_keep_prob\"] < 1.0:\n            vr_kwargs = {}\n            if d_hp[\"variational_recurrent\"]:\n                vr_kwargs = {\"variational_recurrent\": True,\n                             \"input_size\": d_hp[\"input_size\"][layer_i],\n                             \"dtype\": tf.float32}\n            input_keep_prob = utils.switch_dropout(d_hp[\"input_keep_prob\"],\n                                                   mode)\n            output_keep_prob = utils.switch_dropout(d_hp[\"output_keep_prob\"],\n                                                    mode)\n            state_keep_prob = utils.switch_dropout(d_hp[\"state_keep_prob\"],\n                                                   mode)\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=input_keep_prob,\n                output_keep_prob=output_keep_prob,\n                state_keep_prob=state_keep_prob,\n                **vr_kwargs)\n\n        # Optionally add residual and highway connections\n        if layer_i > 0:\n            if hparams[\"residual\"]:\n                cell = rnn.ResidualWrapper(cell)\n            if hparams[\"highway\"]:\n                cell = rnn.HighwayWrapper(cell)\n\n        cells.append(cell)\n\n    if hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    return cell",
            "file_path": "commits/cc4a397586c6dc8c2de95773572bf3ab318a8371/After/texar#core#layers.py"
        },
        "variable_name": "input_keep_prob",
        "label": "positive",
        "id": "8069ba48-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 7611
    },
    {
        "commit_hash": "f088ca492bb0a5ecb6c8b5708132d561b812efde",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "train_model_from_config",
            "container_name": "train",
            "source_code": "def train_model_from_config(config_path: str, usr_dir_name=USR_DIR):\n    # make a serialization user dir\n    usr_dir_path = set_usr_dir(config_path, usr_dir_name)\n\n    config = read_json(config_path)\n    vocab_path = usr_dir_path.joinpath('vocab.txt')\n\n    data = get_data(config, config['dataset_reader'], vocab_path)\n\n    model_config = config['model']\n    model_name = model_config['name']\n    model = from_params(_REGISTRY[model_name], model_config, vocab_path=vocab_path)\n\n    num_epochs = config['num_epochs']\n    num_tr_data = config['num_train_instances']\n\n    ####### Train\n    # TODO do batching in the train script.\n    model.train(data, num_epochs=num_epochs, num_tr_data=num_tr_data)",
            "file_path": "commits/f088ca492bb0a5ecb6c8b5708132d561b812efde/Before/deeppavlov#core#commands#train.py"
        },
        "inlined_method": {
            "name": "get_data",
            "container_name": "train",
            "source_code": "def get_data(skill_config, dataset_config, vocab_path):\n    dataset_name = dataset_config['name']\n    data_path = skill_config['data_path']\n\n    data_reader = from_params(_REGISTRY[dataset_name], dataset_config)\n    data = data_reader.read(data_path)\n    data_reader.save_vocab(data, vocab_path)\n    return data",
            "file_path": "commits/f088ca492bb0a5ecb6c8b5708132d561b812efde/Before/deeppavlov#core#commands#train.py"
        },
        "caller": {
            "name": "train_model_from_config",
            "container_name": "train",
            "source_code": "def train_model_from_config(config_path: str):\n    usr_dir = paths.USR_PATH\n    config = read_json(config_path)\n\n    reader_config = config['dataset_reader']\n    reader = from_params(_REGISTRY[reader_config['name']], {})\n    data = reader.read(reader_config.get('data_path', usr_dir))\n\n    dataset_config = config['dataset']\n    dataset_name = dataset_config['name']\n    dataset = from_params(_REGISTRY[dataset_name], dataset_config, data=data)\n\n    model_config = config['model']\n    model_name = model_config['name']\n    model = from_params(_REGISTRY[model_name], model_config)\n\n    model.train(dataset)",
            "file_path": "commits/f088ca492bb0a5ecb6c8b5708132d561b812efde/After/deeppavlov#core#commands#train.py"
        },
        "label": "positive",
        "id": "805ee12c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2295
    },
    {
        "commit_hash": "ba7ab2ffe62143949b9730a55291c474352f31e5",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "all",
            "container_name": "theano_backend",
            "source_code": "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n    \"\"\"\n    y = T.all(x, axis=axis, keepdims=keepdims)\n    if hasattr(x, '_keras_shape'):\n        if axis is None:\n            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n        else:\n            if isinstance(axis, int):\n                axis_list = [axis]\n            else:\n                axis_list = list(set(int(a) for a in axis))\n            keras_shape_list = list(x._keras_shape)\n            if keepdims:\n                for a in axis_list:\n                    keras_shape_list[a] = 1\n            else:\n                for a in axis_list[::-1]:\n                    keras_shape_list.pop(a)\n                if not keras_shape_list:\n                    keras_shape_list = (1,)\n            y._keras_shape = tuple(keras_shape_list)\n    return y"
        },
        "original_method_after_refactoring": {
            "name": "all",
            "container_name": "theano_backend",
            "source_code": "def all(x, axis=None, keepdims=False):\n    \"\"\"Bitwise reduction (logical AND).\n    \"\"\"\n    y = T.all(x, axis=axis, keepdims=keepdims)\n    y = _set_keras_shape_for_reduction(x, y, axis, keepdims)\n    return y"
        },
        "newly_extracted_method": {
            "name": "_set_keras_shape_for_reduction",
            "container_name": "theano_backend",
            "source_code": "def _set_keras_shape_for_reduction(x, y, axis, keepdims):\n    if hasattr(x, '_keras_shape'):\n        if axis is None:\n            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n        else:\n            if isinstance(axis, int):\n                axis_list = [axis]\n            else:\n                axis_list = list(set(int(a) for a in axis))\n            keras_shape_list = list(x._keras_shape)\n            if keepdims:\n                for a in axis_list:\n                    keras_shape_list[a] = 1\n            else:\n                for a in axis_list[::-1]:\n                    keras_shape_list.pop(a)\n                if not keras_shape_list:\n                    keras_shape_list = (1,)\n            y._keras_shape = tuple(keras_shape_list)\n    return y"
        },
        "label": "positive",
        "id": "805be54e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2210
    },
    {
        "commit_hash": "9f12ca095ab6e3295bd03fd1e50130a12b11569c",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def current_model_info(self):\n        \"\"\"\n        This function is used to extract\n        information related to current function scoping `self.log` call.\n        \"\"\"\n        model_ref = self.trainer.get_model()\n        # extract hook information\n        fx_name = model_ref._current_hook_fx_name or model_ref._current_fx_name\n        dataloader_idx = model_ref._current_dataloader_idx\n        return fx_name, dataloader_idx",
            "file_path": "commits/9f12ca095ab6e3295bd03fd1e50130a12b11569c/Before/pytorch_lightning#trainer#connectors#logger_connector#epoch_result_store.py"
        },
        "refactored_code": {
            "source_code": "def info(self):\n        \"\"\"\n        This function provides necessary parameters to properly configure HookResultStore obj\n        \"\"\"\n        model_ref = self.trainer.get_model()\n        return {\n            \"batch_idx\": self.trainer.batch_idx,\n            \"fx_name\": model_ref._current_hook_fx_name or model_ref._current_fx_name,\n            \"dataloader_idx\": model_ref._current_dataloader_idx or 0,\n            \"opt_idx\": self._opt_idx or 0,\n            \"split_idx\": self._split_idx or 0,\n            \"type\": (\n                ResultStoreType.INSIDE_BATCH_TRAIN_LOOP if self._opt_idx is not None and self._split_idx is not None\n                else ResultStoreType.OUTSIDE_BATCH_TRAIN_LOOP\n            )\n        }",
            "file_path": "commits/9f12ca095ab6e3295bd03fd1e50130a12b11569c/After/pytorch_lightning#trainer#connectors#logger_connector#epoch_result_store.py"
        },
        "variable_name": "dataloader_idx",
        "label": "positive",
        "id": "806ae3f0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1610
    },
    {
        "commit_hash": "0ac875d1a09f90e6bbeb5a14748d30f7212c1074",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "__init__",
            "container_name": "FeedForwardNetwork",
            "source_code": "def __init__(self, layers=None, hparams=None):\n        self._hparams = HParams(hparams, self.default_hparams())\n        self._template = tf.make_template(self.hparams.name, self._build,\n                                          create_scope_now_=True)\n        self._unique_name = self.variable_scope.name.split(\"/\")[-1]\n\n        if layers is not None:\n            self._layers = layers\n        else:\n            self._layers = []\n            for layer_id in range(self._hparams.layers):\n                self._layers.append(\n                    get_layer(self._hparams.layers[layer_id]))\n\n        self._layer_names = []\n        self._layers_by_name = {}\n        self._layers_outputs_by_name = {}\n        self._trainable_variables = []\n        self._built = False"
        },
        "original_method_after_refactoring": {
            "name": "__init__",
            "container_name": "FeedForwardNetwork",
            "source_code": "def __init__(self, layers=None, hparams=None):\n        ModuleBase.__init__(self, hparams)\n\n        with tf.variable_scope(self.variable_scope):\n            if layers is not None:\n                self._layers = layers\n            else:\n                self._layers = []\n                for layer_id in range(len(self._hparams.layers)):\n                    self._layers.append(\n                        get_layer(self._hparams.layers[layer_id]))\n\n        self._layer_names = []\n        self._layers_by_name = {}\n        for layer in self._layers:\n            layer_name = uniquify_str(layer.name, self._layer_names)\n            self._layer_names.append(layer_name)\n            self.layers_by_name[layer_name] = layer\n\n        self._layer_outputs = []\n        self._layer_outputs_by_name = {}"
        },
        "newly_extracted_method": {
            "name": "_build",
            "container_name": "FeedForwardNetwork",
            "source_code": "def _build(self, inputs):\n        \"\"\"\n\n        Args:\n            inputs:\n\n        Returns:\n        \"\"\"\n        prev_outputs = inputs\n        for layer_id, layer in enumerate(self._layers):\n            outputs = layer(prev_outputs)\n            self._layer_outputs.append(outputs)\n            self._layer_outputs_by_name[self._layer_names[layer_id]] = outputs\n            prev_outputs = outputs\n\n        if not self._built:\n            self._add_internal_trainable_variables()\n            # Add trainable variables of `self._layers` which may be constructed\n            # externally.\n            for layer in self._layers:\n                self._add_trainable_variable(layer.trainable_variables)\n            self._built = True\n\n        return outputs"
        },
        "label": "negative",
        "id": "805c02d6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2690
    },
    {
        "commit_hash": "425f3a1ae83c6a5d76d73a3750ffc0e0262c5fed",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "reset",
            "container_name": "AgentSpace",
            "source_code": "def reset(self):\n        for agent in self.agents:\n            agent.reset()"
        },
        "original_method_after_refactoring": {
            "name": "reset",
            "container_name": "AgentSpace",
            "source_code": "def reset(self, state_space):\n        for a, agent in enumerate(self.agents):\n            state = state_space.get(a=a)\n            agent.reset(state)"
        },
        "newly_extracted_method": {
            "name": "post_body_init",
            "container_name": "Agent",
            "source_code": "def post_body_init(self):\n        '''Run init for components that need bodies to exist first, e.g. memory or architecture.'''\n        self.memory.post_body_init()\n        self.algorithm.post_body_init()"
        },
        "label": "negative",
        "id": "805be7ba-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 741
    },
    {
        "commit_hash": "6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "conv2d_transpose",
            "container_name": "tensorflow_backend",
            "source_code": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x = _preprocess_conv2d_input(x, data_format)\n    output_shape = _preprocess_deconv_output_shape(x, output_shape, data_format)\n    padding = _preprocess_padding(padding)\n    strides = (1,) + strides + (1,)\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding)\n    x = _postprocess_conv2d_output(x, data_format)\n    return x",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/Before/keras#backend#tensorflow_backend.py"
        },
        "inlined_method": {
            "name": "_preprocess_deconv_output_shape",
            "container_name": "tensorflow_backend",
            "source_code": "def _preprocess_deconv_output_shape(x, shape, data_format):\n    \"\"\"Get the output_shape for the deconvolution.\n\n    # Arguments\n        x: input tensor.\n        shape: output shape.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n\n    # Returns\n        The output shape.\n    \"\"\"\n    if data_format == 'channels_first':\n        shape = (shape[0], shape[2], shape[3], shape[1])\n\n    if shape[0] is None:\n        shape = (tf.shape(x)[0], ) + tuple(shape[1:])\n        shape = tf.stack(list(shape))\n    return shape",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/Before/keras#backend#tensorflow_backend.py"
        },
        "caller": {
            "name": "conv2d_transpose",
            "container_name": "tensorflow_backend",
            "source_code": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n                     padding='valid', data_format=None):\n    \"\"\"2D deconvolution (i.e. transposed convolution).\n\n    # Arguments\n        x: Tensor or variable.\n        kernel: kernel tensor.\n        output_shape: 1D int tensor for the output shape.\n        strides: strides tuple.\n        padding: string, `\"same\"` or `\"valid\"`.\n        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n            Whether to use Theano or TensorFlow/CNTK data format\n            for inputs/kernels/outputs.\n\n    # Returns\n        A tensor, result of transposed 2D convolution.\n\n    # Raises\n        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n    \"\"\"\n    if data_format is None:\n        data_format = image_data_format()\n    if data_format not in {'channels_first', 'channels_last'}:\n        raise ValueError('Unknown data_format ' + str(data_format))\n    if isinstance(output_shape, (tuple, list)):\n        output_shape = tf.stack(output_shape)\n\n    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        output_shape = (output_shape[0],\n                        output_shape[2],\n                        output_shape[3],\n                        output_shape[1])\n    if output_shape[0] is None:\n        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n        output_shape = tf.stack(list(output_shape))\n\n    padding = _preprocess_padding(padding)\n    if tf_data_format == 'NHWC':\n        strides = (1,) + strides + (1,)\n    else:\n        strides = (1, 1) + strides\n\n    x = tf.nn.conv2d_transpose(x, kernel, output_shape, strides,\n                               padding=padding,\n                               data_format=tf_data_format)\n    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n    return x",
            "file_path": "commits/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/After/keras#backend#tensorflow_backend.py"
        },
        "label": "positive",
        "id": "805ee17c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4744
    },
    {
        "commit_hash": "3c382e94cf3a01f73bf96837eb6428b118555569",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "stream",
            "container_name": "audio",
            "source_code": "def stream(path, block_length, frame_length, hop_length,\n           mono=True, offset=0.0, duration=None, fill_value=None,\n           dtype=np.float32):\n    '''Stream audio in fixed-length buffers.\n\n    This is primarily useful for processing large files that won't\n    fit entirely in memory at once.\n\n    Instead of loading the entire audio signal into memory (as\n    in `load()`, this function produces *blocks* of audio spanning\n    a fixed number of frames at a specified frame length and hop\n    length.\n\n    While this function strives for similar behavior to `load`,\n    there are a few caveats that users should be aware of:\n\n        1. This function does not return audio buffers directly.\n           It returns a generator, which you can iterate over\n           to produce blocks of audio.  A *block*, in this context,\n           refers to a buffer of audio which spans a given number of\n           (potentially overlapping) frames.\n        2. Automatic sample-rate conversion is not supported.\n           Audio will be streamed in its native sample rate,\n           so no default values are provided for `frame_length`\n           and `hop_length`.  It is recommended that you first\n           get the sampling rate for the file in question, using\n           `get_samplerate()`, and set these parameters accordingly.\n        3. Many analyses require access to the entire signal\n           to behave correctly, such as `resample`, `cqt`, or\n           `beat_track`, so these methods will not be appropriate\n           for streamed data.\n        4. The `block_length` parameter specifies how many frames\n           of audio will be produced per block.  Larger values will\n           consume more memory, but will be more efficient to process\n           down-stream.  The best value will ultimately depend on your\n           application and other system constraints.\n        5. By default, most librosa analyses (e.g., short-time Fourier\n           transform) assume centered frames, which requires padding the\n           signal at the beginning and end.  This will not work correctly\n           when the signal is carved into blocks, because it would introduce\n           padding in the middle of the signal.  To disable this feature,\n           use `center=False` in all frame-based analyses.\n        \n    See the examples below for proper usage of this function.\n\n\n    Parameters\n    ----------\n    path : string, int, or file-like object\n        path to the input file to stream.\n\n        Any codec supported by `soundfile` is permitted here.\n\n    block_length : int > 0\n        The number of frames to include in each block.\n\n        Note that at the end of the file, there may not be enough\n        data to fill an entire block, resulting in a shorter block\n        by default.  To pad the signal out so that blocks are always\n        full length, set `fill_value` (see below).\n\n    frame_length : int > 0\n        The number of samples per frame.\n\n    hop_length : int > 0\n        The number of samples to advance between frames.\n\n        Note that by when `hop_length < frame_length`, neighboring frames\n        will overlap.  Similarly, the last frame of one *block* will overlap\n        with the first frame of the next *block*.\n\n    mono : bool\n        Convert the signal to mono during streaming\n\n    offset : float\n        Start reading after this time (in seconds)\n\n    duration : float\n        Only load up to this much audio (in seconds)\n\n    fill_value : float [optional]\n        If padding the signal to produce constant-length blocks,\n        this value will be used at the end of the signal.\n\n        In most cases, `fill_value=0` (silence) is expected, but\n        you may specify any value here.\n\n    dtype : numeric type\n        data type of audio buffers to be produced\n\n    Returns\n    -------\n    stream : generator\n        A generator which produces blocks of audio.\n\n    sr : number > 0\n        The sampling rate of the audio\n\n    See Also\n    --------\n    load\n    get_samplerate\n    soundfile.blocks\n\n    Examples\n    --------\n    Apply a short-term Fourier transform to blocks of 256 frames\n    at a time.  Note that streaming operation requires left-aligned\n    frames, so we must set `center=False` to avoid padding artifacts.\n\n    >>> stream, sr = librosa.stream(librosa.util.example_audio_file(),\n    ...                             block_length=256,\n    ...                             frame_length=4096,\n    ...                             hop_length=1024)\n    >>> for y_block in stream:\n    ...     D_block = librosa.stft(y_block, center=False)\n\n    Or compute a mel spectrogram over a stream, using a shorter frame\n    and non-overlapping windows\n\n    >>> stream, sr = librosa.stream(librosa.util.example_audio_file(),\n    ...                             block_length=256,\n    ...                             frame_length=2048,\n    ...                             hop_length=2048)\n    >>> for y_block in stream:\n    ...     m_block = librosa.feature.melspectrogram(y_block, sr=sr,\n    ...                                              n_fft=2048,\n    ...                                              hop_length=2048,\n    ...                                              center=False)\n\n    '''\n\n    if not (isinstance(block_length, int) and block_length > 0):\n        raise ParameterError('block_length={} must be a positive integer')\n    if not (isinstance(frame_length, int) and frame_length > 0):\n        raise ParameterError('frame_length={} must be a positive integer')\n    if not (isinstance(hop_length, int) and hop_length > 0):\n        raise ParameterError('hop_length={} must be a positive integer')\n\n    # Get the sample rate from the file info\n    sr = sf.info(path).samplerate\n\n    # Construct the stream\n    block_stream = __stream(path, sr, block_length, frame_length, hop_length,\n                            mono, offset, duration, fill_value, dtype)\n\n    return block_stream, sr",
            "file_path": "commits/3c382e94cf3a01f73bf96837eb6428b118555569/Before/librosa#core#audio.py"
        },
        "inlined_method": {
            "name": "__stream",
            "container_name": "audio",
            "source_code": "def __stream(path, sr, block_length, frame_length, hop_length,\n             mono, offset, duration, fill_value, dtype):\n    '''Private function for wrapping sf.blocks in a librosa interface.'''\n\n    if offset:\n        start = int(offset * sr)\n    else:\n        start = 0\n\n    if duration:\n        frames = int(duration * sr)\n    else:\n        frames = -1\n\n    blocks = sf.blocks(path,\n                       blocksize=frame_length + (block_length - 1) * hop_length,\n                       overlap=frame_length - hop_length,\n                       fill_value=fill_value,\n                       start=start,\n                       frames=frames,\n                       dtype=dtype,\n                       always_2d=False)\n\n    for block in blocks:\n        if mono:\n            yield to_mono(block.T)\n        else:\n            yield block.T",
            "file_path": "commits/3c382e94cf3a01f73bf96837eb6428b118555569/Before/librosa#core#audio.py"
        },
        "caller": {
            "name": "stream",
            "container_name": "audio",
            "source_code": "def stream(path, block_length, frame_length, hop_length,\n           mono=True, offset=0.0, duration=None, fill_value=None,\n           dtype=np.float32):\n    '''Stream audio in fixed-length buffers.\n\n    This is primarily useful for processing large files that won't\n    fit entirely in memory at once.\n\n    Instead of loading the entire audio signal into memory (as\n    in `load()`, this function produces *blocks* of audio spanning\n    a fixed number of frames at a specified frame length and hop\n    length.\n\n    While this function strives for similar behavior to `load`,\n    there are a few caveats that users should be aware of:\n\n        1. This function does not return audio buffers directly.\n           It returns a generator, which you can iterate over\n           to produce blocks of audio.  A *block*, in this context,\n           refers to a buffer of audio which spans a given number of\n           (potentially overlapping) frames.\n        2. Automatic sample-rate conversion is not supported.\n           Audio will be streamed in its native sample rate,\n           so no default values are provided for `frame_length`\n           and `hop_length`.  It is recommended that you first\n           get the sampling rate for the file in question, using\n           `get_samplerate()`, and set these parameters accordingly.\n        3. Many analyses require access to the entire signal\n           to behave correctly, such as `resample`, `cqt`, or\n           `beat_track`, so these methods will not be appropriate\n           for streamed data.\n        4. The `block_length` parameter specifies how many frames\n           of audio will be produced per block.  Larger values will\n           consume more memory, but will be more efficient to process\n           down-stream.  The best value will ultimately depend on your\n           application and other system constraints.\n        5. By default, most librosa analyses (e.g., short-time Fourier\n           transform) assume centered frames, which requires padding the\n           signal at the beginning and end.  This will not work correctly\n           when the signal is carved into blocks, because it would introduce\n           padding in the middle of the signal.  To disable this feature,\n           use `center=False` in all frame-based analyses.\n        \n    See the examples below for proper usage of this function.\n\n\n    Parameters\n    ----------\n    path : string, int, or file-like object\n        path to the input file to stream.\n\n        Any codec supported by `soundfile` is permitted here.\n\n    block_length : int > 0\n        The number of frames to include in each block.\n\n        Note that at the end of the file, there may not be enough\n        data to fill an entire block, resulting in a shorter block\n        by default.  To pad the signal out so that blocks are always\n        full length, set `fill_value` (see below).\n\n    frame_length : int > 0\n        The number of samples per frame.\n\n    hop_length : int > 0\n        The number of samples to advance between frames.\n\n        Note that by when `hop_length < frame_length`, neighboring frames\n        will overlap.  Similarly, the last frame of one *block* will overlap\n        with the first frame of the next *block*.\n\n    mono : bool\n        Convert the signal to mono during streaming\n\n    offset : float\n        Start reading after this time (in seconds)\n\n    duration : float\n        Only load up to this much audio (in seconds)\n\n    fill_value : float [optional]\n        If padding the signal to produce constant-length blocks,\n        this value will be used at the end of the signal.\n\n        In most cases, `fill_value=0` (silence) is expected, but\n        you may specify any value here.\n\n    dtype : numeric type\n        data type of audio buffers to be produced\n\n    Yields\n    ------\n    y : np.ndarray\n        An audio buffer of (at most) \n        `block_length * (hop_length-1) + frame_length` samples.\n\n    See Also\n    --------\n    load\n    get_samplerate\n    soundfile.blocks\n\n    Examples\n    --------\n    Apply a short-term Fourier transform to blocks of 256 frames\n    at a time.  Note that streaming operation requires left-aligned\n    frames, so we must set `center=False` to avoid padding artifacts.\n\n    >>> filename = librosa.util.example_audio_file()\n    >>> sr = librosa.get_samplerate(filename)\n    >>> stream librosa.stream(filename,\n    ...                       block_length=256,\n    ...                       frame_length=4096,\n    ...                       hop_length=1024)\n    >>> for y_block in stream:\n    ...     D_block = librosa.stft(y_block, center=False)\n\n    Or compute a mel spectrogram over a stream, using a shorter frame\n    and non-overlapping windows\n\n    >>> filename = librosa.util.example_audio_file()\n    >>> sr = librosa.get_samplerate(filename)\n    >>> stream = librosa.stream(filename,\n    ...                         block_length=256,\n    ...                         frame_length=2048,\n    ...                         hop_length=2048)\n    >>> for y_block in stream:\n    ...     m_block = librosa.feature.melspectrogram(y_block, sr=sr,\n    ...                                              n_fft=2048,\n    ...                                              hop_length=2048,\n    ...                                              center=False)\n\n    '''\n\n    if not (isinstance(block_length, int) and block_length > 0):\n        raise ParameterError('block_length={} must be a positive integer')\n    if not (isinstance(frame_length, int) and frame_length > 0):\n        raise ParameterError('frame_length={} must be a positive integer')\n    if not (isinstance(hop_length, int) and hop_length > 0):\n        raise ParameterError('hop_length={} must be a positive integer')\n\n    # Get the sample rate from the file info\n    sr = sf.info(path).samplerate\n\n    # Construct the stream\n    if offset:\n        start = int(offset * sr)\n    else:\n        start = 0\n\n    if duration:\n        frames = int(duration * sr)\n    else:\n        frames = -1\n\n    blocks = sf.blocks(path,\n                       blocksize=frame_length + (block_length - 1) * hop_length,\n                       overlap=frame_length - hop_length,\n                       fill_value=fill_value,\n                       start=start,\n                       frames=frames,\n                       dtype=dtype,\n                       always_2d=False)\n\n    for block in blocks:\n        if mono:\n            yield to_mono(block.T)\n        else:\n            yield block.T",
            "file_path": "commits/3c382e94cf3a01f73bf96837eb6428b118555569/After/librosa#core#audio.py"
        },
        "label": "positive",
        "id": "805edd76-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 14183
    },
    {
        "commit_hash": "c270e59bf951bca41743bd03272e5b3f255be97c",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def _generate_hp_values(self, hp_list):\n        best_trials = self.get_best_trials()\n        if best_trials:\n            best_hps = best_trials[0].hyperparameters\n        else:\n            best_hps = self.hyperparameters\n\n        collisions = 0\n        while True:\n            hps = copy.deepcopy(best_hps)\n            # Generate a set of random values.\n            for hp in hp_list:\n                # TODO: Check is_active for hp.\n                hps.values[hp.name] = hp.random_sample(self._seed_state)\n                self._seed_state += 1\n            values = hps.values\n            # Keep trying until the set of values is unique,\n            # or until we exit due to too many collisions.\n            values_hash = self._compute_values_hash(values)\n            if values_hash in self._tried_so_far:\n                collisions += 1\n                if collisions <= self._max_collisions:\n                    continue\n                return None\n            self._tried_so_far.add(values_hash)\n            break\n        return values",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/Before/autokeras#tuners#greedy.py"
        },
        "refactored_code": {
            "source_code": "def _get_best_hps(self):\n        best_trials = self.get_best_trials()\n        if best_trials:\n            return best_trials[0].hyperparameters\n        else:\n            return self.hyperparameters",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/After/autokeras#tuners#greedy.py"
        },
        "variable_name": "best_hps",
        "label": "positive",
        "id": "806aea44-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1607
    },
    {
        "commit_hash": "f7815e3bdcd9595480841e3ac1d0fb609e9c0f1a",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def transform_y(self, y_train):\n        # Transform y_train.\n        if self.y_encoder is None:\n            self.y_encoder = OneHotEncoder()\n            self.y_encoder.fit(y_train)\n        y_train = self.y_encoder.transform(y_train)\n        return y_train",
            "file_path": "commits/f7815e3bdcd9595480841e3ac1d0fb609e9c0f1a/Before/autokeras#image#image_supervised.py"
        },
        "refactored_code": {
            "source_code": "def transform_y(self, y):\n        \"\"\"Transform the parameter y_train using the variable self.y_encoder\n        \n        Args:\n            y: list of labels to convert\n        \"\"\"\n        # Transform y.\n        if self.y_encoder is None:\n            self.y_encoder = OneHotEncoder()\n            self.y_encoder.fit(y)\n        y = self.y_encoder.transform(y)\n        return y",
            "file_path": "commits/f7815e3bdcd9595480841e3ac1d0fb609e9c0f1a/After/autokeras#image#image_supervised.py"
        },
        "original_variable_name": "y_train",
        "new_variable_name": "y",
        "label": "positive",
        "id": "8067906a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1004
    },
    {
        "commit_hash": "977ec7cf04facbfecab9b6b3214d5541948d287b",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def fit(self,x, y, batch_size=1024, epochs=50, validation_split = 0.0, validation_data=None,\n            val_size=2 ** 18, shuffle=True,initial_epoch=0,min_display=50,max_iter=-1):\n        \n        if validation_split < 0 or validation_split >= 1:\n            raise ValueError(\"validation_split must be a float number >= 0 and < 1\")\n        \n        n_samples = x.shape[0]\n        iters = (n_samples - 1) // batch_size + 1\n        self.tr_loss_list = []\n        self.val_loss_list = []\n        print(iters, \"steps per epoch\")\n        print(batch_size, \"samples per step\")\n        start_time = time.time()\n        stop_flag = False\n        self.best_loss = np.inf\n        self.best_ckpt = None\n        if not validation_data and validation_split > 0:\n            x,val_x,y,val_y = train_test_split(x,y,test_size = validation_split,random_state = self.seed)\n            validation_data = [(val_x,val_y)]\n        \n        \n        for i in range(epochs):\n            if i < initial_epoch:\n                continue\n            if shuffle:\n                x,y = sklearn_shuffle(x,y, random_state=self.seed) \n            for j in range(iters):\n                batch_x = x[j * batch_size:(j + 1) * batch_size]\n                batch_y = y[j * batch_size:(j + 1) * batch_size]\n                \n                l = self.train_on_batch(batch_x, batch_y )\n                if j % min_display == 0:\n                    tr_loss = self.evaluate(x, y, val_size)\n                    self.tr_loss_list.append(tr_loss)\n                    total_time = time.time() - start_time\n                    if validation_data is None:\n                        print(\"Epoch {0: 2d} Step {1: 4d}: tr_loss {2: 0.6f} tr_time {3: 0.1f}\".format(i, j, tr_loss,\n                                                                                                       total_time))\n                    else:\n                        val_loss = self.evaluate(validation_data[0][0], validation_data[0][1], val_size)\n                        self.val_loss_list.append(val_loss)\n                        print(\n                            \"Epoch {0: 2d} Step {1: 4d}: tr_loss {2: 0.6f} va_loss {3: 0.6f} tr_time {4: 0.1f}\".format(\n                                i, j, tr_loss, val_loss, total_time))\n\n                        if val_loss < self.best_loss:\n                            self.best_loss = val_loss\n                            # self.save_model(self.checkpoint_path+'best')\n\n                # self.save_model(self.checkpoint_path)\n\n                if (i * iters) + j == max_iter:\n                    stop_flag = True\n                    break\n            if stop_flag:\n                break",
            "file_path": "commits/977ec7cf04facbfecab9b6b3214d5541948d287b/Before/base.py"
        },
        "refactored_code": {
            "source_code": "def fit(self,x, y, batch_size=1024, epochs=50, validation_split = 0.0, validation_data=None,\n            val_size=2 ** 18, shuffle=True,initial_epoch=0,min_display=50,max_iter=-1):\n        \n        if validation_split < 0 or validation_split >= 1:\n            raise ValueError(\"validation_split must be a float number >= 0 and < 1\")\n        \n        n_samples = x.shape[0]\n        iters = (n_samples - 1) // batch_size + 1\n        self.tr_loss_list = []\n        self.val_loss_list = []\n        print(iters, \"steps per epoch\")\n        print(batch_size, \"samples per step\")\n        start_time = time.time()\n        stop_flag = False\n        self.best_loss = np.inf\n        self.best_ckpt = None\n        if not validation_data and validation_split > 0:\n            x,val_x,y,val_y = train_test_split(x,y,test_size = validation_split,random_state = self.seed)\n            validation_data = [(val_x,val_y)]\n        \n        \n        for i in range(epochs):\n            if i < initial_epoch:\n                continue\n            if shuffle:\n                x,y = sklearn_shuffle(x,y, random_state=self.seed) \n            for j in range(iters):\n                batch_x = x[j * batch_size:(j + 1) * batch_size]\n                batch_y = y[j * batch_size:(j + 1) * batch_size]\n                \n                self.train_on_batch(batch_x, batch_y )\n                if j % min_display == 0:\n                    tr_loss = self.evaluate(x, y, val_size)\n                    self.tr_loss_list.append(tr_loss)\n                    total_time = time.time() - start_time\n                    if validation_data is None:\n                        print(\"Epoch {0: 2d} Step {1: 4d}: tr_loss {2: 0.6f} tr_time {3: 0.1f}\".format(i, j, tr_loss,\n                                                                                                       total_time))\n                    else:\n                        val_loss = self.evaluate(validation_data[0][0], validation_data[0][1], val_size)\n                        self.val_loss_list.append(val_loss)\n                        print(\n                            \"Epoch {0: 2d} Step {1: 4d}: tr_loss {2: 0.6f} va_loss {3: 0.6f} tr_time {4: 0.1f}\".format(\n                                i, j, tr_loss, val_loss, total_time))\n\n                        if val_loss < self.best_loss:\n                            self.best_loss = val_loss\n                            # self.save_model(self.checkpoint_path+'best')\n\n                # self.save_model(self.checkpoint_path)\n\n                if (i * iters) + j == max_iter:\n                    stop_flag = True\n                    break\n            if stop_flag:\n                break",
            "file_path": "commits/977ec7cf04facbfecab9b6b3214d5541948d287b/After/base.py"
        },
        "variable_name": "l",
        "label": "positive",
        "id": "806ae558-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5709
    },
    {
        "commit_hash": "47c41fcd8f5eec1cb38b8709472b5356a3092588",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "load",
            "container_name": "audio",
            "source_code": "def load(path, sr=22050, mono=True, offset=0.0, duration=None,\n         dtype=np.float32, res_type='kaiser_best'):\n    \"\"\"Load an audio file as a floating point time series.\n\n    Audio will be automatically resampled to the given rate\n    (default `sr=22050`).\n\n    To preserve the native sampling rate of the file, use `sr=None`.\n\n    Parameters\n    ----------\n    path : string\n        path to the input file.\n\n        Any format supported by `audioread` will work.\n\n    sr   : number > 0 [scalar]\n        target sampling rate\n\n        'None' uses the native sampling rate\n\n    mono : bool\n        convert signal to mono\n\n    offset : float\n        start reading after this time (in seconds)\n\n    duration : float\n        only load up to this much audio (in seconds)\n\n    dtype : numeric type\n        data type of `y`\n\n    res_type : str\n        resample type (see note)\n\n        .. note::\n            By default, this uses `resampy`'s high-quality mode ('kaiser_best').\n\n            To use a faster method, set `res_type='kaiser_fast'`.\n\n            To use `scipy.signal.resample`, set `res_type='scipy'`.\n            \n        .. note::\n           This uses `audioread`, which may truncate the precision of the\n           audio data to 16 bits.\n\n           See https://librosa.github.io/librosa/ioformats.html for alternate\n           loading methods.\n\n\n    Returns\n    -------\n    y    : np.ndarray [shape=(n,) or (2, n)]\n        audio time series\n\n    sr   : number > 0 [scalar]\n        sampling rate of `y`\n\n\n    Examples\n    --------\n    >>> # Load a wav file\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename)\n    >>> y\n    array([ -4.756e-06,  -6.020e-06, ...,  -1.040e-06,   0.000e+00], dtype=float32)\n    >>> sr\n    22050\n\n    >>> # Load a wav file and resample to 11 KHz\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename, sr=11025)\n    >>> y\n    array([ -2.077e-06,  -2.928e-06, ...,  -4.395e-06,   0.000e+00], dtype=float32)\n    >>> sr\n    11025\n\n    >>> # Load 5 seconds of a wav file, starting 15 seconds in\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename, offset=15.0, duration=5.0)\n    >>> y\n    array([ 0.069,  0.1  , ..., -0.101,  0.   ], dtype=float32)\n    >>> sr\n    22050\n\n    \"\"\"\n\n    y = []\n    with audioread.audio_open(path) as input_file:\n        sr_native = input_file.samplerate\n        n_channels = input_file.channels\n\n        s_start = int(np.round(sr_native * offset)) * n_channels\n\n        if duration is None:\n            s_end = np.inf\n        else:\n            s_end = s_start + (int(np.round(sr_native * duration))\n                               * n_channels)\n\n        n = 0\n\n        for frame in input_file:\n            frame = util.buf_to_float(frame, dtype=dtype)\n            n_prev = n\n            n = n + len(frame)\n\n            if n < s_start:\n                # offset is after the current frame\n                # keep reading\n                continue\n\n            if s_end < n_prev:\n                # we're off the end.  stop reading\n                break\n\n            if s_end < n:\n                # the end is in this frame.  crop.\n                frame = frame[:s_end - n_prev]\n\n            if n_prev <= s_start <= n:\n                # beginning is in this frame\n                frame = frame[(s_start - n_prev):]\n\n            # tack on the current frame\n            y.append(frame)\n\n    if y:\n        y = np.concatenate(y)\n\n        if n_channels > 1:\n            y = y.reshape((-1, n_channels)).T\n            if mono:\n                y = to_mono(y)\n\n        if sr is not None:\n            y = resample(y, sr_native, sr, res_type=res_type)\n\n        else:\n            sr = sr_native\n\n    # Final cleanup for dtype and contiguity\n    y = np.ascontiguousarray(y, dtype=dtype)\n\n    return (y, sr)"
        },
        "original_method_after_refactoring": {
            "name": "load",
            "container_name": "audio",
            "source_code": "def load(path, sr=22050, mono=True, offset=0.0, duration=None,\n         dtype=np.float32, res_type='kaiser_best'):\n    \"\"\"Load an audio file as a floating point time series.\n\n    Audio will be automatically resampled to the given rate\n    (default `sr=22050`).\n\n    To preserve the native sampling rate of the file, use `sr=None`.\n\n    Parameters\n    ----------\n    path : string\n        path to the input file.\n\n        Any format supported by `audioread` will work.\n\n    sr   : number > 0 [scalar]\n        target sampling rate\n\n        'None' uses the native sampling rate\n\n    mono : bool\n        convert signal to mono\n\n    offset : float\n        start reading after this time (in seconds)\n\n    duration : float\n        only load up to this much audio (in seconds)\n\n    dtype : numeric type\n        data type of `y`\n\n    res_type : str\n        resample type (see note)\n\n        .. note::\n            By default, this uses `resampy`'s high-quality mode ('kaiser_best').\n\n            To use a faster method, set `res_type='kaiser_fast'`.\n\n            To use `scipy.signal.resample`, set `res_type='scipy'`.\n\n        .. note::\n           This uses `audioread`, which may truncate the precision of the\n           audio data to 16 bits.\n\n           See https://librosa.github.io/librosa/ioformats.html for alternate\n           loading methods.\n\n\n    Returns\n    -------\n    y    : np.ndarray [shape=(n,) or (2, n)]\n        audio time series\n\n    sr   : number > 0 [scalar]\n        sampling rate of `y`\n\n\n    Examples\n    --------\n    >>> # Load a wav file\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename)\n    >>> y\n    array([ -4.756e-06,  -6.020e-06, ...,  -1.040e-06,   0.000e+00], dtype=float32)\n    >>> sr\n    22050\n\n    >>> # Load a wav file and resample to 11 KHz\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename, sr=11025)\n    >>> y\n    array([ -2.077e-06,  -2.928e-06, ...,  -4.395e-06,   0.000e+00], dtype=float32)\n    >>> sr\n    11025\n\n    >>> # Load 5 seconds of a wav file, starting 15 seconds in\n    >>> filename = librosa.util.example_audio_file()\n    >>> y, sr = librosa.load(filename, offset=15.0, duration=5.0)\n    >>> y\n    array([ 0.069,  0.1  , ..., -0.101,  0.   ], dtype=float32)\n    >>> sr\n    22050\n\n    \"\"\"\n\n    try:\n        with sf.SoundFile(path) as sf_desc:\n            sr_native = sf_desc.samplerate\n            if offset:\n                # Seek to the start of the target read\n                sf_desc.seek(offset * sr_native)\n            if duration:\n                frame_duration = duration * sr_native\n\n            # Load the target number of frames, and transpose to match librosa form\n            y = sf_desc.read(frames=frame_duration, dtype=dtype, always_2d=False).T\n    except:\n        # If soundfile failed, fall back to the audioread loader\n        y, sr_native = __audioread_load(path, offset, duration, dtype)\n\n    # Final cleanup for dtype and contiguity\n    if mono:\n        y = to_mono(y)\n\n    if sr is not None:\n        y = resample(y, sr_native, sr, res_type=res_type)\n\n    else:\n        sr = sr_native\n\n    return y, sr"
        },
        "newly_extracted_method": {
            "name": "__audioread_load",
            "container_name": "audio",
            "source_code": "def __audioread_load(path, offset, duration, dtype):\n    '''Load an audio buffer using audioread.\n\n    This loads one block at a time, and then concatenates the results.\n    '''\n\n    y = []\n    with audioread.audio_open(path) as input_file:\n        sr_native = input_file.samplerate\n        n_channels = input_file.channels\n\n        s_start = int(np.round(sr_native * offset)) * n_channels\n\n        if duration is None:\n            s_end = np.inf\n        else:\n            s_end = s_start + (int(np.round(sr_native * duration))\n                               * n_channels)\n\n        n = 0\n\n        for frame in input_file:\n            frame = util.buf_to_float(frame, dtype=dtype)\n            n_prev = n\n            n = n + len(frame)\n\n            if n < s_start:\n                # offset is after the current frame\n                # keep reading\n                continue\n\n            if s_end < n_prev:\n                # we're off the end.  stop reading\n                break\n\n            if s_end < n:\n                # the end is in this frame.  crop.\n                frame = frame[:s_end - n_prev]\n\n            if n_prev <= s_start <= n:\n                # beginning is in this frame\n                frame = frame[(s_start - n_prev):]\n\n            # tack on the current frame\n            y.append(frame)\n\n    if y:\n        y = np.concatenate(y)\n        if n_channels > 1:\n            y = y.reshape((-1, n_channels)).T\n    else:\n        y = np.empty(0, dtype=dtype)\n\n    return y, sr_native"
        },
        "label": "positive",
        "id": "805bed6e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 9137
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    tmp = tf.tile(tf.range(label_shape[0]), max_num_labels_tns)\n    batch_array = tf.transpose(tf.reshape(tmp, reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n\n    indices = concatenate([batch_ind, label_ind], axis=0)\n    indices = tf.transpose(tf.reshape(indices, [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    indices = tf.to_int64(indices)\n    label_shape = tf.to_int64(label_shape)\n    return tf.SparseTensor(indices, vals_sparse, label_shape)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "indices",
        "label": "positive",
        "id": "8069bbce-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3393
    },
    {
        "commit_hash": "90780bfa782b6c4fa0cac0cda10210d162fb516d",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "stream",
            "container_name": "audio",
            "source_code": "def stream(path, block_length, frame_length, hop_length,\n           mono=True, offset=0.0, duration=None, fill_value=None,\n           dtype=np.float32):\n    '''Stream audio in fixed-length buffers.\n\n    This is primarily useful for processing large files that won't\n    fit entirely in memory at once.\n\n    Instead of loading the entire audio signal into memory (as\n    in `load()`, this function produces *blocks* of audio spanning\n    a fixed number of frames at a specified frame length and hop\n    length.\n\n    While this function strives for similar behavior to `load`,\n    there are a few caveats that users should be aware of:\n\n        1. This function does not return audio buffers directly.\n           It returns a generator, which you can iterate over\n           to produce blocks of audio.  A *block*, in this context,\n           refers to a buffer of audio which spans a given number of\n           (potentially overlapping) frames.\n        2. Automatic sample-rate conversion is not supported.\n           Audio will be streamed in its native sample rate,\n           so no default values are provided for `frame_length`\n           and `hop_length`.  It is recommended that you first\n           get the sampling rate for the file in question, using\n           `get_samplerate()`, and set these parameters accordingly.\n        3. Many analyses require access to the entire signal\n           to behave correctly, such as `resample`, `cqt`, or\n           `beat_track`, so these methods will not be appropriate\n           for streamed data.\n        4. The `block_length` parameter specifies how many frames\n           of audio will be produced per block.  Larger values will\n           consume more memory, but will be more efficient to process\n           down-stream.  The best value will ultimately depend on your\n           application and other system constraints.\n        5. By default, most librosa analyses (e.g., short-time Fourier\n           transform) assume centered frames, which requires padding the\n           signal at the beginning and end.  This will not work correctly\n           when the signal is carved into blocks, because it would introduce\n           padding in the middle of the signal.  To disable this feature,\n           use `center=False` in all frame-based analyses.\n        \n    See the examples below for proper usage of this function.\n\n\n    Parameters\n    ----------\n    path : string, int, or file-like object\n        path to the input file to stream.\n\n        Any codec supported by `soundfile` is permitted here.\n\n    block_length : int > 0\n        The number of frames to include in each block.\n\n        Note that at the end of the file, there may not be enough\n        data to fill an entire block, resulting in a shorter block\n        by default.  To pad the signal out so that blocks are always\n        full length, set `fill_value` (see below).\n\n    frame_length : int > 0\n        The number of samples per frame.\n\n    hop_length : int > 0\n        The number of samples to advance between frames.\n\n        Note that by when `hop_length < frame_length`, neighboring frames\n        will overlap.  Similarly, the last frame of one *block* will overlap\n        with the first frame of the next *block*.\n\n    mono : bool\n        Convert the signal to mono during streaming\n\n    offset : float\n        Start reading after this time (in seconds)\n\n    duration : float\n        Only load up to this much audio (in seconds)\n\n    fill_value : float [optional]\n        If padding the signal to produce constant-length blocks,\n        this value will be used at the end of the signal.\n\n        In most cases, `fill_value=0` (silence) is expected, but\n        you may specify any value here.\n\n    dtype : numeric type\n        data type of audio buffers to be produced\n\n    Returns\n    -------\n    stream : generator\n        A generator which produces blocks of audio.\n\n    sr : number > 0\n        The sampling rate of the audio\n\n    See Also\n    --------\n    load\n    get_samplerate\n    soundfile.blocks\n\n    Examples\n    --------\n    Apply a short-term Fourier transform to blocks of 256 frames\n    at a time.  Note that streaming operation requires left-aligned\n    frames, so we must set `center=False` to avoid padding artifacts.\n\n    >>> stream, sr = librosa.stream(librosa.util.example_audio_file(),\n    ...                             block_length=256,\n    ...                             frame_length=4096,\n    ...                             hop_length=1024)\n    >>> for y_block in stream:\n    ...     D_block = librosa.stft(y_block, center=False)\n\n    Or compute a mel spectrogram over a stream, using a shorter frame\n    and non-overlapping windows\n\n    >>> stream, sr = librosa.stream(librosa.util.example_audio_file(),\n    ...                             block_length=256,\n    ...                             frame_length=2048,\n    ...                             hop_length=2048)\n    >>> for y_block in stream:\n    ...     m_block = librosa.feature.melspectrogram(y_block, sr=sr,\n    ...                                              n_fft=2048,\n    ...                                              hop_length=2048,\n    ...                                              center=False)\n\n    '''\n\n    if not (isinstance(block_length, int) and block_length > 0):\n        raise ParameterError('block_length={} must be a positive integer')\n    if not (isinstance(frame_length, int) and frame_length > 0):\n        raise ParameterError('frame_length={} must be a positive integer')\n    if not (isinstance(hop_length, int) and hop_length > 0):\n        raise ParameterError('hop_length={} must be a positive integer')\n\n    # Get the sample rate from the file info\n    sr = sf.info(path).samplerate\n\n    # Construct the stream\n    block_stream = __stream(path, sr, block_length, frame_length, hop_length,\n                            mono, offset, duration, fill_value, dtype)\n\n    return block_stream, sr",
            "file_path": "commits/90780bfa782b6c4fa0cac0cda10210d162fb516d/Before/librosa#core#audio.py"
        },
        "inlined_method": {
            "name": "__stream",
            "container_name": "audio",
            "source_code": "def __stream(path, sr, block_length, frame_length, hop_length,\n             mono, offset, duration, fill_value, dtype):\n    '''Private function for wrapping sf.blocks in a librosa interface.'''\n\n    if offset:\n        start = int(offset * sr)\n    else:\n        start = 0\n\n    if duration:\n        frames = int(duration * sr)\n    else:\n        frames = -1\n\n    blocks = sf.blocks(path,\n                       blocksize=frame_length + (block_length - 1) * hop_length,\n                       overlap=frame_length - hop_length,\n                       fill_value=fill_value,\n                       start=start,\n                       frames=frames,\n                       dtype=dtype,\n                       always_2d=False)\n\n    for block in blocks:\n        if mono:\n            yield to_mono(block.T)\n        else:\n            yield block.T",
            "file_path": "commits/90780bfa782b6c4fa0cac0cda10210d162fb516d/Before/librosa#core#audio.py"
        },
        "caller": {
            "name": "stream",
            "container_name": "audio",
            "source_code": "def stream(path, block_length, frame_length, hop_length,\n           mono=True, offset=0.0, duration=None, fill_value=None,\n           dtype=np.float32):\n    '''Stream audio in fixed-length buffers.\n\n    This is primarily useful for processing large files that won't\n    fit entirely in memory at once.\n\n    Instead of loading the entire audio signal into memory (as\n    in `load()`, this function produces *blocks* of audio spanning\n    a fixed number of frames at a specified frame length and hop\n    length.\n\n    While this function strives for similar behavior to `load`,\n    there are a few caveats that users should be aware of:\n\n        1. This function does not return audio buffers directly.\n           It returns a generator, which you can iterate over\n           to produce blocks of audio.  A *block*, in this context,\n           refers to a buffer of audio which spans a given number of\n           (potentially overlapping) frames.\n        2. Automatic sample-rate conversion is not supported.\n           Audio will be streamed in its native sample rate,\n           so no default values are provided for `frame_length`\n           and `hop_length`.  It is recommended that you first\n           get the sampling rate for the file in question, using\n           `get_samplerate()`, and set these parameters accordingly.\n        3. Many analyses require access to the entire signal\n           to behave correctly, such as `resample`, `cqt`, or\n           `beat_track`, so these methods will not be appropriate\n           for streamed data.\n        4. The `block_length` parameter specifies how many frames\n           of audio will be produced per block.  Larger values will\n           consume more memory, but will be more efficient to process\n           down-stream.  The best value will ultimately depend on your\n           application and other system constraints.\n        5. By default, most librosa analyses (e.g., short-time Fourier\n           transform) assume centered frames, which requires padding the\n           signal at the beginning and end.  This will not work correctly\n           when the signal is carved into blocks, because it would introduce\n           padding in the middle of the signal.  To disable this feature,\n           use `center=False` in all frame-based analyses.\n        \n    See the examples below for proper usage of this function.\n\n\n    Parameters\n    ----------\n    path : string, int, or file-like object\n        path to the input file to stream.\n\n        Any codec supported by `soundfile` is permitted here.\n\n    block_length : int > 0\n        The number of frames to include in each block.\n\n        Note that at the end of the file, there may not be enough\n        data to fill an entire block, resulting in a shorter block\n        by default.  To pad the signal out so that blocks are always\n        full length, set `fill_value` (see below).\n\n    frame_length : int > 0\n        The number of samples per frame.\n\n    hop_length : int > 0\n        The number of samples to advance between frames.\n\n        Note that by when `hop_length < frame_length`, neighboring frames\n        will overlap.  Similarly, the last frame of one *block* will overlap\n        with the first frame of the next *block*.\n\n    mono : bool\n        Convert the signal to mono during streaming\n\n    offset : float\n        Start reading after this time (in seconds)\n\n    duration : float\n        Only load up to this much audio (in seconds)\n\n    fill_value : float [optional]\n        If padding the signal to produce constant-length blocks,\n        this value will be used at the end of the signal.\n\n        In most cases, `fill_value=0` (silence) is expected, but\n        you may specify any value here.\n\n    dtype : numeric type\n        data type of audio buffers to be produced\n\n    Yields\n    ------\n    y : np.ndarray\n        An audio buffer of (at most) \n        `block_length * (hop_length-1) + frame_length` samples.\n\n    See Also\n    --------\n    load\n    get_samplerate\n    soundfile.blocks\n\n    Examples\n    --------\n    Apply a short-term Fourier transform to blocks of 256 frames\n    at a time.  Note that streaming operation requires left-aligned\n    frames, so we must set `center=False` to avoid padding artifacts.\n\n    >>> filename = librosa.util.example_audio_file()\n    >>> sr = librosa.get_samplerate(filename)\n    >>> stream librosa.stream(filename,\n    ...                       block_length=256,\n    ...                       frame_length=4096,\n    ...                       hop_length=1024)\n    >>> for y_block in stream:\n    ...     D_block = librosa.stft(y_block, center=False)\n\n    Or compute a mel spectrogram over a stream, using a shorter frame\n    and non-overlapping windows\n\n    >>> filename = librosa.util.example_audio_file()\n    >>> sr = librosa.get_samplerate(filename)\n    >>> stream = librosa.stream(filename,\n    ...                         block_length=256,\n    ...                         frame_length=2048,\n    ...                         hop_length=2048)\n    >>> for y_block in stream:\n    ...     m_block = librosa.feature.melspectrogram(y_block, sr=sr,\n    ...                                              n_fft=2048,\n    ...                                              hop_length=2048,\n    ...                                              center=False)\n\n    '''\n\n    if not (isinstance(block_length, int) and block_length > 0):\n        raise ParameterError('block_length={} must be a positive integer')\n    if not (isinstance(frame_length, int) and frame_length > 0):\n        raise ParameterError('frame_length={} must be a positive integer')\n    if not (isinstance(hop_length, int) and hop_length > 0):\n        raise ParameterError('hop_length={} must be a positive integer')\n\n    # Get the sample rate from the file info\n    sr = sf.info(path).samplerate\n\n    # Construct the stream\n    if offset:\n        start = int(offset * sr)\n    else:\n        start = 0\n\n    if duration:\n        frames = int(duration * sr)\n    else:\n        frames = -1\n\n    blocks = sf.blocks(path,\n                       blocksize=frame_length + (block_length - 1) * hop_length,\n                       overlap=frame_length - hop_length,\n                       fill_value=fill_value,\n                       start=start,\n                       frames=frames,\n                       dtype=dtype,\n                       always_2d=False)\n\n    for block in blocks:\n        if mono:\n            yield to_mono(block.T)\n        else:\n            yield block.T",
            "file_path": "commits/90780bfa782b6c4fa0cac0cda10210d162fb516d/After/librosa#core#audio.py"
        },
        "label": "positive",
        "id": "805edce0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 14183
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(label_shape[0]),\n                                                  max_num_labels_tns), reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n    indices = tf.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def ctc_label_dense_to_sparse(labels, label_lengths):\n    \"\"\"Converts CTC labels from dense to sparse.\n\n    # Arguments\n        labels: dense CTC labels.\n        label_lengths: length of the labels.\n\n    # Returns\n        A sparse tensor representation of the labels.\n    \"\"\"\n    label_shape = tf.shape(labels)\n    num_batches_tns = tf.stack([label_shape[0]])\n    max_num_labels_tns = tf.stack([label_shape[1]])\n\n    def range_less_than(_, current_input):\n        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(\n            max_num_labels_tns, current_input)\n\n    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\n    dense_mask = functional_ops.scan(range_less_than, label_lengths,\n                                     initializer=init, parallel_iterations=1)\n    dense_mask = dense_mask[:, 0, :]\n\n    label_array = tf.reshape(tf.tile(tf.range(label_shape[1]), num_batches_tns),\n                             label_shape)\n    label_ind = tf.boolean_mask(label_array, dense_mask)\n\n    tmp = tf.tile(tf.range(label_shape[0]), max_num_labels_tns)\n    batch_array = tf.transpose(tf.reshape(tmp, reverse(label_shape, 0)))\n    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n\n    indices = concatenate([batch_ind, label_ind], axis=0)\n    indices = tf.transpose(tf.reshape(indices, [2, -1]))\n\n    vals_sparse = tf.gather_nd(labels, indices)\n\n    indices = tf.to_int64(indices)\n    label_shape = tf.to_int64(label_shape)\n    return tf.SparseTensor(indices, vals_sparse, label_shape)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "label_shape",
        "label": "positive",
        "id": "8069bbec-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3397
    },
    {
        "commit_hash": "848c491ed8d109f64124232d3ef2635067f8ac38",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _fit(self, data_d):\n        # TODO: check that data and task definition fit together!\n\n        self.metric_ = data_d.info['metric']\n        self.task_ = data_d.info['task']\n        self.target_num_ = data_d.info['target_num']\n\n        self._set_auto_seed(self._seed)\n\n        # load data\n        self._stopwatch.start_task('LoadData')\n        self._save_ensemble_data(data_d.data['X_train'], data_d.data['Y_train'],\n                                 self._tmp_dir)\n        self._stopwatch.stop_task('LoadData')\n\n        if self._debug_mode:\n            self._print_load_time(self._basename,\n                                  self._time_left_for_this_task,\n                                  self._stopwatch,\n                                  self._info)\n\n        # == Calculate metafeatures\n        ml = self._calculate_metafeatures(\n            data_feat_type=data_d.feat_type,\n            data_info_task=data_d.info['task'],\n            x_train=data_d.data['X_train'],\n            y_train=data_d.data['Y_train'],\n            basename=self._basename,\n            watcher=self._stopwatch,\n            metalearning_cnt=self._initial_configurations_via_metalearning\n        )\n\n        self._stopwatch.start_task('OneHot')\n        data_d.perform1HotEncoding()\n        self._ohe = data_d.encoder_\n        self._stopwatch.stop_task('OneHot')\n\n        # == Pickle the data manager\n        data_manager_path = self._save_data_manager(\n            data_d,\n            self._tmp_dir,\n            self._basename,\n            watcher=self._stopwatch,\n        )\n\n        # = Create a searchspace\n        self._stopwatch.start_task('CreateConfigSpace')\n        configspace_path = os.path.join(self._tmp_dir, 'space.pcs')\n        self.configuration_space = paramsklearn.get_configuration_space(\n            data_d.info)\n\n        self.configuration_space_created_hook()\n\n        sp_string = pcs_parser.write(self.configuration_space)\n        configuration_space_lockfile = configspace_path + '.lock'\n        with lockfile.LockFile(configuration_space_lockfile):\n            if not os.path.exists(configspace_path):\n                with open(configspace_path, 'w') as fh:\n                    fh.write(sp_string)\n                self._debug('Configuration space written to %s' %\n                                  configspace_path)\n            else:\n                self._debug('Configuration space already present at %s' %\n                                  configspace_path)\n        self._stopwatch.stop_task('CreateConfigSpace')\n\n        if ml is None:\n            initial_configurations = []\n        elif data_d.info['task'] in \\\n                [MULTICLASS_CLASSIFICATION, BINARY_CLASSIFICATION]:\n            self._stopwatch.start_task('CalculateMetafeaturesEncoded')\n            ml.calculate_metafeatures_encoded_labels(\n                X_train=data_d.data['X_train'],\n                Y_train=data_d.data['Y_train'],\n                categorical=[False] * data_d.data['X_train'].shape[0],\n                dataset_name=self._basename)\n            self._stopwatch.stop_task('CalculateMetafeaturesEncoded')\n            self._debug(\n                'Calculating Metafeatures (encoded attributes) took %5.2fsec' %\n                self._stopwatch.wall_elapsed('CalculateMetafeaturesEncoded'))\n\n            self._debug(ml._metafeatures_labels.__repr__(verbosity=2))\n            self._debug(\n                ml._metafeatures_encoded_labels.__repr__(verbosity=2))\n\n            self._stopwatch.start_task('InitialConfigurations')\n            try:\n                initial_configurations = ml.create_metalearning_string_for_smac_call(\n                    self.configuration_space, self._basename, self.metric_,\n                    self.task_,\n                    True if data_d.info['is_sparse'] == 1 else False,\n                    self._initial_configurations_via_metalearning,\n                    self._metadata_directory)\n            except Exception as e:\n                import traceback\n\n                self._error(str(e))\n                self._error(traceback.format_exc())\n                initial_configurations = []\n\n            self._stopwatch.stop_task('InitialConfigurations')\n\n            self._debug('Initial Configurations: (%d)' %\n                              len(initial_configurations))\n            for initial_configuration in initial_configurations:\n                self._debug(initial_configuration)\n            self._debug(\n                'Looking for initial configurations took %5.2fsec' %\n                self._stopwatch.wall_elapsed('InitialConfigurations'))\n            self._info(\n                'Time left for %s after finding initial configurations: %5.2fsec'\n                % (self._basename, self._time_left_for_this_task -\n                   self._stopwatch.wall_elapsed(self._basename)))\n        else:\n            initial_configurations = []\n            self._critical('Metafeatures encoded not calculated')\n\n        # == Set up a directory where all the trained models will be pickled to\n        if self._keep_models:\n            self.model_directory_ = os.path.join(self._tmp_dir,\n                                                 'models_%d' % self._seed)\n            os.mkdir(self.model_directory_)\n        self.ensemble_indices_directory_ = os.path.join(\n            self._tmp_dir, 'ensemble_indices_%d' % self._seed)\n        os.mkdir(self.ensemble_indices_directory_)\n\n        # == RUN SMAC\n        self._stopwatch.start_task('runSmac')\n        # = Create an empty instance file\n\n\n        instance_file = os.path.join(self._tmp_dir, 'instances.txt')\n        instance_file_lock = instance_file + '.lock'\n        with lockfile.LockFile(instance_file_lock):\n            if not os.path.exists(instance_file_lock):\n                with open(instance_file, 'w') as fh:\n                    fh.write('holdout')\n                self._debug('Created instance file %s' % instance_file)\n            else:\n                self._debug('Instance file already present at %s' %\n                                  instance_file)\n\n        # = Start SMAC\n        time_left_for_smac = max(\n            0, self._time_left_for_this_task -\n               (self._stopwatch.wall_elapsed(self._basename)))\n        self._debug('Start SMAC with %5.2fsec time left' %\n                          time_left_for_smac)\n        proc_smac, smac_call = \\\n            submit_process.run_smac(dataset_name=self._basename,\n                                    dataset=data_manager_path,\n                                    tmp_dir=self._tmp_dir,\n                                    searchspace=configspace_path,\n                                    instance_file=instance_file,\n                                    limit=time_left_for_smac,\n                                    cutoff_time=self._per_run_time_limit,\n                                    initial_challengers=initial_configurations,\n                                    memory_limit=self._ml_memory_limit,\n                                    seed=self._seed)\n        self._debug(smac_call)\n        self._stopwatch.stop_task('runSmac')\n\n        # == RUN ensemble builder\n        self._stopwatch.start_task('runEnsemble')\n        time_left_for_ensembles = max(\n            0, self._time_left_for_this_task -\n               (self._stopwatch.wall_elapsed(self._basename)))\n        self._debug('Start Ensemble with %5.2fsec time left' %\n                          time_left_for_ensembles)\n        proc_ensembles = \\\n            submit_process.run_ensemble_builder(tmp_dir=self._tmp_dir,\n                                                dataset_name=self._basename,\n                                                task_type=self.task_,\n                                                metric=self.metric_,\n                                                limit=time_left_for_ensembles,\n                                                output_dir=self._output_dir,\n                                                ensemble_size=self._ensemble_size,\n                                                ensemble_nbest=self._ensemble_nbest,\n                                                seed=self._seed,\n                                                ensemble_indices_output_dir=self.ensemble_indices_directory_)\n        self._stopwatch.stop_task('runEnsemble')\n\n        del data_d\n\n        if self._queue is not None:\n            self._queue.put([time_for_load_data, data_manager_path,\n                            proc_smac, proc_ensembles])\n        else:\n            proc_smac.wait()\n            proc_ensembles.wait()\n\n        # Delete AutoSklearn environment variable\n        self._del_auto_seed()\n        return self",
            "file_path": "commits/848c491ed8d109f64124232d3ef2635067f8ac38/Before/autosklearn#automl.py"
        },
        "refactored_code": {
            "source_code": "def _fit(self, data_d):\n\n        # TODO: check that data and task definition fit together!\n\n        self.metric_ = data_d.info['metric']\n        self.task_ = data_d.info['task']\n        self.target_num_ = data_d.info['target_num']\n\n        _set_auto_seed(self._seed)\n\n        # load data\n        self._save_ensemble_data(data_d.data['X_train'],\n                                 data_d.data['Y_train'],\n                                 self._tmp_dir,\n                                 self._stopwatch)\n\n        time_for_load_data = self._stopwatch.wall_elapsed(self._basename)\n\n        if self._debug_mode:\n            self._print_load_time(self._basename,\n                                  self._time_for_task,\n                                  time_for_load_data,\n                                  self._info)\n\n        # == Calculate metafeatures\n        ml = self._calculate_metafeatures(\n            data_feat_type=data_d.feat_type,\n            data_info_task=data_d.info['task'],\n            x_train=data_d.data['X_train'],\n            y_train=data_d.data['Y_train'],\n            basename=self._basename,\n            watcher=self._stopwatch,\n            metalearning_cnt=self._initial_configurations_via_metalearning\n        )\n\n        self._stopwatch.start_task('OneHot')\n        data_d.perform1HotEncoding()\n        self._ohe = data_d.encoder_\n        self._stopwatch.stop_task('OneHot')\n\n        # == Pickle the data manager\n        data_manager_path = self._save_data_manager(\n            data_d,\n            self._tmp_dir,\n            self._basename,\n            watcher=self._stopwatch,\n        )\n\n        # = Create a searchspace\n        self._stopwatch.start_task('CreateConfigSpace')\n        configspace_path = os.path.join(self._tmp_dir, 'space.pcs')\n        self.configuration_space = paramsklearn.get_configuration_space(\n            data_d.info)\n        self.configuration_space_created_hook()\n        sp_string = pcs_parser.write(self.configuration_space)\n        _write_file_with_data(configspace_path, sp_string,\n                              \"Configuration space\", self._debug)\n        self._stopwatch.stop_task('CreateConfigSpace')\n\n        if ml is None:\n            initial_configurations = []\n        elif data_d.info['task'] in \\\n                [MULTICLASS_CLASSIFICATION, BINARY_CLASSIFICATION]:\n            self._stopwatch.start_task('CalculateMetafeaturesEncoded')\n            ml.calculate_metafeatures_encoded_labels(\n                X_train=data_d.data['X_train'],\n                Y_train=data_d.data['Y_train'],\n                categorical=[False] * data_d.data['X_train'].shape[0],\n                dataset_name=self._basename)\n            self._stopwatch.stop_task('CalculateMetafeaturesEncoded')\n            self._debug(\n                'Calculating Metafeatures (encoded attributes) took %5.2fsec' %\n                self._stopwatch.wall_elapsed('CalculateMetafeaturesEncoded'))\n\n            self._debug(ml._metafeatures_labels.__repr__(verbosity=2))\n            self._debug(\n                ml._metafeatures_encoded_labels.__repr__(verbosity=2))\n\n            self._stopwatch.start_task('InitialConfigurations')\n            try:\n                initial_configurations = ml.create_metalearning_string_for_smac_call(\n                    self.configuration_space, self._basename, self.metric_,\n                    self.task_,\n                    True if data_d.info['is_sparse'] == 1 else False,\n                    self._initial_configurations_via_metalearning,\n                    self._metadata_directory)\n            except Exception as e:\n                import traceback\n\n                self._error(str(e))\n                self._error(traceback.format_exc())\n                initial_configurations = []\n\n            self._stopwatch.stop_task('InitialConfigurations')\n\n            self._debug('Initial Configurations: (%d)' %\n                              len(initial_configurations))\n            for initial_configuration in initial_configurations:\n                self._debug(initial_configuration)\n            self._debug(\n                'Looking for initial configurations took %5.2fsec' %\n                self._stopwatch.wall_elapsed('InitialConfigurations'))\n            self._info(\n                'Time left for %s after finding initial configurations: %5.2fsec'\n                % (self._basename, self._time_for_task -\n                   self._stopwatch.wall_elapsed(self._basename)))\n        else:\n            initial_configurations = []\n            self._critical('Metafeatures encoded not calculated')\n\n        # == RUN SMAC\n        proc_smac = _run_smac(self._tmp_dir, self._basename,\n                              self._time_for_task,\n                              self._ml_memory_limit,\n                              data_manager_path,\n                              configspace_path,\n                              initial_configurations,\n                              self._per_run_time_limit,\n                              self._stopwatch,\n                              self._debug)\n\n        # == RUN ensemble builder\n        self._stopwatch.start_task('runEnsemble')\n        time_left_for_ensembles = max(\n            0, self._time_for_task -\n               (self._stopwatch.wall_elapsed(self._basename)))\n        self._debug('Start Ensemble with %5.2fsec time left' %\n                          time_left_for_ensembles)\n        proc_ensembles = \\\n            submit_process.run_ensemble_builder(tmp_dir=self._tmp_dir,\n                                                dataset_name=self._basename,\n                                                task_type=self.task_,\n                                                metric=self.metric_,\n                                                limit=time_left_for_ensembles,\n                                                output_dir=self._output_dir,\n                                                ensemble_size=self._ensemble_size,\n                                                ensemble_nbest=self._ensemble_nbest,\n                                                seed=self._seed,\n                                                ensemble_indices_output_dir=self._ensemble_indices_dir)\n        self._stopwatch.stop_task('runEnsemble')\n\n        del data_d\n\n        if self._queue is not None:\n            self._queue.put([time_for_load_data, data_manager_path,\n                            proc_smac, proc_ensembles])\n        else:\n            proc_smac.wait()\n            proc_ensembles.wait()\n\n        # Delete AutoSklearn environment variable\n        _del_auto_seed()\n        return self",
            "file_path": "commits/848c491ed8d109f64124232d3ef2635067f8ac38/After/autosklearn#automl.py"
        },
        "original_variable_name": "time_left_for_smac",
        "new_variable_name": "time_left_for_ensembles",
        "label": "negative",
        "id": "80679024-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 16003
    },
    {
        "commit_hash": "be65ce986a45bf2f35b5494db3fa6e993b905aeb",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def DIEN(feature_dim_dict, seq_feature_list, embedding_size=8, hist_len_max=16,\n         gru_type=\"GRU\", use_negsampling=False, alpha=1.0, use_bn=False, dnn_hidden_units=(200, 80),\n         dnn_activation='relu',\n         att_hidden_units=(64, 16), att_activation=\"dice\", att_weight_normalization=True,\n         l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, init_std=0.0001, seed=1024, task='binary'):\n    \"\"\"Instantiates the Deep Interest Evolution Network architecture.\n\n    :param feature_dim_dict: dict,to indicate sparse field (**now only support sparse feature**)like {'sparse':{'field_1':4,'field_2':3,'field_3':2},'dense':[]}\n    :param seq_feature_list: list,to indicate  sequence sparse field (**now only support sparse feature**),must be a subset of ``feature_dim_dict[\"sparse\"]``\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param hist_len_max: positive int, to indicate the max length of seq input\n    :param gru_type: str,can be GRU AIGRU AUGRU AGRU\n    :param use_negsampling: bool, whether or not use negtive sampling\n    :param alpha: float ,weight of auxiliary_loss\n    :param use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n    :param dnn_activation: Activation function to use in DNN\n    :param att_hidden_units: list,list of positive integer , the layer number and units in each layer of attention net\n    :param att_activation: Activation function to use in attention net\n    :param att_weight_normalization: bool.Whether normalize the attention score of local activation unit.\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n    check_feature_config_dict(feature_dim_dict)\n\n    sparse_input, dense_input, user_behavior_input, user_behavior_length = get_input(\n        feature_dim_dict, seq_feature_list, hist_len_max)\n    sparse_embedding_dict = {feat.name: Embedding(feat.dimension, embedding_size,\n                                                  embeddings_initializer=RandomNormal(\n                                                      mean=0.0, stddev=init_std, seed=seed),\n                                                  embeddings_regularizer=l2(\n                                                      l2_reg_embedding),\n                                                  name='sparse_emb_' + str(i) + '-' + feat.name) for i, feat in\n                             enumerate(feature_dim_dict[\"sparse\"])}\n\n    query_emb_list = get_embedding_vec_list(sparse_embedding_dict,sparse_input,feature_dim_dict[\"sparse\"],return_feat_list=seq_feature_list)\n    keys_emb_list = get_embedding_vec_list(sparse_embedding_dict,user_behavior_input,feature_dim_dict['sparse'],return_feat_list=seq_feature_list)\n    deep_input_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_dim_dict['sparse'])\n\n    query_emb = concat_fun(query_emb_list)\n    keys_emb = concat_fun(keys_emb_list)\n    deep_input_emb = concat_fun(deep_input_emb_list)\n\n\n    if use_negsampling:\n        neg_user_behavior_input = OrderedDict()\n        for i, feat in enumerate(seq_feature_list):\n            neg_user_behavior_input[feat] = Input(shape=(hist_len_max,), name='neg_seq_' + str(i) + '-' + feat)\n\n        neg_uiseq_embed_list = get_embedding_vec_list(sparse_embedding_dict,neg_user_behavior_input,feature_dim_dict[\"sparse\"],seq_feature_list,)\n           # [sparse_embedding_dict[feat](\n           # neg_user_behavior_input[feat]) for feat in seq_feature_list]\n        neg_concat_behavior = concat_fun(neg_uiseq_embed_list)\n\n    else:\n        neg_concat_behavior = None\n\n    hist, aux_loss_1 = interest_evolution(keys_emb, query_emb, user_behavior_length, gru_type=gru_type,\n                                          use_neg=use_negsampling, neg_concat_behavior=neg_concat_behavior,\n                                          embedding_size=embedding_size, att_hidden_size=att_hidden_units,\n                                          att_activation=att_activation,\n                                          att_weight_normalization=att_weight_normalization, )\n\n    deep_input_emb = Concatenate()([deep_input_emb, hist])\n\n    deep_input_emb = tf.keras.layers.Flatten()(deep_input_emb)\n    if len(dense_input) > 0:\n        deep_input_emb = Concatenate()(\n            [deep_input_emb] + list(dense_input.values()))\n\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, use_bn, seed)(deep_input_emb)\n    final_logit = Dense(1, use_bias=False)(output)\n    output = PredictionLayer(task)(final_logit)\n\n    model_input_list = get_inputs_list(\n        [sparse_input, dense_input, user_behavior_input])\n\n    if use_negsampling:\n        model_input_list += list(neg_user_behavior_input.values())\n\n    model_input_list += [user_behavior_length]\n\n    model = tf.keras.models.Model(inputs=model_input_list, outputs=output)\n\n    if use_negsampling:\n        model.add_loss(alpha * aux_loss_1)\n    tf.keras.backend.get_session().run(tf.global_variables_initializer())\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/Before/deepctr#models#dien.py"
        },
        "refactored_code": {
            "source_code": "def DIEN(dnn_feature_columns, history_feature_list, embedding_size=8, hist_len_max=16,\n         gru_type=\"GRU\", use_negsampling=False, alpha=1.0, use_bn=False, dnn_hidden_units=(200, 80),\n         dnn_activation='relu',\n         att_hidden_units=(64, 16), att_activation=\"dice\", att_weight_normalization=True,\n         l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, init_std=0.0001, seed=1024, task='binary'):\n    \"\"\"Instantiates the Deep Interest Evolution Network architecture.\n\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param history_feature_list: list,to indicate  sequence sparse field\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param hist_len_max: positive int, to indicate the max length of seq input\n    :param gru_type: str,can be GRU AIGRU AUGRU AGRU\n    :param use_negsampling: bool, whether or not use negtive sampling\n    :param alpha: float ,weight of auxiliary_loss\n    :param use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n    :param dnn_activation: Activation function to use in DNN\n    :param att_hidden_units: list,list of positive integer , the layer number and units in each layer of attention net\n    :param att_activation: Activation function to use in attention net\n    :param att_weight_normalization: bool.Whether normalize the attention score of local activation unit.\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n    # check_feature_config_dict(feature_columns)\n    #\n    # sparse_input, dense_input, user_behavior_input, user_behavior_length = get_input(\n    #     feature_columns, seq_feature_list, hist_len_max)\n    # sparse_embedding_dict = {feat.name: Embedding(feat.dimension, embedding_size,\n    #                                               embeddings_initializer=RandomNormal(\n    #                                                   mean=0.0, stddev=init_std, seed=seed),\n    #                                               embeddings_regularizer=l2(\n    #                                                   l2_reg_embedding),\n    #                                               name='sparse_emb_' + str(i) + '-' + feat.name) for i, feat in\n    #                          enumerate(feature_columns[\"sparse\"])}\n    #\n    # query_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_columns[\"sparse\"], return_feat_list=seq_feature_list)\n    # keys_emb_list = get_embedding_vec_list(sparse_embedding_dict, user_behavior_input, feature_columns['sparse'], return_feat_list=seq_feature_list)\n    # deep_input_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_columns['sparse'])\n    #\n    # query_emb = concat_fun(query_emb_list)\n    # keys_emb = concat_fun(keys_emb_list)\n    # deep_input_emb = concat_fun(deep_input_emb_list)\n\n    features = build_input_features(dnn_feature_columns)\n\n    user_behavior_length = Input(shape=(1,), name='seq_length')\n\n    sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, SparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n    dense_feature_columns = list(\n        filter(lambda x: isinstance(x, DenseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n    varlen_sparse_feature_columns = list(\n        filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n\n    history_feature_columns = []\n    neg_history_feature_columns = []\n    sparse_varlen_feature_columns = []\n    history_fc_names = list(map(lambda x: \"hist_\" + x, history_feature_list))\n    neg_history_fc_names = list(map(lambda x: \"neg_\" + x, history_fc_names))\n    for fc in varlen_sparse_feature_columns:\n        feature_name = fc.name\n        if feature_name in history_fc_names:\n            history_feature_columns.append(fc)\n        elif feature_name in neg_history_fc_names:\n            neg_history_feature_columns.append(fc)\n        else:\n            sparse_varlen_feature_columns.append(fc)\n\n    inputs_list = list(features.values())\n\n    embedding_dict = create_embedding_matrix(dnn_feature_columns, l2_reg_embedding, init_std, seed, embedding_size,\n                                             prefix=\"\",seq_mask_zero=False)\n\n    query_emb_list = embedding_lookup(embedding_dict, features, sparse_feature_columns, return_feat_list=history_feature_list,\n                                      )  # query\u662f\u5355\u72ec\u7684\n\n    keys_emb_list = embedding_lookup(embedding_dict, features, history_feature_columns,return_feat_list=history_fc_names)\n    dnn_input_emb_list = embedding_lookup(embedding_dict, features, sparse_feature_columns,\n                                          mask_feat_list=history_feature_list)\n    dense_value_list = get_dense_input(features, dense_feature_columns)\n\n    sequence_embed_dict = varlen_embedding_lookup(embedding_dict, features, sparse_varlen_feature_columns)\n    sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, features, sparse_varlen_feature_columns)\n    dnn_input_emb_list += sequence_embed_list\n\n\n    keys_emb = concat_fun(keys_emb_list)\n    deep_input_emb = concat_fun(dnn_input_emb_list)\n    query_emb = concat_fun(query_emb_list)\n\n\n\n    if use_negsampling:\n        #neg_user_behavior_input = OrderedDict()\n        #for i, feat in enumerate(history_feature_list):\n        #    neg_user_behavior_input[feat] = Input(shape=(hist_len_max,), name='neg_seq_' + str(i) + '-' + feat)\n\n        neg_uiseq_embed_list = embedding_lookup(embedding_dict, features, neg_history_feature_columns, neg_history_fc_names,)\n            #get_embedding_vec_list(sparse_embedding_dict, neg_user_behavior_input, feature_columns[\"sparse\"], history_feature_list, )\n           # [sparse_embedding_dict[feat](\n           # neg_user_behavior_input[feat]) for feat in seq_feature_list]\n        neg_concat_behavior = concat_fun(neg_uiseq_embed_list)\n\n    else:\n        neg_concat_behavior = None\n    hist, aux_loss_1 = interest_evolution(keys_emb, query_emb, user_behavior_length, gru_type=gru_type,\n                                          use_neg=use_negsampling, neg_concat_behavior=neg_concat_behavior,\n                                          embedding_size=embedding_size, att_hidden_size=att_hidden_units,\n                                          att_activation=att_activation,\n                                          att_weight_normalization=att_weight_normalization, )\n\n    deep_input_emb = Concatenate()([deep_input_emb, hist])\n\n    deep_input_emb = tf.keras.layers.Flatten()(deep_input_emb)\n\n    dnn_input = combined_dnn_input([deep_input_emb], dense_value_list)\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, use_bn, seed)(dnn_input)\n    final_logit = Dense(1, use_bias=False)(output)\n    output = PredictionLayer(task)(final_logit)\n\n    #model_input_list = get_inputs_list(\n    #    [sparse_input, dense_input, user_behavior_input])\n    model_input_list = inputs_list\n\n    #if use_negsampling:\n    #    model_input_list += list(neg_user_behavior_input.values())\n\n    model_input_list += [user_behavior_length]\n\n    model = tf.keras.models.Model(inputs=model_input_list, outputs=output)\n\n    if use_negsampling:\n        model.add_loss(alpha * aux_loss_1)\n    tf.keras.backend.get_session().run(tf.global_variables_initializer())\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/After/deepctr#models#dien.py"
        },
        "variable_name": "feature_name",
        "label": "negative",
        "id": "8069bdf4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 14155
    },
    {
        "commit_hash": "e723b99888008b7b28a1e5fb50c331b1e314a273",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def save_model(model, optimizer, current_step, epoch, r, output_path, amp_state_dict=None, **kwargs):\n    new_state_dict = model.state_dict()\n    state = {\n        'model': new_state_dict,\n        'optimizer': optimizer.state_dict() if optimizer is not None else None,\n        'step': current_step,\n        'epoch': epoch,\n        'date': datetime.date.today().strftime(\"%B %d, %Y\"),\n        'r': r\n    }\n    if amp_state_dict:\n        state['amp'] = amp_state_dict\n    state.update(kwargs)\n    torch.save(state, output_path)",
            "file_path": "commits/e723b99888008b7b28a1e5fb50c331b1e314a273/Before/TTS#tts#utils#io.py"
        },
        "refactored_code": {
            "source_code": "def save_model(model, optimizer, current_step, epoch, r, output_path, amp_state_dict=None, **kwargs):\n    if hasattr(model, 'module'):\n        model_state = model.module.state_dict()\n    else:\n        model_state = model.state_dict()\n    state = {\n        'model': model_state,\n        'optimizer': optimizer.state_dict() if optimizer is not None else None,\n        'step': current_step,\n        'epoch': epoch,\n        'date': datetime.date.today().strftime(\"%B %d, %Y\"),\n        'r': r\n    }\n    if amp_state_dict:\n        state['amp'] = amp_state_dict\n    state.update(kwargs)\n    torch.save(state, output_path)",
            "file_path": "commits/e723b99888008b7b28a1e5fb50c331b1e314a273/After/TTS#tts#utils#io.py"
        },
        "original_variable_name": "new_state_dict",
        "new_variable_name": "model_state",
        "label": "positive",
        "id": "8067a55a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1543
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            tile_shape = tf.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def switch(condition, then_expression, else_expression):\n    \"\"\"Switches between two operations depending on a scalar value.\n\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: tensor (`int` or `bool`).\n        then_expression: either a tensor, or a callable that returns a tensor.\n        else_expression: either a tensor, or a callable that returns a tensor.\n\n    # Returns\n        The selected tensor.\n\n    # Raises\n        ValueError: If rank of `condition` is greater than rank of expressions.\n    \"\"\"\n    if condition.dtype != tf.bool:\n        condition = tf.cast(condition, 'bool')\n    cond_ndim = ndim(condition)\n    if not cond_ndim:\n        if not callable(then_expression):\n            def then_expression_fn():\n                return then_expression\n        else:\n            then_expression_fn = then_expression\n        if not callable(else_expression):\n            def else_expression_fn():\n                return else_expression\n        else:\n            else_expression_fn = else_expression\n        x = tf.cond(condition,\n                    then_expression_fn,\n                    else_expression_fn)\n    else:\n        # tf.where needs its condition tensor\n        # to be the same shape as its two\n        # result tensors\n        if callable(then_expression):\n            then_expression = then_expression()\n        if callable(else_expression):\n            else_expression = else_expression()\n        expr_ndim = ndim(then_expression)\n        if cond_ndim > expr_ndim:\n            raise ValueError('Rank of `condition` should be less than or'\n                             ' equal to rank of `then_expression` and '\n                             '`else_expression`. ndim(condition)=' +\n                             str(cond_ndim) + ', ndim(then_expression)'\n                             '=' + str(expr_ndim))\n        if cond_ndim > 1:\n            ndim_diff = expr_ndim - cond_ndim\n            cond_shape = tf.concat([tf.shape(condition), [1] * ndim_diff], axis=0)\n            condition = tf.reshape(condition, cond_shape)\n            expr_shape = tf.shape(then_expression)\n            shape_diff = expr_shape - cond_shape\n            zero_expr_shape = tf.ones_like(expr_shape)\n            tile_shape = tf.where(shape_diff > 0, expr_shape, zero_expr_shape)\n            condition = tf.tile(condition, tile_shape)\n        x = tf.where(condition, then_expression, else_expression)\n    return x",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "zero_expr_shape",
        "label": "positive",
        "id": "8069bc14-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5469
    },
    {
        "commit_hash": "660d61aeebb0a28e89b2e485a61f8949407e2e88",
        "refactoring_type": "Rename Method",
        "original_method": {
            "name": "maximum_path",
            "container_name": "__init__",
            "source_code": "def maximum_path(value, mask):\n    \"\"\" Cython optimised version.\n    value: [b, t_x, t_y]\n    mask: [b, t_x, t_y]\n    \"\"\"\n    value = value * mask\n    device = value.device\n    dtype = value.dtype\n    value = value.data.cpu().numpy().astype(np.float32)\n    path = np.zeros_like(value).astype(np.int32)\n    mask = mask.data.cpu().numpy()\n\n    t_x_max = mask.sum(1)[:, 0].astype(np.int32)\n    t_y_max = mask.sum(2)[:, 0].astype(np.int32)\n    maximum_path_c(path, value, t_x_max, t_y_max)\n    return torch.from_numpy(path).to(device=device, dtype=dtype)",
            "file_path": "commits/660d61aeebb0a28e89b2e485a61f8949407e2e88/Before/TTS#tts#layers#glow_tts#monotonic_align#__init__.py"
        },
        "renamed_method": {
            "name": "maximum_path_cython",
            "container_name": "__init__",
            "source_code": "def maximum_path_cython(value, mask):\n    \"\"\" Cython optimised version.\n    value: [b, t_x, t_y]\n    mask: [b, t_x, t_y]\n    \"\"\"\n    value = value * mask\n    device = value.device\n    dtype = value.dtype\n    value = value.data.cpu().numpy().astype(np.float32)\n    path = np.zeros_like(value).astype(np.int32)\n    mask = mask.data.cpu().numpy()\n\n    t_x_max = mask.sum(1)[:, 0].astype(np.int32)\n    t_y_max = mask.sum(2)[:, 0].astype(np.int32)\n    maximum_path_c(path, value, t_x_max, t_y_max)\n    return torch.from_numpy(path).to(device=device, dtype=dtype)",
            "file_path": "commits/660d61aeebb0a28e89b2e485a61f8949407e2e88/After/TTS#tts#layers#glow_tts#monotonic_align#__init__.py"
        },
        "label": "negative",
        "id": "8063dfb0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1634
    },
    {
        "commit_hash": "a0464dc48757ffc3cd3e28f4c3aa547ccc138034",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_checkpoint_distribution_strategy(self, golden, strategy_fn):\n    strategy = strategy_fn()\n    with strategy.scope():\n      module = golden.create_module()\n      variables = golden.create_all_variables(module)\n\n    def forward():\n      per_replica = strategy.experimental_run_v2(lambda: golden.forward(module))\n      return tf.stack(strategy.unwrap(per_replica), axis=0)\n\n    # Assign sequential values to the weights and compute a forward pass.\n    for index, variable in enumerate(variables):\n      variable.assign(goldens.range_like(variable, start=index))\n    before_save_ys = forward()\n\n    # Create a checkpoint and save the weights.\n    checkpoint = TestCheckpoint(module=module)\n    checkpoint.save()\n\n    # Assign ones into the weights and do another forward pass. The result\n    # should be different.\n    for variable in variables:\n      variable.assign(tf.ones_like(variable))\n\n    if golden.deterministic:\n      y = forward()\n      self.assertNotAllClose(y, before_save_ys)\n\n    # Restore from the checkpoint and assert the module is in the same state.\n    checkpoint.restore_latest()\n\n    for index, variable in enumerate(variables):\n      # Parameters should be restored to their previous values.\n      self.assertAllEqual(variable.read_value(),\n                          goldens.range_like(variable, start=index))\n\n    if golden.deterministic:\n      self.assertAllEqual(forward(), before_save_ys)",
            "file_path": "commits/a0464dc48757ffc3cd3e28f4c3aa547ccc138034/Before/sonnet#golden_checkpoints#goldens_test.py"
        },
        "refactored_code": {
            "source_code": "def assertCheckpointDistributionStrategy(self, golden, strategy,\n                                           use_function=True):\n    with strategy.scope():\n      module = golden.create_module()\n      variables = golden.create_all_variables(module)\n\n    def forward():\n      per_replica = strategy.experimental_run_v2(lambda: golden.forward(module))\n      return tf.stack(strategy.unwrap(per_replica), axis=0)\n\n    if use_function:\n      forward = tf.function(forward)\n      if self.primary_device == \"TPU\":\n        # TODO(b/132329316) Remove when `xla.compile` allows tf.device(TPU).\n        forward = with_soft_placement(forward)\n\n    # Assign sequential values to the weights and compute a forward pass.\n    for index, variable in enumerate(variables):\n      variable.assign(goldens.range_like(variable, start=index))\n    before_save_ys = forward()\n\n    # Create a checkpoint and save the weights.\n    checkpoint = TestCheckpoint(module=module)\n    checkpoint.save()\n\n    # Assign different values into the weights and do another forward pass. The\n    # result should be different.\n    for variable in variables:\n      variable.assign(-tf.ones_like(variable))\n\n    if golden.deterministic:\n      y = forward()\n      self.assertNotAllClose(y, before_save_ys)\n\n    # Restore from the checkpoint and assert the module is in the same state.\n    status = checkpoint.restore_latest()\n    status.assert_consumed()\n\n    for index, variable in enumerate(variables):\n      # Parameters should be restored to their previous values.\n      self.assertAllEqual(variable.read_value(),\n                          goldens.range_like(variable, start=index))\n\n    if golden.deterministic:\n      self.assertAllEqual(forward(), before_save_ys)",
            "file_path": "commits/a0464dc48757ffc3cd3e28f4c3aa547ccc138034/After/sonnet#golden_checkpoints#goldens_test.py"
        },
        "variable_name": "status",
        "label": "positive",
        "id": "8069b9b2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3594
    },
    {
        "commit_hash": "f1afb5df71893ff2770c7cc7ca83d2ac68f977d7",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_positive_wavefunction_psi():\n    nn_state = PositiveWaveFunction(10, gpu=False)\n\n    vis_state = torch.ones(10).to(dtype=torch.double)\n    actual_psi = nn_state.psi(vis_state)[1].to(vis_state)\n    expected_psi = torch.zeros(1).to(vis_state)\n\n    msg = \"PositiveWaveFunction is giving a non-zero imaginary part!\"\n    assert torch.equal(actual_psi, expected_psi), msg",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/Before/tests#test_models_misc.py"
        },
        "refactored_code": {
            "source_code": "def test_positive_wavefunction_psi():\n    nn_state = PositiveWaveFunction(10, gpu=False)\n\n    vis_state = torch.ones(10).to(dtype=torch.double)\n    actual_psi_im = cplx.imag(nn_state.psi(vis_state)).to(vis_state)\n    expected_psi_im = torch.zeros(1).squeeze().to(vis_state)\n\n    msg = \"PositiveWaveFunction is giving a non-zero imaginary part!\"\n    assert torch.equal(actual_psi_im, expected_psi_im), msg",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/After/tests#test_models_misc.py"
        },
        "original_variable_name": "actual_psi",
        "new_variable_name": "actual_psi_im",
        "label": "positive",
        "id": "80679600-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1149
    },
    {
        "commit_hash": "9f352f5072543a5a47b78943bf9a729eb18502c6",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def backward_EG(self):\n    # content Ladv for generator\n    loss_G_GAN_Acontent = self.backward_G_GAN_content(self.z_content_a)\n    loss_G_GAN_Bcontent = self.backward_G_GAN_content(self.z_content_b)\n\n    # Ladv for generator\n    loss_G_GAN_A = self.backward_G_GAN(self.fake_A_encoded, self.disA)\n    loss_G_GAN_B = self.backward_G_GAN(self.fake_B_encoded, self.disB)\n\n    # KL loss - z_a\n    kl_element_a = self.mu_a.pow(2).add_(self.logvar_a.exp()).mul_(-1).add_(1).add_(self.logvar_a)\n    loss_kl_za = torch.sum(kl_element_a).mul_(-0.5) * 0.01\n    kl_element_b = self.mu_b.pow(2).add_(self.logvar_b.exp()).mul_(-1).add_(1).add_(self.logvar_b)\n    loss_kl_zb = torch.sum(kl_element_b).mul_(-0.5) * 0.01\n    kl_element_recon_a = self.mu_recon_a.pow(2).add_(self.logvar_recon_a.exp()).mul_(-1).add_(1).add_(self.logvar_recon_a)\n    loss_kl_recon_za = torch.sum(kl_element_recon_a).mul_(-0.5) * 0.01\n    kl_element_recon_b = self.mu_recon_b.pow(2).add_(self.logvar_recon_b.exp()).mul_(-1).add_(1).add_(self.logvar_recon_b)\n    loss_kl_recon_zb = torch.sum(kl_element_recon_b).mul_(-0.5) * 0.01\n\n    # KL loss - z_c\n    loss_kl_zs_a = self._compute_kl(self.z_content_a) * 0.01\n    loss_kl_zs_b = self._compute_kl(self.z_content_b) * 0.01\n    loss_kl_zs_recon_a = self._compute_kl(self.z_content_recon_a) * 0.01\n    loss_kl_zs_recon_b = self._compute_kl(self.z_content_recon_b) * 0.01\n\n    # cross cycle consistency loss\n    loss_G_L1_A = self.criterionL1(self.fake_A_recon, self.real_A_encoded) * 10\n    loss_G_L1_B = self.criterionL1(self.fake_B_recon, self.real_B_encoded) * 10\n    loss_G_L1_AA = self.criterionL1(self.fake_AA_encoded, self.real_A_encoded) * 10\n    loss_G_L1_BB = self.criterionL1(self.fake_BB_encoded, self.real_B_encoded) * 10\n\n    loss_G = loss_G_GAN_A + loss_G_GAN_B + \\\n             loss_G_GAN_Acontent + loss_G_GAN_Bcontent + \\\n             loss_kl_za + loss_kl_zb + loss_kl_recon_za + loss_kl_recon_zb + \\\n             loss_kl_zs_a + loss_kl_zs_b + loss_kl_zs_recon_a + loss_kl_zs_recon_b + \\\n             loss_G_L1_AA + loss_G_L1_BB +\\\n             loss_G_L1_A + loss_G_L1_B\n\n    loss_G.backward(retain_graph=True)\n\n    self.gan_loss_a = loss_G_GAN_A.data.cpu().numpy()[0]\n    self.gan_loss_b = loss_G_GAN_B.data.cpu().numpy()[0]\n    self.gan_loss_acontent = loss_G_GAN_Acontent.data.cpu().numpy()[0]\n    self.gan_loss_bcontent = loss_G_GAN_Bcontent.data.cpu().numpy()[0]\n    self.kl_za_loss = loss_kl_za.data.cpu().numpy()[0]\n    self.kl_zb_loss = loss_kl_zb.data.cpu().numpy()[0]\n    self.kl_zs_a_loss = loss_kl_zs_a.data.cpu().numpy()[0]\n    self.kl_zs_b_loss = loss_kl_zs_b.data.cpu().numpy()[0]\n    self.l1_recon_A_loss = loss_G_L1_A.data.cpu().numpy()[0]\n    self.l1_recon_B_loss = loss_G_L1_B.data.cpu().numpy()[0]\n    self.l1_recon_AA_loss = loss_G_L1_AA.data.cpu().numpy()[0]\n    self.l1_recon_BB_loss = loss_G_L1_BB.data.cpu().numpy()[0]\n    self.G_loss = loss_G.data.cpu().numpy()[0]",
            "file_path": "commits/9f352f5072543a5a47b78943bf9a729eb18502c6/Before/src#model.py"
        },
        "refactored_code": {
            "source_code": "def backward_EG(self):\n    # content Ladv for generator\n    loss_G_GAN_Acontent = self.backward_G_GAN_content(self.z_content_a)\n    loss_G_GAN_Bcontent = self.backward_G_GAN_content(self.z_content_b)\n\n    # Ladv for generator\n    loss_G_GAN_A = self.backward_G_GAN(self.fake_A_encoded, self.disA)\n    loss_G_GAN_B = self.backward_G_GAN(self.fake_B_encoded, self.disB)\n\n    # KL loss - z_a\n    kl_element_a = self.mu_a.pow(2).add_(self.logvar_a.exp()).mul_(-1).add_(1).add_(self.logvar_a)\n    loss_kl_za_a = torch.sum(kl_element_a).mul_(-0.5) * 0.01\n    kl_element_b = self.mu_b.pow(2).add_(self.logvar_b.exp()).mul_(-1).add_(1).add_(self.logvar_b)\n    loss_kl_za_b = torch.sum(kl_element_b).mul_(-0.5) * 0.01\n\n    # KL loss - z_c\n    loss_kl_zc_a = self._compute_kl(self.z_content_a) * 0.01\n    loss_kl_zc_b = self._compute_kl(self.z_content_b) * 0.01\n\n    # cross cycle consistency loss\n    loss_G_L1_A = self.criterionL1(self.fake_A_recon, self.real_A_encoded) * 10\n    loss_G_L1_B = self.criterionL1(self.fake_B_recon, self.real_B_encoded) * 10\n    loss_G_L1_AA = self.criterionL1(self.fake_AA_encoded, self.real_A_encoded) * 10\n    loss_G_L1_BB = self.criterionL1(self.fake_BB_encoded, self.real_B_encoded) * 10\n\n    loss_G = loss_G_GAN_A + loss_G_GAN_B + \\\n             loss_G_GAN_Acontent + loss_G_GAN_Bcontent + \\\n             loss_G_L1_AA + loss_G_L1_BB + \\\n             loss_G_L1_A + loss_G_L1_B + \\\n             loss_kl_zc_a + loss_kl_zc_b + \\\n             loss_kl_za_a + loss_kl_za_b\n\n    loss_G.backward(retain_graph=True)\n\n    self.gan_loss_a = loss_G_GAN_A.data.cpu().numpy()\n    self.gan_loss_b = loss_G_GAN_B.data.cpu().numpy()\n    self.gan_loss_acontent = loss_G_GAN_Acontent.data.cpu().numpy()\n    self.gan_loss_bcontent = loss_G_GAN_Bcontent.data.cpu().numpy()\n    self.kl_loss_za_a = loss_kl_za_a.data.cpu().numpy()\n    self.kl_loss_za_b = loss_kl_za_b.data.cpu().numpy()\n    self.kl_loss_zc_a = loss_kl_zc_a.data.cpu().numpy()\n    self.kl_loss_zc_b = loss_kl_zc_b.data.cpu().numpy()\n    self.l1_recon_A_loss = loss_G_L1_A.data.cpu().numpy()\n    self.l1_recon_B_loss = loss_G_L1_B.data.cpu().numpy()\n    self.l1_recon_AA_loss = loss_G_L1_AA.data.cpu().numpy()\n    self.l1_recon_BB_loss = loss_G_L1_BB.data.cpu().numpy()\n    self.G_loss = loss_G.data.cpu().numpy()",
            "file_path": "commits/9f352f5072543a5a47b78943bf9a729eb18502c6/After/src#model.py"
        },
        "original_variable_name": "loss_kl_zb",
        "new_variable_name": "loss_kl_za_b",
        "label": "positive",
        "id": "8067a488-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5638
    },
    {
        "commit_hash": "f1afb5df71893ff2770c7cc7ca83d2ac68f977d7",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def psi(self, v):\n        # vector/tensor of shape (len(v),)\n        amplitude = self.amplitude(v)\n\n        # complex vector; shape: (2, len(v))\n        psi = torch.zeros((2,) + amplitude.shape).to(\n            dtype=torch.double, device=self.device\n        )\n        psi[0] = amplitude\n\n        # squeeze down to complex scalar if there was only one visible state\n        return psi.squeeze()",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/Before/tests#test_observables.py"
        },
        "refactored_code": {
            "source_code": "def psi(self, v):\n        # vector/tensor of shape (len(v),)\n        return cplx.make_complex(self.amplitude(v))",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/After/tests#test_observables.py"
        },
        "variable_name": "amplitude",
        "label": "positive",
        "id": "806ae594-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 859
    },
    {
        "commit_hash": "1411a1c92f3fce385babe7b3785ee943f34c77b8",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "train",
            "container_name": "main",
            "source_code": "def train(source_loader, target_train_loader, target_test_loader, model, optimizer, CFG):\n    len_source_loader = len(source_loader)\n    len_target_loader = len(target_train_loader)\n    for e in range(CFG['epoch']):\n        # Train\n        model.train()\n        model.isTrain = True\n        iter_source, iter_target = iter(\n            source_loader), iter(target_train_loader)\n        n_batch = min(len_source_loader, len_target_loader)\n        criterion = torch.nn.CrossEntropyLoss()\n        for i in range(n_batch):\n            data_source, label_source = iter_source.next()\n            data_target, _ = iter_target.next()\n            data_source, label_source = data_source.to(\n                DEVICE), label_source.to(DEVICE)\n            data_target = data_target.to(DEVICE)\n\n            optimizer.zero_grad()\n            label_source_pred, loss_coral = model(data_source, data_target)\n            loss_cls = criterion(label_source_pred, label_source)\n            loss = loss_cls + CFG['lambda'] * loss_coral\n            loss.backward()\n            optimizer.step()\n            if i % CFG['log_interval'] == 0:\n                print('Train Epoch: [{}/{} ({:.0f}%)], \\\n                    total_Loss: {:.6f}, \\\n                    cls_Loss: {:.6f}, \\\n                    adapt_Loss: {:.6f}'.format(\n                    e + 1,\n                    CFG['epoch'],\n                    100. * i / len_source_loader, loss.item(), loss_cls.item(), loss_coral.item()))\n       \n        # Test\n        model.eval()\n        test_loss = 0\n        correct = 0\n        criterion = torch.nn.CrossEntropyLoss()\n        len_target_dataset = len(target_test_loader.dataset)\n        with torch.no_grad():\n            model.isTrain = False\n            for data, target in target_test_loader:\n                data, target = data.to(DEVICE), target.to(DEVICE)\n                s_output, _ = model(data, None)\n                test_loss += criterion(s_output, target)\n                pred = torch.max(s_output, 1)[1]\n                correct += torch.sum(pred == target.data)\n\n        test_loss /= len_target_dataset\n        print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n            target_name, test_loss, correct, len_target_dataset,\n            100. * correct / len_target_dataset))\n        print('source: {} to target: {} max correct: {} max accuracy{: .2f}%\\n'.format(\n            source_name, target_name, correct, 100. * correct / len_target_dataset))"
        },
        "original_method_after_refactoring": {
            "name": "train",
            "container_name": "main",
            "source_code": "def train(source_loader, target_train_loader, target_test_loader, model, optimizer, CFG):\n    len_source_loader = len(source_loader)\n    len_target_loader = len(target_train_loader)\n    train_loss_clf = utils.AverageMeter()\n    train_loss_transfer = utils.AverageMeter()\n    train_loss_total = utils.AverageMeter()\n    for e in range(CFG['epoch']):\n        model.train()\n        iter_source, iter_target = iter(\n            source_loader), iter(target_train_loader)\n        n_batch = min(len_source_loader, len_target_loader)\n        criterion = torch.nn.CrossEntropyLoss()\n        for i in range(n_batch):\n            data_source, label_source = iter_source.next()\n            data_target, _ = iter_target.next()\n            data_source, label_source = data_source.to(\n                DEVICE), label_source.to(DEVICE)\n            data_target = data_target.to(DEVICE)\n\n            optimizer.zero_grad()\n            label_source_pred, transfer_loss = model(data_source, data_target)\n            clf_loss = criterion(label_source_pred, label_source)\n            loss = clf_loss + CFG['lambda'] * transfer_loss\n            loss.backward()\n            optimizer.step()\n            train_loss_clf.update(clf_loss.item())\n            train_loss_transfer.update(transfer_loss.item())\n            train_loss_total.update(loss.item())\n            if i % CFG['log_interval'] == 0:\n                print('Train Epoch: [{}/{} ({:02d}%)], cls_Loss: {:.6f}, transfer_loss: {:.6f}, total_Loss: {:.6f}'.format(\n                    e + 1,\n                    CFG['epoch'],\n                    int(100. * i / n_batch), train_loss_clf.avg, train_loss_transfer.avg, train_loss_total.avg))\n\n        # Test\n        test(model, target_test_loader)"
        },
        "newly_extracted_method": {
            "name": "test",
            "container_name": "Unknown",
            "source_code": "def test(model, target_test_loader):\n    model.eval()\n    test_loss = utils.AverageMeter()\n    correct = 0\n    criterion = torch.nn.CrossEntropyLoss()\n    len_target_dataset = len(target_test_loader.dataset)\n    with torch.no_grad():\n        for data, target in target_test_loader:\n            data, target = data.to(DEVICE), target.to(DEVICE)\n            s_output = model.predict(data)\n            loss = criterion(s_output, target)\n            test_loss.update(loss.item())\n            pred = torch.max(s_output, 1)[1]\n            correct += torch.sum(pred == target)\n\n    print('{} --> {}: max correct: {}, accuracy{: .2f}%\\n'.format(\n        source_name, target_name, correct, 100. * correct / len_target_dataset))"
        },
        "label": "positive",
        "id": "805beab2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5304
    },
    {
        "commit_hash": "452ba701d7d365c22764cbdf0dca46e0df5b6d8a",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_chinese_handicap_handling(self):\n        final_board = go.load_board('''\n            ....WB...\n            .W.WWB...\n            W.W.B.B..\n            .WBBB....\n            WB...BB..\n            .B.BBW...\n            B.BWWBBB.\n            BBBW.WWB.\n            .BWWB.W..\n        ''')\n        final_position = go.Position(\n            board=final_board,\n            n=50,\n            komi=5.5,\n            caps=(7, 2),\n            groups=go.deduce_groups(final_board),\n            ko=None,\n            last=pc('F9'),\n            last2=pc('E9'),\n            player1turn=False,\n        )\n        sgf = sgf_wrapper.SgfWrapper(CHINESE_HANDICAP_SGF)\n        positions = list(sgf.get_main_branch())\n        self.assertEqualPositions(final_position, positions[-1])",
            "file_path": "commits/452ba701d7d365c22764cbdf0dca46e0df5b6d8a/Before/tests#test_sgf_wrapper.py"
        },
        "refactored_code": {
            "source_code": "def test_chinese_handicap_handling(self):\n        final_board = go.load_board('''\n            ....WB...\n            .W.WWB...\n            W.W.B.B..\n            .WBBB....\n            WB...BB..\n            .B.BBW...\n            B.BWWBBB.\n            BBBW.WWB.\n            .BWWB.W..\n        ''')\n        final_position = go.Position(\n            board=final_board,\n            n=50,\n            komi=5.5,\n            caps=(7, 2),\n            groups=go.deduce_groups(final_board),\n            ko=None,\n            last=pc('F9'),\n            last2=pc('E9'),\n            player1turn=False,\n        )\n        sgf = sgf_wrapper.SgfWrapper(CHINESE_HANDICAP_SGF)\n        positions_w_context = list(sgf.get_main_branch())\n        self.assertEqualPositions(final_position, positions_w_context[-1].position)",
            "file_path": "commits/452ba701d7d365c22764cbdf0dca46e0df5b6d8a/After/tests#test_sgf_wrapper.py"
        },
        "original_variable_name": "positions",
        "new_variable_name": "positions_w_context",
        "label": "positive",
        "id": "8067a42e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1969
    },
    {
        "commit_hash": "c2a6caae852adb0c832da86d5815c26b2e7d24c6",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "get_config",
            "container_name": "UpSampling2D",
            "source_code": "def get_config(self):\n        config = {'size': self.size,\n                  'data_format': self.data_format}\n        base_config = super(UpSampling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
            "file_path": "commits/c2a6caae852adb0c832da86d5815c26b2e7d24c6/Before/keras#layers#convolutional.py"
        },
        "inlined_method": {
            "name": "compute_output_shape",
            "container_name": "UpSampling2D",
            "source_code": "def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n            return (input_shape[0],\n                    input_shape[1],\n                    height,\n                    width)\n        elif self.data_format == 'channels_last':\n            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n            return (input_shape[0],\n                    height,\n                    width,\n                    input_shape[3])",
            "file_path": "commits/c2a6caae852adb0c832da86d5815c26b2e7d24c6/Before/keras#layers#convolutional.py"
        },
        "caller": {
            "name": "get_config",
            "container_name": "UpSampling2D",
            "source_code": "def get_config(self):\n        config = super(UpSampling2D, self).get_config()\n        config['interpolation'] = self.interpolation\n        return config",
            "file_path": "commits/c2a6caae852adb0c832da86d5815c26b2e7d24c6/After/keras#layers#convolutional.py"
        },
        "label": "negative",
        "id": "805edc36-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1809
    },
    {
        "commit_hash": "4a744f5768490d9cfd45c33a011476a509f6810c",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "_process_dataset",
            "container_name": "MonoTextData",
            "source_code": "def _process_dataset(self, dataset):\n        dataset_hparams = self._hparams.dataset\n\n        # Create data decoder\n        decoder = TextDataDecoder(\n            delimiter=dataset_hparams[\"delimiter\"],\n            bos_token=dataset_hparams[\"bos_token\"],\n            eos_token=dataset_hparams[\"eos_token\"],\n            max_seq_length=dataset_hparams[\"max_seq_length\"],\n            token_to_id_map=self._vocab.token_to_id_map)\n\n        # Process data\n        num_parallel_calls = self._hparams.num_parallel_calls\n        dataset = dataset.map(\n            decoder, num_parallel_calls=num_parallel_calls)\n\n        other_trans = dataset_hparams[\"other_transformations\"]\n        if len(other_trans) > 0:\n            for tran in other_trans:\n                tran_fn = utils.get_function(tran, [\"texar.custom\"])\n                other_trans.append(tran_fn)\n                dataset = dataset.map(\n                    lambda x: other_trans[-1](x, self),\n                    num_parallel_calls=num_parallel_calls)\n\n        return dataset, decoder"
        },
        "original_method_after_refactoring": {
            "name": "_process_dataset",
            "container_name": "MonoTextData",
            "source_code": "def _process_dataset(self, dataset):\n        dataset_hparams = self._hparams.dataset\n\n        # Create data decoder\n        decoder = TextDataDecoder(\n            delimiter=dataset_hparams[\"delimiter\"],\n            bos_token=dataset_hparams[\"bos_token\"],\n            eos_token=dataset_hparams[\"eos_token\"],\n            max_seq_length=dataset_hparams[\"max_seq_length\"],\n            token_to_id_map=self._vocab.token_to_id_map)\n\n        # Process data\n        num_parallel_calls = self._hparams.num_parallel_calls\n        dataset = dataset.map(\n            decoder, num_parallel_calls=num_parallel_calls)\n\n        return dataset, decoder"
        },
        "newly_extracted_method": {
            "name": "_perform_other_transformations",
            "container_name": "MonoTextData",
            "source_code": "def _perform_other_transformations(self, dataset):\n        other_trans_hparams = self._hparams.dataset.other_transformations\n        num_parallel_calls = self._hparams.num_parallel_calls\n        other_trans = []\n        for tran in other_trans_hparams:\n            if not utils.is_callable(tran):\n                tran = utils.get_function(tran, [\"texar.custom\"])\n            other_trans.append(tran)\n            dataset = dataset.map(\n                lambda x: other_trans[-1](x, self),\n                num_parallel_calls=num_parallel_calls)\n\n        return dataset"
        },
        "label": "positive",
        "id": "805beb70-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2644
    },
    {
        "commit_hash": "e245fa265fefa196338f12ad7b2ad65beaccb23e",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def build_single_input(input_feature_def, other_input_features, **kwargs):\n    logger.debug('Input {} feature {}'.format(\n        input_feature_def[TYPE],\n        input_feature_def[NAME]\n    ))\n\n    encoder_obj = None\n    if input_feature_def.get(TIED, None) is not None:\n        tied_input_feature_id = input_feature_def[TIED]\n        if tied_input_feature_id in other_input_features:\n            encoder_obj = other_input_features[\n                tied_input_feature_id].encoder_obj\n\n    input_feature_class = get_from_registry(\n        input_feature_def[TYPE],\n        input_type_registry\n    )\n    input_feature_obj = input_feature_class(input_feature_def, encoder_obj)\n\n    return input_feature_obj",
            "file_path": "commits/e245fa265fefa196338f12ad7b2ad65beaccb23e/Before/ludwig#models#ecd.py"
        },
        "refactored_code": {
            "source_code": "def build_single_input(input_feature_def, other_input_features, **kwargs):\n    logger.debug('Input {} feature {}'.format(\n        input_feature_def[TYPE],\n        input_feature_def[NAME]\n    ))\n\n    encoder_obj = None\n    if input_feature_def.get(TIED, None) is not None:\n        tied_input_feature_name = input_feature_def[TIED]\n        if tied_input_feature_name in other_input_features:\n            encoder_obj = other_input_features[\n                tied_input_feature_name].encoder_obj\n\n    input_feature_class = get_from_registry(\n        input_feature_def[TYPE],\n        input_type_registry\n    )\n    input_feature_obj = input_feature_class(input_feature_def, encoder_obj)\n\n    return input_feature_obj",
            "file_path": "commits/e245fa265fefa196338f12ad7b2ad65beaccb23e/After/ludwig#models#ecd.py"
        },
        "original_variable_name": "tied_input_feature_id",
        "new_variable_name": "tied_input_feature_name",
        "label": "positive",
        "id": "8067a3d4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1816
    },
    {
        "commit_hash": "e24661a1aa2a86a6e69877c91a3c6803d78b3c22",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def draw(self, **kwargs):\n        \"\"\"\n        Plots a scatterplot of points that represented the decomposition,\n        `pca_features_`, of the original features, `X`, projected into either 2 or\n        3 dimensions.\n\n        If 2 dimensions are selected, a colorbar and heatmap can also be optionally\n        included to show the magnitude of each feature value to the component.\n\n        Returns\n        -------\n        self : visualizer.ax\n            Returns the axes of the visualizer for use in Pipelines\n        \"\"\"\n        X = self.pca_features_\n        if self.proj_dim == 2:\n            im = self.ax.scatter(\n                X[:, 0],\n                X[:, 1],\n                c=self.color,\n                cmap=self.colormap,\n                alpha=self.alpha,\n                vmin=self.pca_components_.min(),\n                vmax=self.pca_components_.max(),\n                **kwargs\n            )\n            if self.colorbar:\n                plt.colorbar(\n                    im,\n                    cax=self.uax,\n                    orientation=\"horizontal\",\n                    ticks=[self.pca_components_.min(), 0, self.pca_components_.max()],\n                )\n            if self.heatmap:\n                # TODO: change to pcolormesh instead of imshow per #615 spec\n                self.lax.imshow(\n                    self.pca_components_, interpolation=\"none\", cmap=self.colormap\n                )\n            if self.proj_features:\n                x_vector = self.pca_components_[0]\n                y_vector = self.pca_components_[1]\n                max_x = max(X[:, 0])\n                max_y = max(X[:, 1])\n                for i in range(self.pca_components_.shape[1]):\n                    self.ax.arrow(\n                        x=0,\n                        y=0,\n                        dx=x_vector[i] * max_x,\n                        dy=y_vector[i] * max_y,\n                        color=\"r\",\n                        head_width=0.05,\n                        width=0.005,\n                    )\n                    self.ax.text(\n                        x_vector[i] * max_x * 1.05,\n                        y_vector[i] * max_y * 1.05,\n                        self.features_[i],\n                        color=\"r\",\n                    )\n        if self.proj_dim == 3:\n            self.fig = plt.figure()\n            self.ax = self.fig.add_subplot(111, projection=\"3d\")\n            self.ax.scatter(\n                X[:, 0],\n                X[:, 1],\n                X[:, 2],\n                c=self.color,\n                cmap=self.colormap,\n                alpha=self.alpha,\n            )\n            if self.proj_features:\n                x_vector = self.pca_components_[0]\n                y_vector = self.pca_components_[1]\n                z_vector = self.pca_components_[2]\n                max_x = max(X[:, 0])\n                max_y = max(X[:, 1])\n                max_z = max(X[:, 1])\n                for i in range(self.pca_components_.shape[1]):\n                    self.ax.plot(\n                        [0, x_vector[i] * max_x],\n                        [0, y_vector[i] * max_y],\n                        [0, z_vector[i] * max_z],\n                        color=\"r\",\n                    )\n                    self.ax.text(\n                        x_vector[i] * max_x * 1.05,\n                        y_vector[i] * max_y * 1.05,\n                        z_vector[i] * max_z * 1.05,\n                        self.features_[i],\n                        color=\"r\",\n                    )\n        return self.ax",
            "file_path": "commits/e24661a1aa2a86a6e69877c91a3c6803d78b3c22/Before/yellowbrick#features#pca.py"
        },
        "refactored_code": {
            "source_code": "def draw(self, Xp, y):\n        \"\"\"\n        Plots a scatterplot of points that represented the decomposition,\n        `pca_features_`, of the original features, `X`, projected into either 2 or\n        3 dimensions.\n\n        If 2 dimensions are selected, a colorbar and heatmap can also be optionally\n        included to show the magnitude of each feature value to the component.\n        \n        Parameters\n        ----------\n        Xp : array-like of shape (n, 2) or (n, 3)\n            The matrix produced by the ``transform()`` method.\n\n        y : array-like of shape (n,), optional\n            The target, used to specify the colors of the points.\n\n\n        Returns\n        -------\n        self.ax : matplotlib Axes object\n            Returns the axes that the scatter plot was drawn on.\n        \"\"\"\n        # Call to super draw which draws the scatter plot.\n        super(PCA, self).draw(Xp, y)\n        if self.proj_features:\n            # Draws projection features in transformed space.\n            self._draw_projection_features(Xp, y)\n        if self.projection == 2:\n            if self.heatmap:\n                # TODO: change to pcolormesh instead of imshow per #615 spec\n                im = self.lax.imshow(\n                    self.pca_components_, interpolation=\"none\", cmap=self.colormap\n                )\n                plt.colorbar(\n                    im,\n                    cax=self.uax,\n                    orientation=\"horizontal\",\n                    ticks=[self.pca_components_.min(), 0, self.pca_components_.max()],\n                )\n        return self.ax",
            "file_path": "commits/e24661a1aa2a86a6e69877c91a3c6803d78b3c22/After/yellowbrick#features#pca.py"
        },
        "variable_name": "im",
        "label": "positive",
        "id": "8069bafc-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5568
    },
    {
        "commit_hash": "187ff9cbb00a07c789897a717c65c8bbf3b21164",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "get_head_version",
            "container_name": "RDBStorage",
            "source_code": "def get_head_version(self):\n        # type: () -> str\n        \"\"\"Return the latest schema version.\"\"\"\n\n        script = self._create_alembic_script()\n        return script.get_current_head()"
        },
        "original_method_after_refactoring": {
            "name": "get_head_version",
            "container_name": "RDBStorage",
            "source_code": "def get_head_version(self):\n        # type: () -> str\n        \"\"\"Return the latest schema version.\"\"\"\n\n        return self._version_manager._get_head_version()"
        },
        "newly_extracted_method": {
            "name": "_get_head_version",
            "container_name": "_VersionManager",
            "source_code": "def _get_head_version(self):\n        # type: () -> str\n\n        script = self._create_alembic_script()\n        return script.get_current_head()"
        },
        "label": "positive",
        "id": "805bfdf4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 846
    },
    {
        "commit_hash": "c270e59bf951bca41743bd03272e5b3f255be97c",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def _generate_hp_values(self, hp_list):\n        best_trials = self.get_best_trials()\n        if best_trials:\n            best_hps = best_trials[0].hyperparameters\n        else:\n            best_hps = self.hyperparameters\n\n        collisions = 0\n        while True:\n            hps = copy.deepcopy(best_hps)\n            # Generate a set of random values.\n            for hp in hp_list:\n                # TODO: Check is_active for hp.\n                hps.values[hp.name] = hp.random_sample(self._seed_state)\n                self._seed_state += 1\n            values = hps.values\n            # Keep trying until the set of values is unique,\n            # or until we exit due to too many collisions.\n            values_hash = self._compute_values_hash(values)\n            if values_hash in self._tried_so_far:\n                collisions += 1\n                if collisions <= self._max_collisions:\n                    continue\n                return None\n            self._tried_so_far.add(values_hash)\n            break\n        return values",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/Before/autokeras#tuners#greedy.py"
        },
        "refactored_code": {
            "source_code": "def _get_best_hps(self):\n        best_trials = self.get_best_trials()\n        if best_trials:\n            return best_trials[0].hyperparameters\n        else:\n            return self.hyperparameters",
            "file_path": "commits/c270e59bf951bca41743bd03272e5b3f255be97c/After/autokeras#tuners#greedy.py"
        },
        "variable_name": "best_hps",
        "label": "positive",
        "id": "806aea3a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1607
    },
    {
        "commit_hash": "bed2aa4de23a40c6c96403446495ce30acf92e21",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def forward_a(self, x, z):\n    z = self.mlpA(z)\n    z1, z2, z3, z4 = torch.split(z, self.tch_add, dim=1)\n    z1 = z1.contiguous()\n    z2 = z2.contiguous()\n    z3 = z3.contiguous()\n    z4 = z4.contiguous()\n    out1 = self.decA1(x, z1)\n    out2 = self.decA2(out1, z2)\n    out3 = self.decA3(out2, z3)\n    out4 = self.decA4(out3, z4)\n    out = self.decA5(out4)\n    return out",
            "file_path": "commits/bed2aa4de23a40c6c96403446495ce30acf92e21/Before/src#networks.py"
        },
        "refactored_code": {
            "source_code": "def forward_a(self, x, z):\n    z = self.mlpA(z)\n    z1, z2, z3, z4 = torch.split(z, self.tch_add, dim=1)\n    z1, z2, z3, z4 = z1.contiguous(), z2.contiguous(), z3.contiguous(), z4.contiguous()\n    out1 = self.decA1(x, z1)\n    out2 = self.decA2(out1, z2)\n    out3 = self.decA3(out2, z3)\n    out4 = self.decA4(out3, z4)\n    out = self.decA5(out4)\n    return out",
            "file_path": "commits/bed2aa4de23a40c6c96403446495ce30acf92e21/After/src#networks.py"
        },
        "variable_name": "z1",
        "label": "negative",
        "id": "806ae45e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1065
    },
    {
        "commit_hash": "7be56405f2af0f700763249da3c368976582d792",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "get_updated_memory",
            "container_name": "TGN",
            "source_code": "def get_updated_memory(self, n_id):\n        \"\"\"\n        Returns updated memory for nodes in n_id using the messages stored in the message stores for these nodes\n        \"\"\"\n        aggr, t, idx = self.get_aggregated_messages(n_id)\n\n        # Get local copy of updated memory.\n        memory = self.gru(aggr, self.memory[n_id])\n\n        # Get local copy of updated `last_update`.\n        last_update = self.last_update.scatter(0, idx, t)[n_id]\n\n        return memory, last_update",
            "file_path": "commits/7be56405f2af0f700763249da3c368976582d792/Before/torch_geometric#nn#models#tgn.py"
        },
        "inlined_method": {
            "name": "get_aggregated_messages",
            "container_name": "TGN",
            "source_code": "def get_aggregated_messages(self, n_id):\n        self.assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n\n        # Compute messages (src -> dst).\n        msg_s, t_s, src_s, dst_s = self.compute_messages(\n            n_id, self.msg_s_store, self.msg_s_module)\n\n        # Compute messages (dst -> src).\n        msg_d, t_d, src_d, dst_d = self.compute_messages(\n            n_id, self.msg_d_store, self.msg_d_module)\n\n        # Aggregate messages.\n        idx = torch.cat([src_s, src_d], dim=0)\n        msg = torch.cat([msg_s, msg_d], dim=0)\n        t = torch.cat([t_s, t_d], dim=0)\n        aggr = self.aggr_module(msg, self.assoc[idx], t, dim_size=n_id.size(0))\n\n        return aggr, t, idx",
            "file_path": "commits/7be56405f2af0f700763249da3c368976582d792/Before/torch_geometric#nn#models#tgn.py"
        },
        "caller": {
            "name": "get_updated_memory",
            "container_name": "TGN",
            "source_code": "def get_updated_memory(self, n_id):\n        \"\"\"Returns the updated memory for nodes in :obj:`n_id` using the\n        messages stored in the message stores for these nodes.\"\"\"\n        self.assoc[n_id] = torch.arange(n_id.size(0), device=n_id.device)\n\n        # Compute messages (src -> dst).\n        msg_s, t_s, src_s, dst_s = self.compute_messages(\n            n_id, self.msg_s_store, self.msg_s_module)\n\n        # Compute messages (dst -> src).\n        msg_d, t_d, src_d, dst_d = self.compute_messages(\n            n_id, self.msg_d_store, self.msg_d_module)\n\n        # Aggregate messages.\n        idx = torch.cat([src_s, src_d], dim=0)\n        msg = torch.cat([msg_s, msg_d], dim=0)\n        t = torch.cat([t_s, t_d], dim=0)\n        aggr = self.aggr_module(msg, self.assoc[idx], t, dim_size=n_id.size(0))\n\n        # Get local copy of updated memory.\n        memory = self.gru(aggr, self.memory[n_id])\n\n        # Get local copy of updated `last_update`.\n        last_update = self.last_update.scatter(0, idx, t)[n_id]\n\n        return memory, last_update",
            "file_path": "commits/7be56405f2af0f700763249da3c368976582d792/After/torch_geometric#nn#models#tgn.py"
        },
        "label": "positive",
        "id": "805ee0fa-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2921
    },
    {
        "commit_hash": "7c4f035497540e3217042201d08693a5ecc12b55",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _resample_bspline(self, inputs, sample_coords):\n\n        in_size = inputs.get_shape().as_list()\n        in_spatial_size = in_size[1:-1]\n        in_spatial_rank = infer_spatial_rank(inputs)\n        batch_size = in_size[0]\n\n        out_spatial_rank = infer_spatial_rank(sample_coords)\n        input_size = tf.reshape(\n            in_spatial_size, [1] * (out_spatial_rank + 1) + [-1])\n        if in_spatial_rank == 2:\n            raise NotImplementedError(\n                'bspline interpolation not implemented for 2d yet')\n        index_voxel_coords = tf.floor(sample_coords)\n        # Compute voxels to use for interpolation\n        grid = tf.meshgrid([-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           indexing='ij')\n        offset_shape = [1, 4 ** in_spatial_rank] + \\\n                       [1] * out_spatial_rank + [in_spatial_rank]\n        offsets = tf.reshape(tf.stack(grid, 3), offset_shape)\n        preboundary_spatial_coords = offsets + \\\n                                     tf.expand_dims(\n                                         tf.cast(index_voxel_coords, tf.int32),\n                                         1)\n        spatial_coords = self.boundary_func(\n            preboundary_spatial_coords, input_size)\n        sz = spatial_coords.get_shape().as_list()\n\n        # Compute weights for each voxel\n        def build_coef(u, d):\n            coeff_list = [tf.pow(1 - u, 3),\n                          3 * tf.pow(u, 3) - 6 * tf.pow(u, 2) + 4,\n                          -3 * tf.pow(u, 3) + 3 * tf.pow(u, 2) + 3 * u + 1,\n                          tf.pow(u, 3)]\n            return tf.concat(coeff_list, d) / 6\n\n        weight = tf.reshape(sample_coords - index_voxel_coords,\n                            [batch_size, -1, 3])\n        coef_shape = [batch_size, 1, 1, 1, -1]\n        Bu = build_coef(tf.reshape(weight[:, :, 0], coef_shape), 1)\n        Bv = build_coef(tf.reshape(weight[:, :, 1], coef_shape), 2)\n        Bw = build_coef(tf.reshape(weight[:, :, 2], coef_shape), 3)\n        all_weights = tf.reshape(Bu * Bv * Bw, [batch_size] + sz[1:-1] + [1])\n        # Gather voxel values and compute weighted sum\n        batch_coords = tf.reshape(\n            tf.range(batch_size), [batch_size] + [1] * (len(sz) - 1))\n        batch_coords = tf.tile(batch_coords, [1] + sz[1:-1] + [1])\n        raw_samples = tf.gather_nd(\n            inputs, tf.concat([batch_coords, spatial_coords], -1))\n        return tf.reduce_sum(all_weights * raw_samples, reduction_indices=1)",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/Before/niftynet#layer#resampler.py"
        },
        "refactored_code": {
            "source_code": "def _resample_bspline(self, inputs, sample_coords):\n        in_size = inputs.get_shape().as_list()\n        batch_size = in_size[0]\n        in_spatial_size = in_size[1:-1]\n        in_spatial_rank = infer_spatial_rank(inputs)\n\n        out_spatial_rank = infer_spatial_rank(sample_coords)\n        if in_spatial_rank == 2:\n            raise NotImplementedError(\n                'bspline interpolation not implemented for 2d yet')\n        floor_coords = tf.floor(sample_coords)\n\n        # Compute voxels to use for interpolation\n        grid = tf.meshgrid([-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           indexing='ij')\n        offset_shape = [1, -1] + [1] * out_spatial_rank + [in_spatial_rank]\n        offsets = tf.reshape(tf.stack(grid, 3), offset_shape)\n        spatial_coords = \\\n            offsets + tf.expand_dims(tf.cast(floor_coords, tf.int32), 1)\n        spatial_coords = self.boundary_func(spatial_coords, in_spatial_size)\n        knot_size = spatial_coords.get_shape().as_list()\n\n        # Compute weights for each voxel\n        def build_coef(u, d):\n            coeff_list = [tf.pow(1 - u, 3),\n                          3 * tf.pow(u, 3) - 6 * tf.pow(u, 2) + 4,\n                          -3 * tf.pow(u, 3) + 3 * tf.pow(u, 2) + 3 * u + 1,\n                          tf.pow(u, 3)]\n            return tf.concat(coeff_list, d) / 6\n\n        weight = tf.reshape(sample_coords - floor_coords, [batch_size, -1, 3])\n        coef_shape = [batch_size, 1, 1, 1, -1]\n        Bu = build_coef(tf.reshape(weight[:, :, 0], coef_shape), 1)\n        Bv = build_coef(tf.reshape(weight[:, :, 1], coef_shape), 2)\n        Bw = build_coef(tf.reshape(weight[:, :, 2], coef_shape), 3)\n        all_weights = tf.reshape(Bu * Bv * Bw,\n                                 [batch_size] + knot_size[1:-1] + [1])\n        # Gather voxel values and compute weighted sum\n        batch_coords = tf.reshape(\n            tf.range(batch_size), [batch_size] + [1] * (len(knot_size) - 1))\n        batch_coords = tf.tile(batch_coords, [1] + knot_size[1:-1] + [1])\n        raw_samples = tf.gather_nd(\n            inputs, tf.concat([batch_coords, spatial_coords], -1))\n        return tf.reduce_sum(all_weights * raw_samples, reduction_indices=1)",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/After/niftynet#layer#resampler.py"
        },
        "original_variable_name": "sz",
        "new_variable_name": "knot_size",
        "label": "positive",
        "id": "80679d30-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5273
    },
    {
        "commit_hash": "632596ae718297a6c36bf87c8303298d672fd851",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "switch_dropout",
            "container_name": "utils",
            "source_code": "def switch_dropout(dropout_keep_prob, mode=None):\n    \"\"\"Turns off dropout when not in training mode.\n\n    Args:\n        dropout_keep_prob: Dropout keep probability in training mode\n        mode (optional): A Tensor taking values of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Dropout is activated if :attr:`mode` is `TRAIN`.\n            If `None`, the mode is inferred from\n            :func:`texar.context.global_mode`.\n\n    Returns:\n        A unit Tensor that equals the dropout keep probability in `TRAIN` mode,\n        and `1.` in other modes.\n    \"\"\"\n    if mode is None:\n        is_train = context.global_mode_train()\n    else:\n        is_train = tf.equal(mode, tf.estimator.ModeKeys.TRAIN)\n    return 1. - (1. - dropout_keep_prob) * tf.to_float(is_train)"
        },
        "original_method_after_refactoring": {
            "name": "switch_dropout",
            "container_name": "utils",
            "source_code": "def switch_dropout(dropout_keep_prob, mode=None):\n    \"\"\"Turns off dropout when not in training mode.\n\n    Args:\n        dropout_keep_prob: Dropout keep probability in training mode\n        mode (optional): A Tensor taking values of\n            :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n            Dropout is activated if :attr:`mode` is `TRAIN`.\n            If `None`, the mode is inferred from\n            :func:`texar.context.global_mode`.\n\n    Returns:\n        A unit Tensor that equals the dropout keep probability in `TRAIN` mode,\n        and `1.` in other modes.\n    \"\"\"\n    return 1. - (1. - dropout_keep_prob) * tf.to_float(is_train_mode(mode))"
        },
        "newly_extracted_method": {
            "name": "is_train_mode",
            "container_name": "utils",
            "source_code": "def is_train_mode(mode):\n    \"\"\"Returns a bool Tensor indicating whether the global mode is TRAIN.\n    If :attr:`mode` is `None`, the mode is determined by\n    :func:`texar.contex.global_mode`.\n    \"\"\"\n    if mode is None:\n        return context.global_mode_train()\n    else:\n        return tf.equal(mode, tf.estimator.ModeKeys.TRAIN)"
        },
        "label": "positive",
        "id": "805bebd4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2153
    },
    {
        "commit_hash": "f69e046eef93af5a28de5330bfe15ee348520b2d",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir='TB',\n                 expand_nested=False,\n                 dpi=96,\n                 subgraph=False):\n    \"\"\"Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n        subgraph: whether to return a pydot.Cluster instance.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model or\n        a `pydot.Cluster` instance representing nested model if\n        `subgraph=True`.\n    \"\"\"\n    from ..layers.wrappers import Wrapper\n    from ..models import Model\n    from ..models import Sequential\n\n    _check_pydot()\n    if subgraph:\n        dot = pydot.Cluster(style='dashed')\n        dot.set('label', model.name)\n        dot.set('labeljust', 'l')\n    else:\n        dot = pydot.Dot()\n        dot.set('rankdir', rankdir)\n        dot.set('concentrate', True)\n        dot.set('dpi', dpi)\n        dot.set_node_defaults(shape='record')\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n    layers = model._layers\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Model):\n                submodel = model_to_dot(layer.layer, show_shapes,\n                                        show_layer_names, rankdir, expand_nested,\n                                        subgraph=True)\n                model_nodes = submodel.get_nodes()\n                dot.add_edge(pydot.Edge(layer_id, model_nodes[0].get_name()))\n                if len(layers) > i + 1:\n                    next_layer_id = str(id(layers[i + 1]))\n                    dot.add_edge(pydot.Edge(\n                        model_nodes[len(model_nodes) - 1].get_name(),\n                        next_layer_id))\n                dot.add_subgraph(submodel)\n            else:\n                layer_name = '{}({})'.format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = '{}({})'.format(class_name, child_class_name)\n\n        # Create node's label.\n        if show_layer_names:\n            label = '{}: {}'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = 'multiple'\n            if hasattr(layer, 'input_shape'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, 'input_shapes'):\n                inputlabels = ', '.join(\n                    [str(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = 'multiple'\n            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n        node = pydot.Node(layer_id, label=label)\n        dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + '_ib-' + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in node.inbound_layers:\n                    if not expand_nested or not (\n                            isinstance(inbound_layer, Wrapper) and\n                            isinstance(inbound_layer.layer, Model)):\n                        inbound_layer_id = str(id(inbound_layer))\n                        # Make sure that both nodes exist before connecting them with\n                        # an edge, as add_edge would otherwise\n                        # create any missing node.\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n    return dot",
            "file_path": "commits/f69e046eef93af5a28de5330bfe15ee348520b2d/Before/keras#utils#vis_utils.py"
        },
        "refactored_code": {
            "source_code": "def model_to_dot(model,\n                 show_shapes=False,\n                 show_layer_names=True,\n                 rankdir='TB',\n                 expand_nested=False,\n                 dpi=96,\n                 subgraph=False):\n    \"\"\"Convert a Keras model to dot format.\n\n    # Arguments\n        model: A Keras model instance.\n        show_shapes: whether to display shape information.\n        show_layer_names: whether to display layer names.\n        rankdir: `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot:\n            'TB' creates a vertical plot;\n            'LR' creates a horizontal plot.\n        expand_nested: whether to expand nested models into clusters.\n        dpi: dot DPI.\n        subgraph: whether to return a pydot.Cluster instance.\n\n    # Returns\n        A `pydot.Dot` instance representing the Keras model or\n        a `pydot.Cluster` instance representing nested model if\n        `subgraph=True`.\n    \"\"\"\n    from ..layers.wrappers import Wrapper\n    from ..models import Model\n    from ..models import Sequential\n\n    _check_pydot()\n    if subgraph:\n        dot = pydot.Cluster(style='dashed', graph_name=model.name)\n        dot.set('label', model.name)\n        dot.set('labeljust', 'l')\n    else:\n        dot = pydot.Dot()\n        dot.set('rankdir', rankdir)\n        dot.set('concentrate', True)\n        dot.set('dpi', dpi)\n        dot.set_node_defaults(shape='record')\n\n    if isinstance(model, Sequential):\n        if not model.built:\n            model.build()\n    layers = model._layers\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Model):\n                submodel_wrapper = model_to_dot(layer.layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n                # sub_w : submodel_wrapper\n                sub_w_nodes = submodel_wrapper.get_nodes()\n                sub_w_first_node = sub_w_nodes[0]\n                sub_w_last_node = sub_w_nodes[len(sub_w_nodes) - 1]\n                dot.add_subgraph(submodel_wrapper)\n            else:\n                layer_name = '{}({})'.format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = '{}({})'.format(class_name, child_class_name)\n\n        if expand_nested and isinstance(layer, Model):\n            submodel_not_wrapper = model_to_dot(layer, show_shapes,\n                                                show_layer_names, rankdir,\n                                                expand_nested,\n                                                subgraph=True)\n            # sub_n : submodel_not_wrapper\n            sub_n_nodes = submodel_not_wrapper.get_nodes()\n            sub_n_first_node = sub_n_nodes[0]\n            sub_n_last_node = sub_n_nodes[len(sub_n_nodes) - 1]\n            dot.add_subgraph(submodel_not_wrapper)\n\n        # Create node's label.\n        if show_layer_names:\n            label = '{}: {}'.format(layer_name, class_name)\n        else:\n            label = class_name\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n            try:\n                outputlabels = str(layer.output_shape)\n            except AttributeError:\n                outputlabels = 'multiple'\n            if hasattr(layer, 'input_shape'):\n                inputlabels = str(layer.input_shape)\n            elif hasattr(layer, 'input_shapes'):\n                inputlabels = ', '.join(\n                    [str(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = 'multiple'\n            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                           inputlabels,\n                                                           outputlabels)\n\n        if not expand_nested or not isinstance(layer, Model):\n            node = pydot.Node(layer_id, label=label)\n            dot.add_node(node)\n\n    # Connect nodes with edges.\n    for layer in layers:\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + '_ib-' + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in node.inbound_layers:\n                    inbound_layer_id = str(id(inbound_layer))\n                    if not expand_nested:\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n                    else:\n                        # if inbound_layer is not Model or wrapped Model\n                        if not is_model(inbound_layer) and (\n                                not is_wrapped_model(inbound_layer)):\n                            # if current layer is not Model or wrapped Model\n                            if not is_model(layer) and (\n                                    not is_wrapped_model(layer)):\n                                assert dot.get_node(inbound_layer_id)\n                                assert dot.get_node(layer_id)\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                            # if current layer is Model\n                            elif is_model(layer):\n                                add_edge(dot, inbound_layer_id,\n                                         sub_n_first_node.get_name())\n                            # if current layer is wrapped Model\n                            elif is_wrapped_model(layer):\n                                dot.add_edge(pydot.Edge(inbound_layer_id,\n                                                        layer_id))\n                                dot.add_edge(pydot.Edge(layer_id,\n                                                        sub_w_first_node.get_name()))\n                        # if inbound_layer is Model\n                        elif is_model(inbound_layer):\n                            add_edge(dot, sub_n_last_node.get_name(), layer_id)\n                        # if inbound_layer is wrapped Model\n                        elif is_wrapped_model(inbound_layer):\n                            add_edge(dot, sub_w_last_node.get_name(), layer_id)\n    return dot",
            "file_path": "commits/f69e046eef93af5a28de5330bfe15ee348520b2d/After/keras#utils#vis_utils.py"
        },
        "original_variable_name": "model_nodes",
        "new_variable_name": "sub_w_nodes",
        "label": "positive",
        "id": "806790ec-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 12164
    },
    {
        "commit_hash": "dd3469ee312513f2b8a1b2e4e90e8eb95a6f3bbb",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "batch_dataset",
            "container_name": "data_utils",
            "source_code": "def batch_dataset(dataset, batch_size):\n    shape = nest.flatten(dataset_shape(dataset))[0]\n    if shape[0] is not None:\n        return dataset.batch(batch_size)\n    return dataset"
        },
        "original_method_after_refactoring": {
            "name": "batch_dataset",
            "container_name": "data_utils",
            "source_code": "def batch_dataset(dataset, batch_size):\n    if batched(dataset):\n        return dataset\n    return dataset.batch(batch_size)"
        },
        "newly_extracted_method": {
            "name": "batched",
            "container_name": "data_utils",
            "source_code": "def batched(dataset):\n    shape = nest.flatten(dataset_shape(dataset))[0]\n    return len(shape) > 0 and shape[0] is None"
        },
        "label": "positive",
        "id": "805bf61a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 753
    },
    {
        "commit_hash": "683c1b13a82e2fa94d369ce275ebf439be943a88",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def test_structured_classifier(init, fit, tmp_path):\n    num_data = 500\n    train_x = utils.generate_structured_data(num_data)\n    train_y = utils.generate_one_hot_labels(num_instances=num_data, num_classes=3)\n\n    clf = structured_data.StructuredDataClassifier(\n        column_names=utils.COLUMN_NAMES_FROM_NUMPY,\n        directory=tmp_path,\n        max_trials=1,\n        seed=utils.SEED)\n    clf.fit(train_x, train_y, epochs=2, validation_data=(train_x, train_y))\n\n    assert init.called\n    assert fit.called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/Before/tests#autokeras#tasks#structure_data_test.py"
        },
        "refactored_code": {
            "source_code": "def test_structured_clf_fit_call_auto_model_fit(fit, tmp_path):\n    auto_model = ak.StructuredDataClassifier(directory=tmp_path, seed=utils.SEED)\n\n    auto_model.fit(\n        x=utils.generate_structured_data(num_instances=100),\n        y=utils.generate_one_hot_labels(num_instances=100, num_classes=3))\n\n    assert fit.is_called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/After/tests#autokeras#tasks#structure_data_test.py"
        },
        "variable_name": "train_y",
        "label": "negative",
        "id": "806ae710-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1236
    },
    {
        "commit_hash": "a8136afcb53b4c26b251be583b57ff53f8e32aab",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "r2_op",
            "container_name": "metrics",
            "source_code": "def r2_op(predictions, targets, inputs):\n    \"\"\" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = r2_op(y_pred, y_true, input_data)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        inputs: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('StandardError'):\n        if hasattr(inputs, '__len__'):\n            inputs = tf.add_n(inputs)\n        if inputs.get_shape().as_list() != targets.get_shape().as_list():\n            raise Exception(\"R2 metric requires Inputs and Targets to have \"\n                            \"same shape.\")\n        a = tf.reduce_sum(tf.square(predictions - inputs))\n        b = tf.reduce_sum(tf.square(targets - inputs))\n        return tf.div(a, b)"
        },
        "original_method_after_refactoring": {
            "name": "r2_op",
            "container_name": "metrics",
            "source_code": "def r2_op(predictions, targets):\n    \"\"\" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = r2_op(y_pred, y_true)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('StandardError'):\n        a = tf.reduce_sum(tf.square(predictions))\n        b = tf.reduce_sum(tf.square(targets))\n        return tf.div(a, b)"
        },
        "newly_extracted_method": {
            "name": "weighted_r2_op",
            "container_name": "metrics",
            "source_code": "def weighted_r2_op(predictions, targets, inputs):\n    \"\"\" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = r2_op(y_pred, y_true, input_data)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        inputs: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('WeightedStandardError'):\n        if hasattr(inputs, '__len__'):\n            inputs = tf.add_n(inputs)\n        if inputs.get_shape().as_list() != targets.get_shape().as_list():\n            raise Exception(\"Weighted R2 metric requires Inputs and Targets to \"\n                            \"have same shape.\")\n        a = tf.reduce_sum(tf.square(predictions - inputs))\n        b = tf.reduce_sum(tf.square(targets - inputs))\n        return tf.div(a, b)"
        },
        "label": "positive",
        "id": "805beb98-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3471
    },
    {
        "commit_hash": "f86ceee1b4a5cfa7ddc728eabcffc6327e853af3",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _build(self, helper, initial_state=None):\n        \"\"\"Performs decoding.\n\n        Args:\n            helper: An instance of `tf.contrib.seq2seq.Helper` that helps with\n                the decoding process. For example, use an instance of\n                `TrainingHelper` in training phase.\n            initial_state (optional): Initial state of decoding.\n                If `None` (default), zero state is used.\n            mode (optional): A member of\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n                If `None`, :func:`~texar.context.global_mode` is used.\n                Note that if :attr:`cell` is given when constructing the\n                deocoder, the :attr:`mode` here does not have an effect to\n                :attr:`cell`.\n\n        Returns:\n            `(outputs, final_state, sequence_lengths)`: `outputs` is an object\n            containing the decoder output on all time steps, `final_state` is\n            the cell state of the final time step, `sequence_lengths` is a\n            Tensor of shape `[batch_size]`.\n        \"\"\"\n        self._helper = helper\n        if initial_state is not None:\n            self._initial_state = initial_state\n        else:\n            self._initial_state = self.zero_state(\n                batch_size=self.batch_size, dtype=tf.float32)\n\n        max_decoding_length_train = self._hparams.max_decoding_length_train\n        if max_decoding_length_train is None:\n            max_decoding_length_train = utils.MAX_SEQ_LENGTH\n        max_decoding_length_infer = self._hparams.max_decoding_length_infer\n        if max_decoding_length_infer is None:\n            max_decoding_length_infer = utils.MAX_SEQ_LENGTH\n        max_decoding_length = tf.cond(\n            #utils.is_train_mode(mode),\n            context.global_mode_train(),\n            lambda: max_decoding_length_train,\n            lambda: max_decoding_length_infer)\n        outputs, final_state, sequence_lengths = dynamic_decode(\n            decoder=self, maximum_iterations=max_decoding_length)\n\n        if not self._built:\n            self._add_internal_trainable_variables()\n            # Add trainable variables of `self._cell` which may be\n            # constructed externally.\n            self._add_trainable_variable(\n                layers.get_rnn_cell_trainable_variables(self._cell))\n            if isinstance(self._output_layer, tf.layers.Layer):\n                self._add_trainable_variable(\n                    self._output_layer.trainable_variables)\n            self._built = True\n\n        return outputs, final_state, sequence_lengths",
            "file_path": "commits/f86ceee1b4a5cfa7ddc728eabcffc6327e853af3/Before/texar#modules#decoders#rnn_decoder_base.py"
        },
        "refactored_code": {
            "source_code": "def _build(self, initial_state=None, max_decoding_length=None,\n               output_time_major=False, decoding_strategy=\"train_greedy\",\n               inputs=None, sequence_length=None, input_time_major=False,\n               embedding=None, start_tokens=None, end_token=None,\n               softmax_temperature=None, helper=None, mode=None, **kwargs):\n        \"\"\"Performs decoding. The decoder provides 3 ways to specify the\n        decoding strategy, with varying flexibility:\n\n        - :attr:`decoding_strategy` argument: A string taking value:\n\n            - \"train_greedy\": decoding in training fashion (i.e., feeding \\\n              ground truth to decode the next step), and each sample is \\\n              obtained by taking the argmax of the RNN output logits. \\\n              Arguments :attr:`(inputs, sequence_length, input_time_major)` \\\n              are required for this strategy, and argument :attr:`embedding` \\\n              is optional.\n            - \"infer_greedy\": decoding in inference fashion (i.e., feeding \\\n              the generated sample to decode the next step), and each sample\\\n              is obtained by taking the argmax of the RNN output logits.\\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n            - \"infer_sample\": decoding in inference fashion, and each sample \\\n              is obtained by random sampling from the RNN output distribution. \\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n\n          This argument is used only when :attr:`helper` is `None`.\n\n        - :attr:`helper` argument: An instance of \\\n          :tf_main:`tf.contrib.seq2seq.Helper <contrib/seq2seq/Helper>`. This \\\n          provides a superset of decoding strategies than above, for example:\n\n            - :tf_main:`TrainingHelper\n              <contrib/seq2seq/TrainingHelper>` corresponding to the \\\n              :attr:`\"train_argmax\"` strategy.\n            - :tf_main:`ScheduledEmbeddingTrainingHelper\n              <contrib/seq2seq/ScheduledEmbeddingTrainingHelper>` and \\\n              :tf_main:`ScheduledOutputTrainingHelper\n              <contrib/seq2seq/ScheduledOutputTrainingHelper>` for scheduled \\\n              sampling.\n            - :class:`~texar.modules.SoftmaxEmbeddingHelper` and \\\n              :class:`~texar.modules.GumbelSoftmaxEmbeddingHelper` for \\\n              soft decoding and gradient backpropagation.\n\n          This means gives the maximal flexibility of configuring the decoding\\\n          strategy.\n\n        - :attr:`hparams[\"helper_train\"]` and :attr:`hparams[\"helper_infer\"]`:\\\n          Specifying the helper through hyperparameters. Train and infer \\\n          strategy is toggled based on :attr:`mode`. Appriopriate arguments \\\n          (e.g., :attr:`inputs`, :attr:`start_tokens`, etc) are selected to \\\n          construct the helper. Additional construction arguments can be \\\n          provided either through :attr:`**kwargs`, or through \\\n          :attr:`hparams[\"helper_train/infer\"][\"kwargs\"]`.\n\n          This means is used only when :attr:`decoding_strategy` and \\\n          :attr:`helper` are both `None`.\n\n        Args:\n            initial_state (optional): Initial state of decoding.\n                If `None` (default), zero state is used.\n            max_decoding_length: A int scalar Tensor indicating the maximum\n                allowed number of decoding steps. If `None` (default), either\n                :attr:`hparams[\"max_decoding_length_train\"]` or\n                :attr:`hparams[\"max_decoding_length_infer\"]` is used\n                according to :attr:`mode`.\n            output_time_major (bool): If `True`, outputs are returned as\n                time major tensors. If `False` (default), outputs are returned\n                as batch major tensors.\n            decoding_strategy (str, optional): A string specifying the decoding\n                strategy. Different arguments are required based on the\n                strategy.\n                Ignored if :attr:`helper` is given.\n            inputs (optional): Input tensors. Used when\n                :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n\n                If :attr:`embedding` is `None`, :attr:`inputs` is directly\n                fed to the decoder. E.g., in `\"train_greedy\"` strategy,\n                :attr:`inputs` must be a 3D Tensor of shape\n                `[batch_size, max_time, emb_dim]` (or\n                `[max_time, batch_size, emb_dim]` if :attr:`input_time_major`\n                is `True`).\n\n                If :attr:`embedding` is given, :attr:`inputs` is used as index\n                to look up embeddings to be fed in the decoder. Requirements on\n                :attr:`inputs` depend on :attr:`embedding`.\n                E.g., if :attr:`embedding` is an instance of\n                :class:`~texar.modules.WordEmbedder`,\n                then :attr:`inputs` is usually a 2D int Tensor\n                `[batch_size, max_time]` (or\n                `[max_time, batch_size]` if :attr:`input_time_major`\n                is `True`) containing the token indexes.\n            sequence_length (optional): A 1D int Tensor containing the\n                sequence length of :attr:`inputs`.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            input_time_major (optional): Whether the :attr:`inputs` tensor is\n                time major.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            embedding (optional): A callable that returns embedding vectors\n                of inputs, or the `params` argument of\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`. In the\n                later case, :attr:`inputs` (if used) must be a int Tensor\n                containing the ids to be looked up in :attr:`embedding`.\n                Required when :attr:`decoding_strategy=\"infer_greedy\"`\n                or `\"infer_sample\"`; optional when\n                :attr:`decoding_strategy=\"train_greedy\"`.\n            start_tokens (optional): A int Tensor of shape `[batch_size]`,\n                the start tokens.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            end_token (optional): A int 0D Tensor, the token that marks end\n                of decoding.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            softmax_temperature (optional): A float 0D Tensor, value to divide\n                the logits by before computing the softmax. Larger values\n                (above 1.0) result in more random samples. Must > 0. If `None`,\n                1.0 is used. Used when :attr:`decoding_strategy=\"infer_sample\"`.\n            helper (optional): An instance of\n                :tf_main:`Helper <contrib/seq2seq/Helper>`\n                that defines the decoding strategy. If given,\n                :attr:`decoding_strategy`\n                and helper configs in :attr:`hparams` are ignored.\n            mode (str, optional): A string taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`. If\n                `TRAIN`, training related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_train']`), otherwise,\n                inference related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_infer']`). If\n                `None` (default), `TRAIN` mode is used.\n            **kwargs: Other keyword arguments for constructing helper\n                defined by :attr:`hparams[\"helper_trainn\"]` or\n                :attr:`hparams[\"helper_infer\"]`.\n\n        Returns:\n            `(outputs, final_state, sequence_lengths)`: `outputs` is an object\n            containing the decoder output on all time steps, `final_state` is\n            the cell state of the final time step, `sequence_lengths` is a\n            Tensor of shape `[batch_size]`.\n        \"\"\"\n        # Helper\n        if helper is not None:\n            pass\n        elif decoding_strategy is not None:\n            if decoding_strategy == \"train_greedy\":\n                helper = rnn_decoder_helpers._get_training_helper(\n                    inputs, sequence_length, embedding, input_time_major)\n            elif decoding_strategy == \"infer_greedy\":\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    embedding, start_tokens, end_token)\n            elif decoding_strategy == \"infer_sample\":\n                helper = tf.contrib.seq2seq.SampleEmbeddingHelper(\n                    embedding, start_tokens, end_token, softmax_temperature)\n            else:\n                raise ValueError(\n                    \"Unknown decoding strategy: {}\".format(decoding_strategy))\n        else:\n            if mode is None or mode == tf.estimator.ModeKeys.TRAIN:\n                kwargs_ = copy.copy(self._hparams.helper_train.kwargs.todict())\n                helper_type = self._hparams.helper_train.type\n            elif mode == tf.estimator.ModeKeys.EVAL or \\\n                    mode == tf.estimator.ModeKeys.PREDICT:\n                kwargs_ = copy.copy(self._hparams.helper_infer.kwargs.todict())\n                helper_type = self._hparams.helper_infer.type\n            else:\n                raise ValueError(\"Unknown mode: {}\".format(mode))\n            kwargs_.update({\n                \"inputs\": inputs,\n                \"sequence_length\": sequence_length,\n                \"time_major\": input_time_major,\n                \"embedding\": embedding,\n                \"start_tokens\": start_tokens,\n                \"end_token\": end_token,\n                \"softmax_temperature\": softmax_temperature})\n            kwargs_.update(kwargs)\n            helper = rnn_decoder_helpers.get_helper(helper_type, **kwargs_)\n        self._helper = helper\n\n        # Initial state\n        if initial_state is not None:\n            self._initial_state = initial_state\n        else:\n            self._initial_state = self.zero_state(\n                batch_size=self.batch_size, dtype=tf.float32)\n\n        # Maximum decoding length\n        max_l = max_decoding_length\n        if max_l is None:\n            max_l_train = self._hparams.max_decoding_length_train\n            if max_l_train is None:\n                max_l_train = utils.MAX_SEQ_LENGTH\n            max_l_infer = self._hparams.max_decoding_length_infer\n            if max_l_infer is None:\n                max_l_infer = utils.MAX_SEQ_LENGTH\n            max_l = tf.cond(utils.is_train_mode(mode),\n                            lambda: max_l_train, lambda: max_l_infer)\n\n        # Decode\n        outputs, final_state, sequence_lengths = dynamic_decode(\n            decoder=self, maximum_iterations=max_l,\n            output_time_major=output_time_major)\n\n        if not self._built:\n            self._add_internal_trainable_variables()\n            # Add trainable variables of `self._cell` which may be\n            # constructed externally.\n            self._add_trainable_variable(\n                layers.get_rnn_cell_trainable_variables(self._cell))\n            if isinstance(self._output_layer, tf.layers.Layer):\n                self._add_trainable_variable(\n                    self._output_layer.trainable_variables)\n            self._built = True\n\n        return outputs, final_state, sequence_lengths",
            "file_path": "commits/f86ceee1b4a5cfa7ddc728eabcffc6327e853af3/After/texar#modules#decoders#rnn_decoder_base.py"
        },
        "original_variable_name": "max_decoding_length_infer",
        "new_variable_name": "max_l_train",
        "label": "positive",
        "id": "8067984e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 15018
    },
    {
        "commit_hash": "377989c11903f69f042fee717ce6be66bd6eb43a",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def dice(prediction, ground_truth, weight_map=None):\n    \"\"\"\n    Function to calculate the dice loss with the definition given in\n\n        Milletari, F., Navab, N., & Ahmadi, S. A. (2016)\n        V-net: Fully convolutional neural\n        networks for volumetric medical image segmentation. 3DV 2016\n\n    using a square in the denominator\n\n    :param prediction: the logits\n    :param ground_truth: the segmentation ground_truth\n    :param weight_map:\n    :return: the loss\n    \"\"\"\n    ground_truth = tf.to_int64(ground_truth)\n    prediction = tf.cast(prediction, tf.float32)\n    ids = tf.range(tf.to_int64(tf.shape(ground_truth)[0]), dtype=tf.int64)\n    ids = tf.stack([ids, ground_truth], axis=1)\n    one_hot = tf.SparseTensor(\n        indices=ids,\n        values=tf.ones_like(ground_truth, dtype=tf.float32),\n        dense_shape=tf.to_int64(tf.shape(prediction)))\n    if weight_map is not None:\n        n_classes = prediction.shape[1].value\n        weight_map_nclasses = tf.reshape(\n            tf.tile(weight_map, [n_classes]), prediction.get_shape())\n        dice_numerator = 2.0 * tf.sparse_reduce_sum(\n            weight_map_nclasses * one_hot * prediction, reduction_axes=[0])\n        dice_denominator = \\\n            tf.reduce_sum(weight_map_nclasses * tf.square(prediction),\n                          reduction_indices=[0]) + \\\n            tf.sparse_reduce_sum(one_hot * weight_map_nclasses,\n                                 reduction_axes=[0])\n    else:\n        dice_numerator = 2.0 * tf.sparse_reduce_sum(\n            one_hot * prediction, reduction_axes=[0])\n        dice_denominator = \\\n            tf.reduce_sum(tf.square(prediction), reduction_indices=[0]) + \\\n            tf.sparse_reduce_sum(one_hot, reduction_axes=[0])\n    epsilon_denominator = 0.00001\n\n    dice_score = dice_numerator / (dice_denominator + epsilon_denominator)\n    # dice_score.set_shape([n_classes])\n    # minimising (1 - dice_coefficients)\n    return 1.0 - tf.reduce_mean(dice_score)",
            "file_path": "commits/377989c11903f69f042fee717ce6be66bd6eb43a/Before/niftynet#layer#loss_segmentation.py"
        },
        "refactored_code": {
            "source_code": "def generalised_dice_loss(prediction,\n                          ground_truth,\n                          weight_map=None,\n                          type_weight='Square'):\n    \"\"\"\n    Function to calculate the Generalised Dice Loss defined in\n        Sudre, C. et. al. (2017) Generalised Dice overlap as a deep learning\n        loss function for highly unbalanced segmentations. DLMIA 2017\n\n    :param prediction: the logits\n    :param ground_truth: the segmentation ground truth\n    :param weight_map:\n    :param type_weight: type of weighting allowed between labels (choice\n        between Square (square of inverse of volume),\n        Simple (inverse of volume) and Uniform (no weighting))\n    :return: the loss\n    \"\"\"\n    prediction = tf.cast(prediction, tf.float32)\n    one_hot = labels_to_one_hot(ground_truth, tf.shape(prediction))\n    n_classes = prediction.shape[1].value\n\n    if weight_map is not None:\n        weight_map_nclasses = tf.reshape(\n            tf.tile(weight_map, [n_classes]), prediction.get_shape())\n        ref_vol = tf.sparse_reduce_sum(\n            weight_map_nclasses * one_hot, reduction_axes=[0])\n\n        intersect = tf.sparse_reduce_sum(\n            weight_map_nclasses * one_hot * prediction, reduction_axes=[0])\n        seg_vol = tf.reduce_sum(\n            tf.multiply(weight_map_nclasses, prediction), 0)\n    else:\n        ref_vol = tf.sparse_reduce_sum(one_hot, reduction_axes=[0])\n        intersect = tf.sparse_reduce_sum(one_hot * prediction,\n                                         reduction_axes=[0])\n        seg_vol = tf.reduce_sum(prediction, 0)\n    if type_weight == 'Square':\n        weights = tf.reciprocal(tf.square(ref_vol))\n    elif type_weight == 'Simple':\n        weights = tf.reciprocal(ref_vol)\n    elif type_weight == 'Uniform':\n        weights = tf.ones_like(ref_vol)\n    else:\n        raise ValueError(\"The variable type_weight \\\"{}\\\"\"\n                         \"is not defined.\".format(type_weight))\n    new_weights = tf.where(tf.is_inf(weights), tf.zeros_like(weights), weights)\n    weights = tf.where(tf.is_inf(weights), tf.ones_like(weights) *\n                       tf.reduce_max(new_weights), weights)\n    generalised_dice_numerator = \\\n        2 * tf.reduce_sum(tf.multiply(weights, intersect))\n    generalised_dice_denominator = \\\n        tf.reduce_sum(tf.multiply(weights, seg_vol + ref_vol))\n    generalised_dice_score = \\\n        generalised_dice_numerator / generalised_dice_denominator\n    return 1 - generalised_dice_score",
            "file_path": "commits/377989c11903f69f042fee717ce6be66bd6eb43a/After/niftynet#layer#loss_segmentation.py"
        },
        "variable_name": "one_hot",
        "label": "positive",
        "id": "8069bb1a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4939
    },
    {
        "commit_hash": "683c1b13a82e2fa94d369ce275ebf439be943a88",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_image_segmenter(auto_model, tmp_path):\n    image.ImageSegmenter(directory=tmp_path, max_trials=2, seed=utils.SEED)\n    assert auto_model.called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/Before/tests#autokeras#tasks#image_test.py"
        },
        "refactored_code": {
            "source_code": "def test_img_seg_fit_call_auto_model_fit(fit, tmp_path):\n    auto_model = ak.tasks.image.ImageSegmenter(\n        directory=tmp_path, seed=utils.SEED)\n\n    auto_model.fit(\n        x=utils.generate_data(num_instances=100, shape=(32, 32, 3)),\n        y=utils.generate_data(num_instances=100, shape=(32, 32)))\n\n    assert fit.is_called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/After/tests#autokeras#tasks#image_test.py"
        },
        "variable_name": "auto_model",
        "label": "positive",
        "id": "8069bac0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 856
    },
    {
        "commit_hash": "81d24be624d6a0fb05fac14ffac02280ed0b70ad",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_bindcallargs1():\n    out = ((0, 1, 2, 3, 4, 5), {'extra': 'hello'})\n    assert_equal(bindcallargs(F1, 0, 1, d=3, e=4, extra='hello'), out)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/Before/dit#utils#tests#test_bindargs3.py"
        },
        "refactored_code": {
            "source_code": "def test_bindcallargs1():\n    out = bindcallargs(F1, 0, 1, d=3, e=4, extra='hello')\n    out_ = ((0, 1, 2), {'d':3, 'e':4, 'f':5, 'extra': 'hello'})\n    assert_equal(out, out_)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/After/dit#utils#tests#test_bindargs3.py"
        },
        "variable_name": "out",
        "label": "positive",
        "id": "8069b9f8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 679
    },
    {
        "commit_hash": "ef86d2e73e7ce03c4184a04a336d96caf661269a",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _build(self, inputs):\n    \"\"\"Connects the Conv1DTranspose module into the graph.\n\n    If this is not the first time the module has been connected to the graph,\n    the input Tensor provided here must have the same final 2 dimensions, in\n    order for the existing variables to be the correct size for the\n    multiplication. The batch size may differ for each connection.\n\n    Args:\n      inputs: A 3D Tensor of shape `[batch_size, input_length, input_channels]`.\n    Returns:\n      A 3D Tensor of shape `[batch_size, output_length, output_channels]`.\n\n    Raises:\n      ValueError: If connecting the module into the graph any time after the\n        first time and the inferred size of the input does not match previous\n        invocations.\n      base.IncompatibleShapeError: If the input tensor has the wrong number\n          of dimensions.\n      base.IncompatibleShapeError: If the input tensor has an unknown\n          `input_channels`.\n      base.UnderspecifiedError: If the input tensor has unknown `batch_size`.\n      base.IncompatibleShapeError: If `output_shape` is not an integer or\n          iterable of length 1.\n      TypeError: If input Tensor dtype is not tf.float32.\n    \"\"\"\n    # Handle input whose shape is unknown during graph creation.\n    self._input_shape = tuple(inputs.get_shape().as_list())\n\n    if len(self._input_shape) != 3:\n      raise base.IncompatibleShapeError(\n          \"Input Tensor must have shape (batch_size, input_length, \"\n          \"input_channels)\")\n\n    if self._input_shape[2] is None:\n      raise base.UnderspecifiedError(\n          \"Number of input channels must be known at module build time\")\n    input_channels = self._input_shape[2]\n\n    if self._input_shape[0] is None:\n      raise base.UnderspecifiedError(\n          \"Batch size must be known at module build time\")\n    batch_size = self._input_shape[0]\n\n    if self._use_default_output_shape:\n      self._output_shape = (\n          lambda: _default_transpose_size(self._input_shape[1:-1],  # pylint: disable=g-long-lambda\n                                          self.stride[2],\n                                          kernel_shape=self.kernel_shape,\n                                          padding=self.padding))\n\n    if len(self.output_shape) != 1:\n      raise base.IncompatibleShapeError(\n          \"Output shape must be specified as (output_length)\")\n\n    if inputs.dtype != tf.float32:\n      raise TypeError(\"Input must have dtype tf.float32, but dtype was {}\"\n                      .format(inputs.dtype))\n\n    weight_shape = (\n        1,\n        self._kernel_shape[0],\n        self.output_channels,\n        input_channels)\n\n    bias_shape = (self.output_channels,)\n\n    if \"w\" not in self._initializers:\n      fan_in_shape = (weight_shape[1], weight_shape[3])\n      self._initializers[\"w\"] = create_weight_initializer(fan_in_shape)\n\n    if \"b\" not in self._initializers and self._use_bias:\n      self._initializers[\"b\"] = create_bias_initializer(bias_shape)\n\n    self._w = tf.get_variable(\"w\",\n                              shape=weight_shape,\n                              initializer=self._initializers[\"w\"],\n                              partitioner=self._partitioners.get(\"w\", None),\n                              regularizer=self._regularizers.get(\"w\", None))\n\n    tf_out_shape = ((batch_size, 1,) + self._output_shape +\n                    (self.output_channels,))\n\n    # Add an extra dimension to the input - a height of 1.\n    inputs = tf.expand_dims(inputs, 1)\n\n    outputs = tf.nn.conv2d_transpose(inputs,\n                                     self._w,\n                                     tf_out_shape,\n                                     strides=self._stride,\n                                     padding=self._padding)\n\n    if self._use_bias:\n      self._b = tf.get_variable(\"b\",\n                                shape=bias_shape,\n                                initializer=self._initializers[\"b\"],\n                                partitioner=self._partitioners.get(\"b\", None),\n                                regularizer=self._regularizers.get(\"b\", None))\n      outputs += self._b\n\n    # Remove the superfluous height dimension to return a 3D tensor.\n    outputs = tf.squeeze(outputs, [1])\n\n    return outputs",
            "file_path": "commits/ef86d2e73e7ce03c4184a04a336d96caf661269a/Before/sonnet#python#modules#conv.py"
        },
        "refactored_code": {
            "source_code": "def _build(self, inputs):\n    \"\"\"Connects the Conv1DTranspose module into the graph.\n\n    If this is not the first time the module has been connected to the graph,\n    the input Tensor provided here must have the same final 2 dimensions, in\n    order for the existing variables to be the correct size for the\n    multiplication. The batch size may differ for each connection.\n\n    Args:\n      inputs: A 3D Tensor of shape `[batch_size, input_length, input_channels]`.\n    Returns:\n      A 3D Tensor of shape `[batch_size, output_length, output_channels]`.\n\n    Raises:\n      ValueError: If connecting the module into the graph any time after the\n        first time and the inferred size of the input does not match previous\n        invocations.\n      base.IncompatibleShapeError: If the input tensor has the wrong number\n          of dimensions.\n      base.IncompatibleShapeError: If the input tensor has an unknown\n          `input_channels`.\n      base.IncompatibleShapeError: If `output_shape` is not an integer or\n          iterable of length 1.\n      TypeError: If input Tensor dtype is not tf.float32.\n    \"\"\"\n    # Handle input whose shape is unknown during graph creation.\n    self._input_shape = tuple(inputs.get_shape().as_list())\n\n    if len(self._input_shape) != 3:\n      raise base.IncompatibleShapeError(\n          \"Input Tensor must have shape (batch_size, input_length, \"\n          \"input_channels)\")\n\n    if self._input_shape[2] is None:\n      raise base.UnderspecifiedError(\n          \"Number of input channels must be known at module build time\")\n    input_channels = self._input_shape[2]\n\n    if self._use_default_output_shape:\n      self._output_shape = (\n          lambda: _default_transpose_size(self._input_shape[1:-1],  # pylint: disable=g-long-lambda\n                                          self.stride[2],\n                                          kernel_shape=self.kernel_shape,\n                                          padding=self.padding))\n\n    if len(self.output_shape) != 1:\n      raise base.IncompatibleShapeError(\n          \"Output shape must be specified as (output_length)\")\n\n    if inputs.dtype != tf.float32:\n      raise TypeError(\"Input must have dtype tf.float32, but dtype was {}\"\n                      .format(inputs.dtype))\n\n    weight_shape = (\n        1,\n        self._kernel_shape[0],\n        self.output_channels,\n        input_channels)\n\n    bias_shape = (self.output_channels,)\n\n    if \"w\" not in self._initializers:\n      fan_in_shape = (weight_shape[1], weight_shape[3])\n      self._initializers[\"w\"] = create_weight_initializer(fan_in_shape)\n\n    if \"b\" not in self._initializers and self._use_bias:\n      self._initializers[\"b\"] = create_bias_initializer(bias_shape)\n\n    self._w = tf.get_variable(\"w\",\n                              shape=weight_shape,\n                              initializer=self._initializers[\"w\"],\n                              partitioner=self._partitioners.get(\"w\", None),\n                              regularizer=self._regularizers.get(\"w\", None))\n\n    batch_size = tf.expand_dims(tf.shape(inputs)[0], 0)\n    out_shape = (1, self.output_shape[0])\n    out_channels = (self.output_channels,)\n    out_shape_tuple = out_shape + out_channels\n    conv_output_shape = tf.convert_to_tensor(out_shape_tuple)\n    tf_out_shape = tf.concat([batch_size, conv_output_shape], 0)\n\n    # Add an extra dimension to the input - a height of 1.\n    inputs = tf.expand_dims(inputs, 1)\n\n    outputs = tf.nn.conv2d_transpose(inputs,\n                                     self._w,\n                                     tf_out_shape,\n                                     strides=self._stride,\n                                     padding=self._padding)\n\n    if self._use_bias:\n      self._b = tf.get_variable(\"b\",\n                                shape=bias_shape,\n                                initializer=self._initializers[\"b\"],\n                                partitioner=self._partitioners.get(\"b\", None),\n                                regularizer=self._regularizers.get(\"b\", None))\n      outputs += self._b\n\n    # Remove the superfluous height dimension to return a 3D tensor.\n    outputs = tf.squeeze(outputs, [1])\n\n    # Set the tensor sizes in order for shape inference.\n    batch_size_value = inputs.get_shape()[0]\n    output_shape_value = ((batch_size_value,) + self.output_shape +\n                          (self.output_channels,))\n    outputs.set_shape(output_shape_value)\n    return outputs",
            "file_path": "commits/ef86d2e73e7ce03c4184a04a336d96caf661269a/After/sonnet#python#modules#conv.py"
        },
        "original_variable_name": "tf_out_shape",
        "new_variable_name": "output_shape_value",
        "label": "positive",
        "id": "8067918c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 9281
    },
    {
        "commit_hash": "683c1b13a82e2fa94d369ce275ebf439be943a88",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_text_regressor(auto_model, tmp_path):\n    text.TextRegressor(directory=tmp_path, max_trials=2, seed=utils.SEED)\n    assert auto_model.called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/Before/tests#autokeras#tasks#text_test.py"
        },
        "refactored_code": {
            "source_code": "def test_txt_reg_fit_call_auto_model_fit(fit, tmp_path):\n    auto_model = ak.TextRegressor(directory=tmp_path, seed=utils.SEED)\n\n    auto_model.fit(\n        x=np.array(['a b c', 'b b c']),\n        y=np.array([1.0, 2.0]))\n\n    assert fit.is_called",
            "file_path": "commits/683c1b13a82e2fa94d369ce275ebf439be943a88/After/tests#autokeras#tasks#text_test.py"
        },
        "variable_name": "auto_model",
        "label": "positive",
        "id": "8069bade-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 765
    },
    {
        "commit_hash": "1fa0bb3b8a8f1dbf75c24415631011d3e2fcec25",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "maybe_download",
            "container_name": "data_utils",
            "source_code": "def maybe_download(urls, path, extract=False):\n    \"\"\"Downloads a set of files.\n\n    Args:\n        urls: A (list of) urls to download files.\n        path (str): The destination path to save the files.\n        extract (bool): Whether to extract compressed files.\n\n    Returns:\n        A list of paths to the downloaded files.\n    \"\"\"\n    create_dir_if_needed(path)\n\n    if not isinstance(urls, (list, tuple)):\n        urls = [urls]\n    result = []\n    for url in urls:\n        filename = url.split('/')[-1]\n        # If downloading from GitHub, remove suffix ?raw=True\n        # from local filename\n        if filename.endswith(\"?raw=true\"):\n            filename = filename[:-9]\n\n        filepath = os.path.join(path, filename)\n        result.append(filepath)\n\n        if not tf.gfile.Exists(filepath):\n            def _progress(count, block_size, total_size):\n                percent = float(count * block_size) / float(total_size) * 100.\n                # pylint: disable=cell-var-from-loop\n                sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n                                 (filename, percent))\n                sys.stdout.flush()\n            filepath, _ = urllib.request.urlretrieve(url, filepath, _progress)\n            print()\n            statinfo = os.stat(filepath)\n            print('Successfully downloaded {} {} bytes.'.format(\n                filename, statinfo.st_size))\n\n            if extract:\n                tf.logging.info('Extract %s', filepath)\n                if tarfile.is_tarfile(filepath):\n                    tarfile.open(filepath, 'r').extractall(path)\n                elif zipfile.is_zipfile(filepath):\n                    with zipfile.ZipFile(filepath) as zfile:\n                        zfile.extractall(path)\n                else:\n                    tf.logging.info(\"Unknown compression type. Only .tar.gz, \"\n                                    \".tar.bz2, .tar, and .zip are supported\")\n\n    return result"
        },
        "original_method_after_refactoring": {
            "name": "maybe_download",
            "container_name": "data_utils",
            "source_code": "def maybe_download(urls, path, filenames=None, extract=False):\n    \"\"\"Downloads a set of files.\n\n    Args:\n        urls: A (list of) urls to download files.\n        path (str): The destination path to save the files.\n        filenames: A (list of) strings of the file names. If given,\n            must have the same length with :attr:`urls`. If `None`,\n            filenames are extracted from :attr:`urls`.\n        extract (bool): Whether to extract compressed files.\n\n    Returns:\n        A list of paths to the downloaded files.\n    \"\"\"\n    create_dir_if_needed(path)\n\n    if not isinstance(urls, (list, tuple)):\n        urls = [urls]\n    if filenames is not None:\n        if not isinstance(filenames, (list, tuple)):\n            filenames = [filenames]\n        if len(urls) != len(filenames):\n            raise ValueError(\n                '`filenames` must have the same number of elements as `urls`.')\n\n    result = []\n    for i, url in enumerate(urls):\n        if filenames is not None:\n            filename = filenames[i]\n        elif 'drive.google.com' in url:\n            filename = _extract_google_drive_file_id(url)\n        else:\n            filename = url.split('/')[-1]\n            # If downloading from GitHub, remove suffix ?raw=True\n            # from local filename\n            if filename.endswith(\"?raw=true\"):\n                filename = filename[:-9]\n\n        filepath = os.path.join(path, filename)\n        result.append(filepath)\n\n        if not tf.gfile.Exists(filepath):\n            if 'drive.google.com' in url:\n                filepath = _download_from_google_drive(url, filename, path)\n            else:\n                filepath = _download(url, filename, path)\n\n            if extract:\n                tf.logging.info('Extract %s', filepath)\n                if tarfile.is_tarfile(filepath):\n                    tarfile.open(filepath, 'r').extractall(path)\n                elif zipfile.is_zipfile(filepath):\n                    with zipfile.ZipFile(filepath) as zfile:\n                        zfile.extractall(path)\n                else:\n                    tf.logging.info(\"Unknown compression type. Only .tar.gz, \"\n                                    \".tar.bz2, .tar, and .zip are supported\")\n\n    return result"
        },
        "newly_extracted_method": {
            "name": "_download",
            "container_name": "Unknown",
            "source_code": "def _download(url, filename, path):\n    def _progress(count, block_size, total_size):\n        percent = float(count * block_size) / float(total_size) * 100.\n        # pylint: disable=cell-var-from-loop\n        sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n                         (filename, percent))\n        sys.stdout.flush()\n\n    filepath = os.path.join(path, filename)\n    filepath, _ = urllib.request.urlretrieve(url, filepath, _progress)\n    print()\n    statinfo = os.stat(filepath)\n    print('Successfully downloaded {} {} bytes.'.format(\n        filename, statinfo.st_size))\n\n    return filepath"
        },
        "label": "positive",
        "id": "805bfcaa-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5260
    },
    {
        "commit_hash": "73a5213bfbe7c40079102dfebe0cc12ab17135be",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "series",
            "container_name": "conftest",
            "source_code": "def series():\n    \"\"\"Make mocked series as fixture.\"\"\"\n    return _create_series()",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/Before/pandas#tests#window#conftest.py"
        },
        "inlined_method": {
            "name": "_create_series",
            "container_name": "conftest",
            "source_code": "def _create_series():\n    \"\"\"Internal function to mock Series.\"\"\"\n    arr = np.random.randn(100)\n    locs = np.arange(20, 40)\n    arr[locs] = np.NaN\n    series = Series(arr, index=bdate_range(datetime(2009, 1, 1), periods=100))\n    return series",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/Before/pandas#tests#window#conftest.py"
        },
        "caller": {
            "name": "series",
            "container_name": "conftest",
            "source_code": "def series():\n    \"\"\"Make mocked series as fixture.\"\"\"\n    arr = np.random.randn(100)\n    locs = np.arange(20, 40)\n    arr[locs] = np.NaN\n    series = Series(arr, index=bdate_range(datetime(2009, 1, 1), periods=100))\n    return series",
            "file_path": "commits/73a5213bfbe7c40079102dfebe0cc12ab17135be/After/pandas#tests#window#conftest.py"
        },
        "label": "positive",
        "id": "805edb00-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1191
    },
    {
        "commit_hash": "09fe3365beaf43b9d7979399ce10efd086717b24",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "load_all",
            "container_name": "SQLLookupsStore",
            "source_code": "def load_all(self, lookup_collection):\n        lookup_collection.empty()\n        names = self._storage_engine.session.query(Lookup.name).distinct()\n        for name in names:\n            self.load(lookup_collection, name[0])",
            "file_path": "commits/09fe3365beaf43b9d7979399ce10efd086717b24/Before/src#programy#storage#stores#sql#store#lookups.py"
        },
        "inlined_method": {
            "name": "load",
            "container_name": "SQLLookupsStore",
            "source_code": "def load(self, lookup_collection, name):\n        lookup_collection.empty()\n        values = self._storage_engine.session.query(Lookup).filter(Lookup.name==name)\n        for pair in values:\n            key = pair.key.strip('\"')\n            value = pair.value.strip('\"')\n            index, pattern = self.process_key_value(key, value)\n            lookup_collection.add_to_lookup(index,  pattern)",
            "file_path": "commits/09fe3365beaf43b9d7979399ce10efd086717b24/Before/src#programy#storage#stores#sql#store#lookups.py"
        },
        "caller": {
            "name": "load_all",
            "container_name": "SQLLookupsStore",
            "source_code": "def load_all(self, lookup_collection):\n        lookup_collection.empty()\n        db_lookups = self._get_all()\n        for db_lookup in db_lookups:\n            lookup_collection.add_to_lookup(db_lookup.key,  db_lookup.value)",
            "file_path": "commits/09fe3365beaf43b9d7979399ce10efd086717b24/After/src#programy#storage#stores#sql#store#lookups.py"
        },
        "label": "negative",
        "id": "805ede5c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1542
    },
    {
        "commit_hash": "594e504f822a1c8d094ac24f4ef76cb306914e26",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def __early_downsample(y, sr, hop_length, res_type, n_octaves,\n                       nyquist, filter_cutoff):\n    '''Perform early downsampling on an audio signal, if it applies.'''\n\n    if res_type != 'kaiser_fast':\n        return y, sr, hop_length\n\n    downsample_count1 = int(np.ceil(np.log2(audio.BW_FASTEST * nyquist /\n                                            filter_cutoff)) - 1)\n    num_twos = __num_two_factors(hop_length)\n    downsample_count2 = max(0, num_twos - n_octaves + 1)\n    downsample_count = min(downsample_count1, downsample_count2)\n\n    if downsample_count > 0:\n        downsample_factor = 2.0**(downsample_count)\n\n        assert hop_length % downsample_factor == 0\n        hop_length //= downsample_factor\n\n        if len(y) < downsample_factor:\n            raise ParameterError('Input signal length={:d} is too short for '\n                                 '{:d}-octave CQT'.format(len(y), n_octaves))\n\n        # The additional scaling of sqrt(downsample_factor) here is to implicitly\n        # rescale the filters\n        y = np.sqrt(downsample_factor) * audio.resample(y, sr, sr / downsample_factor,\n                                                        res_type=res_type, scale=True)\n\n        sr /= downsample_factor\n\n    return y, sr, hop_length",
            "file_path": "commits/594e504f822a1c8d094ac24f4ef76cb306914e26/Before/librosa#core#constantq.py"
        },
        "refactored_code": {
            "source_code": "def __early_downsample_count(nyquist, filter_cutoff, hop_length, n_octaves):\n    '''Compute the number of early downsampling operations'''\n\n    downsample_count1 = int(np.ceil(np.log2(audio.BW_FASTEST * nyquist /\n                                            filter_cutoff)) - 1)\n    num_twos = __num_two_factors(hop_length)\n    downsample_count2 = max(0, num_twos - n_octaves + 1)\n\n    return min(downsample_count1, downsample_count2)",
            "file_path": "commits/594e504f822a1c8d094ac24f4ef76cb306914e26/After/librosa#core#constantq.py"
        },
        "variable_name": "downsample_count",
        "label": "positive",
        "id": "806ae5d0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2096
    },
    {
        "commit_hash": "edf49b4c7137e902763477f634da90fe038d6364",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "train",
            "container_name": "SklSVM",
            "source_code": "def train(self, training_corpus, feature_set):\n        self.global_feature_set = feature_set\n        self.allowed_features_keys = {fkey for edge in training_corpus.edges() for fkey in edge.features.keys()}\n        self.final_allowed_key_mapping = {}\n        num_feat = 0\n        for allowed_feat_key in self.allowed_features_keys:\n            self.final_allowed_key_mapping[allowed_feat_key] = num_feat\n            num_feat += 1\n\n        X, y = __class__._convert_edges_to_SVC_instances(training_corpus, self.final_allowed_key_mapping, self.preprocess)\n        print_debug(\"Train SVC with #samples {} - #features {} - params: {}\".format(X.shape[0], X.shape[1], str(self.model.get_params())))\n        start = time.time()\n        self.model.fit(X, y)\n        end = time.time()\n        print_debug(\"SVC train, running time: \", (end - start))\n        return self"
        },
        "original_method_after_refactoring": {
            "name": "train",
            "container_name": "SklSVM",
            "source_code": "def train(self, training_corpus, feature_set):\n        self.global_feature_set = feature_set\n        self.allowed_features_keys, self.final_allowed_key_mapping = \\\n            __class__._gen_allowed_and_final_mapping_features_keys(training_corpus)\n\n        X, y = __class__._convert_edges_to_SVC_instances(training_corpus, self.final_allowed_key_mapping, self.preprocess)\n        print_debug(\"Train SVC with #samples {} - #features {} - params: {}\".format(X.shape[0], X.shape[1], str(self.model.get_params())))\n        start = time.time()\n        self.model.fit(X, y)\n        end = time.time()\n        print_debug(\"SVC train, running time: \", (end - start))\n        return self"
        },
        "newly_extracted_method": {
            "name": "_gen_allowed_and_final_mapping_features_keys",
            "container_name": "SklSVM",
            "source_code": "def _gen_allowed_and_final_mapping_features_keys(corpus):\n        allowed_keys = {fkey for edge in corpus.edges() for fkey in edge.features.keys()}\n        final_mapping_keys = {}\n        num_feat = 0\n        for allowed_feat_key in allowed_keys:\n            final_mapping_keys[allowed_feat_key] = num_feat\n            num_feat += 1\n\n        return (allowed_keys, final_mapping_keys)"
        },
        "label": "positive",
        "id": "805befee-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2282
    },
    {
        "commit_hash": "3a230fa1a439a7c6b56099d450faf5702ac5b4ae",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "test_python_version",
            "container_name": "test_client_init",
            "source_code": "def test_python_version():\n\n    server_handle, _ = ray_client_server.init_and_serve(\"localhost:50051\")\n    try:\n        ray = RayAPIStub()\n        info1 = ray.connect(\"localhost:50051\")\n        assert info1[\"python_version\"] == \".\".join(\n            [str(x) for x in list(sys.version_info)[:3]])\n        ray.disconnect()\n        time.sleep(1)\n\n        def mock_connection_response():\n            return ray_client_pb2.ConnectionInfoResponse(\n                num_clients=1,\n                python_version=\"2.7.12\",\n                ray_version=\"\",\n                ray_commit=\"\",\n                protocol_version=CURRENT_PROTOCOL_VERSION,\n            )\n\n        # inject mock connection function\n        server_handle.data_servicer._build_connection_response = \\\n            mock_connection_response\n\n        ray = RayAPIStub()\n        with pytest.raises(RuntimeError):\n            _ = ray.connect(\"localhost:50051\")\n\n        ray = RayAPIStub()\n        info3 = ray.connect(\"localhost:50051\", ignore_version=True)\n        assert info3[\"num_clients\"] == 1, info3\n        ray.disconnect()\n    finally:\n        ray_client_server.shutdown_with_server(server_handle.grpc_server)\n        time.sleep(2)"
        },
        "original_method_after_refactoring": {
            "name": "test_python_version",
            "container_name": "test_client_init",
            "source_code": "def test_python_version(init_and_serve):\n    server_handle = init_and_serve\n    ray = RayAPIStub()\n    info1 = ray.connect(\"localhost:50051\")\n    assert info1[\"python_version\"] == \".\".join(\n        [str(x) for x in list(sys.version_info)[:3]])\n    ray.disconnect()\n    time.sleep(1)\n\n    def mock_connection_response():\n        return ray_client_pb2.ConnectionInfoResponse(\n            num_clients=1,\n            python_version=\"2.7.12\",\n            ray_version=\"\",\n            ray_commit=\"\",\n            protocol_version=CURRENT_PROTOCOL_VERSION,\n        )\n\n    # inject mock connection function\n    server_handle.data_servicer._build_connection_response = \\\n        mock_connection_response\n\n    ray = RayAPIStub()\n    with pytest.raises(RuntimeError):\n        _ = ray.connect(\"localhost:50051\")\n\n    ray = RayAPIStub()\n    info3 = ray.connect(\"localhost:50051\", ignore_version=True)\n    assert info3[\"num_clients\"] == 1, info3\n    ray.disconnect()"
        },
        "newly_extracted_method": {
            "name": "init_and_serve",
            "container_name": "Unknown",
            "source_code": "def init_and_serve():\n    server_handle, _ = ray_client_server.init_and_serve(\"localhost:50051\")\n    yield server_handle\n    ray_client_server.shutdown_with_server(server_handle.grpc_server)\n    time.sleep(2)"
        },
        "label": "positive",
        "id": "805bf57a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2766
    },
    {
        "commit_hash": "ef7dbd2b2ad06fc614570d0943947e24e1334b1b",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def make_query(self):\n        dataset = self.dataset\n        unlabeled_entry_ids, X_pool = zip(*dataset.get_unlabeled_entries())\n\n        while self.budget_used < self.T:\n            # query vector on unlabeled instances \n            p = exp4p.next(self.reward)\n            ask_id = np.random.choice(np.arange(self.K), size=1, p=p)\n\n            self.W.append(1./p[ask_id])\n            self.queried_hist.append(ask_id)\n            if ask_id in unlabeled_entry_ids:\n                self.budget_used += 1\n                return ask_id\n            else:\n                self.calc_reward_fn()",
            "file_path": "commits/ef7dbd2b2ad06fc614570d0943947e24e1334b1b/Before/libact#query_strategies#active_learning_by_learning.py"
        },
        "refactored_code": {
            "source_code": "def make_query(self):\n        dataset = self.dataset\n        unlabeled_entry_ids, X_pool = zip(*dataset.get_unlabeled_entries())\n\n        while self.budget_used < self.T:\n            # query vector on unlabeled instances\n            if self.reward == -1.:\n                p = self.exp4p.next(self.reward, None, None)\n            else:\n                p = self.exp4p.next(\n                        self.reward,\n                        self.queried_hist[-1],\n                        self.dataset.data[self.queried_hist[-1]][1]\n                        )\n            p = p/np.sum(p)\n            ask_idx = np.random.choice(np.arange(self.exp4p.K), size=1, p=p)[0]\n            ask_id = self.unlabeled_entry_ids[ask_idx]\n\n            self.W.append(1./p[ask_idx])\n            self.queried_hist.append(ask_id)\n            if ask_id in unlabeled_entry_ids:\n                self.budget_used += 1\n                return ask_id\n            else:\n                self.calc_reward_fn()",
            "file_path": "commits/ef7dbd2b2ad06fc614570d0943947e24e1334b1b/After/libact#query_strategies#active_learning_by_learning.py"
        },
        "original_variable_name": "ask_id",
        "new_variable_name": "ask_idx",
        "label": "positive",
        "id": "80679baa-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1998
    },
    {
        "commit_hash": "ceb335817a5168c5c78c2887e03fac58087bbf96",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "celer_path",
            "container_name": "homotopy",
            "source_code": "def celer_path(X, y, pb, eps=1e-3, n_alphas=100, alphas=None,\n               coef_init=None, max_iter=20, gap_freq=10, max_epochs=50000,\n               p0=10, verbose=0, verbose_inner=0, tol=1e-6, prune=0,\n               groups=None, return_thetas=False, use_PN=False, X_offset=None,\n               X_scale=None, return_n_iter=False, positive=False):\n    r\"\"\"Compute optimization path with Celer as inner solver.\n\n    With `n = len(y)` the number of samples, the losses are:\n\n    Lasso:\n\n    .. math::\n        \\frac{||y - X w||_2^2}{2 n} + \\alpha ||w||_1\n    Logreg:\n\n    .. math::\n        \\sum_{i=1}^n \\text{log} \\,(1 + e^{-y_i x_i^\\top w}) +\n        \\alpha  ||w||_1\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        Training data. Pass directly as Fortran-contiguous data or column\n        sparse format (CSC) to avoid unnecessary memory duplication.\n\n    y : ndarray, shape (n_samples,)\n        Target values\n\n    pb : \"lasso\" | \"logreg\" | \"grouplasso\"\n        Optimization problem to solve.\n\n    eps : float, optional\n        Length of the path. ``eps=1e-3`` means that\n        ``alpha_min = 1e-3 * alpha_max``\n\n    n_alphas : int, optional\n        Number of alphas along the regularization path\n\n    alphas : ndarray, optional\n        List of alphas where to compute the models.\n        If ``None`` alphas are set automatically\n\n    coef_init : ndarray, shape (n_features,) | None, optional, (defualt=None)\n        Initial value of coefficients. If None, np.zeros(n_features) is used.\n\n    max_iter : int, optional\n        The maximum number of iterations (subproblem definitions)\n\n    gap_freq : int, optional\n        Number of (block) coordinate descent epochs between each duality gap\n        computations.\n\n    max_epochs : int, optional\n        Maximum number of (block) CD epochs on each subproblem.\n\n    p0 : int, optional\n        First working set size.\n\n    verbose : bool or integer, optional\n        Amount of verbosity.\n\n    verbose_inner : bool or integer\n        Amount of verbosity in the inner solver.\n\n    tol : float, optional\n        The tolerance for the optimization: the solver runs until the duality\n        gap is smaller than ``tol`` or the maximum number of iteration is\n        reached.\n\n    prune : 0 | 1, optional\n        Whether or not to use pruning when growing working sets.\n\n    groups : int or list of ints or list of list of ints, optional\n        Used for the group Lasso only. See the documentation of the\n        GroupLasso class.\n\n    return_thetas : bool, optional\n        If True, dual variables along the path are returned.\n\n    use_PN : bool, optional\n        If pb == \"logreg\", use ProxNewton solver instead of coordinate\n        descent.\n\n    X_offset : np.array, shape (n_features,), optional\n        Used to center sparse X without breaking sparsity. Mean of each column.\n        See sklearn.linear_model.base._preprocess_data().\n\n    X_scale : np.array, shape (n_features,), optional\n        Used to scale centered sparse X without breaking sparsity. Norm of each\n        centered column. See sklearn.linear_model.base._preprocess_data().\n\n    return_n_iter : bool, optional\n        If True, number of iterations along the path are returned.\n\n    positive : bool, optional (default=False)\n        If True and pb == \"lasso\", forces the coefficients to be positive.\n\n    Returns\n    -------\n    alphas : array, shape (n_alphas,)\n        The alphas along the path where models are computed.\n\n    coefs : array, shape (n_features, n_alphas)\n        Coefficients along the path.\n\n    dual_gaps : array, shape (n_alphas,)\n        Duality gaps returned by the solver along the path.\n\n    thetas : array, shape (n_alphas, n_samples)\n        The dual variables along the path.\n        (Is returned only when ``return_thetas`` is set to True).\n    \"\"\"\n    if pb.lower() not in (\"lasso\", \"logreg\", \"grouplasso\"):\n        raise ValueError(\"Unsupported problem %s\" % pb)\n    if pb.lower() == \"lasso\":\n        pb = LASSO\n    elif pb.lower() == \"logreg\":\n        pb = LOGREG\n        if set(y) - set([-1.0, 1.0]):\n            raise ValueError(\n                \"y must contain only -1. or 1 values. Got %s \" % (set(y)))\n    elif pb.lower() == \"grouplasso\":\n        pb = GRPLASSO\n        if groups is None:\n            raise ValueError(\n                \"Groups must be specified for the group lasso problem.\")\n        grp_ptr, grp_indices = _grp_converter(groups, X.shape[1])\n        n_groups = len(grp_ptr) - 1\n    else:\n        raise ValueError(\"Unsupported problem: %s\" % pb)\n\n    is_sparse = sparse.issparse(X)\n\n    X = check_array(X, 'csc', dtype=[np.float64, np.float32],\n                    order='F', copy=False)\n    y = check_array(y, 'csc', dtype=X.dtype.type, order='F', copy=False,\n                    ensure_2d=False)\n\n    n_samples, n_features = X.shape\n\n    if X_offset is not None:\n        # As sparse matrices are not actually centered we need this\n        # to be passed to the CD solver.\n        X_sparse_scaling = X_offset / X_scale\n        X_sparse_scaling = np.asarray(X_sparse_scaling, dtype=X.dtype)\n    else:\n        X_sparse_scaling = np.zeros(n_features, dtype=X.dtype)\n\n    if alphas is None:\n        # TODO this is wrong is X_sparse_scaling is used\n        if pb == LASSO:\n            if positive:\n                alpha_max = np.max(X.T.dot(y)) / n_samples\n            else:\n                alpha_max = norm(X.T @ y, ord=np.inf) / n_samples\n        elif pb == LOGREG:\n            alpha_max = norm(X.T @ y, ord=np.inf) / 2.\n        elif pb == GRPLASSO:\n            # TODO compute it with dscal to handle centering sparse\n            alpha_max = 0\n            for g in range(n_groups):\n                X_g = X[:, grp_indices[grp_ptr[g]:grp_ptr[g + 1]]]\n                alpha_max = max(alpha_max, norm(X_g.T @ y, ord=2))\n            alpha_max /= n_samples\n\n        alphas = alpha_max * np.geomspace(1, eps, n_alphas,\n                                          dtype=X.dtype)\n    else:\n        alphas = np.sort(alphas)[::-1]\n\n    n_alphas = len(alphas)\n\n    coefs = np.zeros((n_features, n_alphas), order='F', dtype=X.dtype)\n    thetas = np.zeros((n_alphas, n_samples), dtype=X.dtype)\n    dual_gaps = np.zeros(n_alphas)\n\n    if return_n_iter:\n        n_iters = np.zeros(n_alphas, dtype=int)\n\n    if is_sparse:\n        X_dense = np.empty([1, 1], order='F', dtype=X.data.dtype)\n        X_data = X.data\n        X_indptr = X.indptr\n        X_indices = X.indices\n    else:\n        X_dense = X\n        X_data = np.empty([1], dtype=X.dtype)\n        X_indices = np.empty([1], dtype=np.int32)\n        X_indptr = np.empty([1], dtype=np.int32)\n\n    if pb == GRPLASSO:\n        # TODO this must be included in compute_norm_Xcols when centering\n        norms_X_grp = np.zeros(n_groups, dtype=X_dense.dtype)\n        for g in range(n_groups):\n            X_g = X[:, grp_indices[grp_ptr[g]:grp_ptr[g + 1]]]\n            if is_sparse:\n                gram = (X_g.T @ X_g).todense()\n                # handle centering:\n                for j1 in range(grp_ptr[g], grp_ptr[g + 1]):\n                    for j2 in range(grp_ptr[g], grp_ptr[g + 1]):\n                        gram[j1 - grp_ptr[g], j2 - grp_ptr[g]] += \\\n                            X_sparse_scaling[j1] * \\\n                            X_sparse_scaling[j2] * n_samples - \\\n                            X_sparse_scaling[j1] * \\\n                            X_data[X_indptr[j2]:X_indptr[j2+1]].sum() - \\\n                            X_sparse_scaling[j2] * \\\n                            X_data[X_indptr[j1]:X_indptr[j1+1]].sum()\n\n                norms_X_grp[g] = np.sqrt(norm(gram, ord=2))\n            else:\n                norms_X_grp[g] = norm(X_g, ord=2)\n    else:\n        # TODO harmonize names\n        norms_X_col = np.zeros(n_features, dtype=X_dense.dtype)\n        compute_norms_X_col(\n            is_sparse, norms_X_col, n_samples, X_dense, X_data,\n            X_indices, X_indptr, X_sparse_scaling)\n\n    # do not skip alphas[0], it is not always alpha_max\n    for t in range(n_alphas):\n        alpha = alphas[t]\n        if verbose:\n            to_print = \"##### Computing alpha %d/%d\" % (t + 1, n_alphas)\n            print(\"#\" * len(to_print))\n            print(to_print)\n            print(\"#\" * len(to_print))\n        if t > 0:\n            w = coefs[:, t - 1].copy()\n            theta = thetas[t - 1].copy()\n            p0 = max(len(np.where(w != 0)[0]), 1)\n        else:\n            if coef_init is not None:\n                w = coef_init.copy()\n                p0 = max((w != 0.).sum(), p0)\n                # y - Xw for Lasso, Xw for Logreg:\n                Xw = np.zeros(n_samples, dtype=X.dtype)\n                compute_Xw(\n                    is_sparse, pb, Xw, w, y, X_sparse_scaling.any(), X_dense,\n                    X_data, X_indices, X_indptr, X_sparse_scaling)\n            else:\n                w = np.zeros(n_features, dtype=X.dtype)\n                Xw = np.zeros(n_samples, X.dtype) if pb == LOGREG else y.copy()\n\n            if pb == LASSO:\n                theta = Xw / np.linalg.norm(X.T.dot(Xw), ord=np.inf)\n            elif pb == GRPLASSO:\n                theta = Xw.copy()\n                scal = dscal_grp(\n                    is_sparse, theta, grp_ptr, grp_indices, X_dense,\n                    X_data, X_indices, X_indptr, X_sparse_scaling,\n                    len(grp_ptr) - 1, np.zeros(1, dtype=np.int32),\n                    X_sparse_scaling.any())\n                theta /= scal\n            elif pb == LOGREG:\n                theta = y / (1 + np .exp(y * Xw)) / alpha\n                theta /= np.linalg.norm(X.T @ theta, ord=np.inf)\n        # celer modifies w, Xw, and theta in place:\n        if pb == GRPLASSO:  # TODO this if else scheme is complicated\n            sol = celer_grp(\n                is_sparse, LASSO, X_dense, grp_indices, grp_ptr, X_data,\n                X_indices,\n                X_indptr, X_sparse_scaling, y, alpha, w, Xw, theta,\n                norms_X_grp, tol, max_iter, max_epochs, gap_freq, p0=p0,\n                prune=prune, verbose=verbose)\n            coefs[:, t], thetas[t], dual_gaps[t] = sol[0], sol[1], sol[2][-1]\n        elif pb == LASSO or (pb == LOGREG and not use_PN):\n            sol = celer(\n                is_sparse, pb,\n                X_dense, X_data, X_indices, X_indptr, X_sparse_scaling, y,\n                alpha, w, Xw, theta, norms_X_col,\n                max_iter=max_iter, gap_freq=gap_freq, max_epochs=max_epochs,\n                p0=p0, verbose=verbose, verbose_inner=verbose_inner,\n                use_accel=1, tol=tol, prune=prune, positive=positive)\n        else:  # pb == LOGREG and use_PN\n            sol = newton_celer(\n                is_sparse, X_dense, X_data, X_indices, X_indptr, y, alpha, w,\n                max_iter, verbose, verbose_inner, tol, prune, p0, True, K=6,\n                growth=2, blitz_sc=False)\n\n        coefs[:, t], thetas[t], dual_gaps[t] = sol[0], sol[1], sol[2][-1]\n        if return_n_iter:\n            n_iters[t] = len(sol[2])\n\n        if dual_gaps[t] > tol:\n            warnings.warn(\n                'Objective did not converge. Increasing `tol` may make the' +\n                ' solver faster without affecting the results much. \\n' +\n                'Fitting data with very small alpha causes precision issues.',\n                ConvergenceWarning)\n\n    results = alphas, coefs, dual_gaps\n    if return_thetas:\n        results += (thetas,)\n    if return_n_iter:\n        results += (n_iters,)\n\n    return results"
        },
        "original_method_after_refactoring": {
            "name": "celer_path",
            "container_name": "homotopy",
            "source_code": "def celer_path(X, y, pb, eps=1e-3, n_alphas=100, alphas=None,\n               coef_init=None, max_iter=20, gap_freq=10, max_epochs=50000,\n               p0=10, verbose=0, verbose_inner=0, tol=1e-6, prune=0,\n               groups=None, return_thetas=False, use_PN=False, X_offset=None,\n               X_scale=None, return_n_iter=False, positive=False):\n    r\"\"\"Compute optimization path with Celer as inner solver.\n\n    With `n = len(y)` the number of samples, the losses are:\n\n    Lasso:\n\n    .. math::\n        \\frac{||y - X w||_2^2}{2 n} + \\alpha ||w||_1\n    Logreg:\n\n    .. math::\n        \\sum_{i=1}^n \\text{log} \\,(1 + e^{-y_i x_i^\\top w}) +\n        \\alpha  ||w||_1\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        Training data. Pass directly as Fortran-contiguous data or column\n        sparse format (CSC) to avoid unnecessary memory duplication.\n\n    y : ndarray, shape (n_samples,)\n        Target values\n\n    pb : \"lasso\" | \"logreg\" | \"grouplasso\"\n        Optimization problem to solve.\n\n    eps : float, optional\n        Length of the path. ``eps=1e-3`` means that\n        ``alpha_min = 1e-3 * alpha_max``\n\n    n_alphas : int, optional\n        Number of alphas along the regularization path\n\n    alphas : ndarray, optional\n        List of alphas where to compute the models.\n        If ``None`` alphas are set automatically\n\n    coef_init : ndarray, shape (n_features,) | None, optional, (defualt=None)\n        Initial value of coefficients. If None, np.zeros(n_features) is used.\n\n    max_iter : int, optional\n        The maximum number of iterations (subproblem definitions)\n\n    gap_freq : int, optional\n        Number of (block) coordinate descent epochs between each duality gap\n        computations.\n\n    max_epochs : int, optional\n        Maximum number of (block) CD epochs on each subproblem.\n\n    p0 : int, optional\n        First working set size.\n\n    verbose : bool or integer, optional\n        Amount of verbosity.\n\n    verbose_inner : bool or integer\n        Amount of verbosity in the inner solver.\n\n    tol : float, optional\n        The tolerance for the optimization: the solver runs until the duality\n        gap is smaller than ``tol`` or the maximum number of iteration is\n        reached.\n\n    prune : 0 | 1, optional\n        Whether or not to use pruning when growing working sets.\n\n    groups : int or list of ints or list of list of ints, optional\n        Used for the group Lasso only. See the documentation of the\n        GroupLasso class.\n\n    return_thetas : bool, optional\n        If True, dual variables along the path are returned.\n\n    use_PN : bool, optional\n        If pb == \"logreg\", use ProxNewton solver instead of coordinate\n        descent.\n\n    X_offset : np.array, shape (n_features,), optional\n        Used to center sparse X without breaking sparsity. Mean of each column.\n        See sklearn.linear_model.base._preprocess_data().\n\n    X_scale : np.array, shape (n_features,), optional\n        Used to scale centered sparse X without breaking sparsity. Norm of each\n        centered column. See sklearn.linear_model.base._preprocess_data().\n\n    return_n_iter : bool, optional\n        If True, number of iterations along the path are returned.\n\n    positive : bool, optional (default=False)\n        If True and pb == \"lasso\", forces the coefficients to be positive.\n\n    Returns\n    -------\n    alphas : array, shape (n_alphas,)\n        The alphas along the path where models are computed.\n\n    coefs : array, shape (n_features, n_alphas)\n        Coefficients along the path.\n\n    dual_gaps : array, shape (n_alphas,)\n        Duality gaps returned by the solver along the path.\n\n    thetas : array, shape (n_alphas, n_samples)\n        The dual variables along the path.\n        (Is returned only when ``return_thetas`` is set to True).\n    \"\"\"\n    if pb.lower() not in (\"lasso\", \"logreg\", \"grouplasso\"):\n        raise ValueError(\"Unsupported problem %s\" % pb)\n    if pb.lower() == \"lasso\":\n        pb = LASSO\n    elif pb.lower() == \"logreg\":\n        pb = LOGREG\n        if set(y) - set([-1.0, 1.0]):\n            raise ValueError(\n                \"y must contain only -1. or 1 values. Got %s \" % (set(y)))\n    elif pb.lower() == \"grouplasso\":\n        pb = GRPLASSO\n        if groups is None:\n            raise ValueError(\n                \"Groups must be specified for the group lasso problem.\")\n        grp_ptr, grp_indices = _grp_converter(groups, X.shape[1])\n        n_groups = len(grp_ptr) - 1\n    else:\n        raise ValueError(\"Unsupported problem: %s\" % pb)\n\n    is_sparse = sparse.issparse(X)\n\n    X = check_array(X, 'csc', dtype=[np.float64, np.float32],\n                    order='F', copy=False)\n    y = check_array(y, 'csc', dtype=X.dtype.type, order='F', copy=False,\n                    ensure_2d=False)\n\n    n_samples, n_features = X.shape\n\n    if X_offset is not None:\n        # As sparse matrices are not actually centered we need this\n        # to be passed to the CD solver.\n        X_sparse_scaling = X_offset / X_scale\n        X_sparse_scaling = np.asarray(X_sparse_scaling, dtype=X.dtype)\n    else:\n        X_sparse_scaling = np.zeros(n_features, dtype=X.dtype)\n\n    if alphas is None:\n        # TODO this is wrong is X_sparse_scaling is used\n        if pb == LASSO:\n            if positive:\n                alpha_max = np.max(X.T.dot(y)) / n_samples\n            else:\n                alpha_max = norm(X.T @ y, ord=np.inf) / n_samples\n        elif pb == LOGREG:\n            alpha_max = norm(X.T @ y, ord=np.inf) / 2.\n        elif pb == GRPLASSO:\n            # TODO compute it with dscal to handle centering sparse\n            alpha_max = 0\n            for g in range(n_groups):\n                X_g = X[:, grp_indices[grp_ptr[g]:grp_ptr[g + 1]]]\n                alpha_max = max(alpha_max, norm(X_g.T @ y, ord=2))\n            alpha_max /= n_samples\n\n        alphas = alpha_max * np.geomspace(1, eps, n_alphas,\n                                          dtype=X.dtype)\n    else:\n        alphas = np.sort(alphas)[::-1]\n\n    n_alphas = len(alphas)\n\n    coefs = np.zeros((n_features, n_alphas), order='F', dtype=X.dtype)\n    thetas = np.zeros((n_alphas, n_samples), dtype=X.dtype)\n    dual_gaps = np.zeros(n_alphas)\n\n    if return_n_iter:\n        n_iters = np.zeros(n_alphas, dtype=int)\n\n    X_dense, X_data, X_indices, X_indptr = _sparse_and_dense(X)\n\n    if pb == GRPLASSO:\n        # TODO this must be included in compute_norm_Xcols when centering\n        norms_X_grp = np.zeros(n_groups, dtype=X_dense.dtype)\n        for g in range(n_groups):\n            X_g = X[:, grp_indices[grp_ptr[g]:grp_ptr[g + 1]]]\n            if is_sparse:\n                gram = (X_g.T @ X_g).todense()\n                # handle centering:\n                for j1 in range(grp_ptr[g], grp_ptr[g + 1]):\n                    for j2 in range(grp_ptr[g], grp_ptr[g + 1]):\n                        gram[j1 - grp_ptr[g], j2 - grp_ptr[g]] += \\\n                            X_sparse_scaling[j1] * \\\n                            X_sparse_scaling[j2] * n_samples - \\\n                            X_sparse_scaling[j1] * \\\n                            X_data[X_indptr[j2]:X_indptr[j2+1]].sum() - \\\n                            X_sparse_scaling[j2] * \\\n                            X_data[X_indptr[j1]:X_indptr[j1+1]].sum()\n\n                norms_X_grp[g] = np.sqrt(norm(gram, ord=2))\n            else:\n                norms_X_grp[g] = norm(X_g, ord=2)\n    else:\n        # TODO harmonize names\n        norms_X_col = np.zeros(n_features, dtype=X_dense.dtype)\n        compute_norms_X_col(\n            is_sparse, norms_X_col, n_samples, X_dense, X_data,\n            X_indices, X_indptr, X_sparse_scaling)\n\n    # do not skip alphas[0], it is not always alpha_max\n    for t in range(n_alphas):\n        alpha = alphas[t]\n        if verbose:\n            to_print = \"##### Computing alpha %d/%d\" % (t + 1, n_alphas)\n            print(\"#\" * len(to_print))\n            print(to_print)\n            print(\"#\" * len(to_print))\n        if t > 0:\n            w = coefs[:, t - 1].copy()\n            theta = thetas[t - 1].copy()\n            p0 = max(len(np.where(w != 0)[0]), 1)\n        else:\n            if coef_init is not None:\n                w = coef_init.copy()\n                p0 = max((w != 0.).sum(), p0)\n                # y - Xw for Lasso, Xw for Logreg:\n                Xw = np.zeros(n_samples, dtype=X.dtype)\n                compute_Xw(\n                    is_sparse, pb, Xw, w, y, X_sparse_scaling.any(), X_dense,\n                    X_data, X_indices, X_indptr, X_sparse_scaling)\n            else:\n                w = np.zeros(n_features, dtype=X.dtype)\n                Xw = np.zeros(n_samples, X.dtype) if pb == LOGREG else y.copy()\n\n            if pb == LASSO:\n                theta = Xw / np.linalg.norm(X.T.dot(Xw), ord=np.inf)\n            elif pb == GRPLASSO:\n                theta = Xw.copy()\n                scal = dnorm_grp(\n                    is_sparse, theta, grp_ptr, grp_indices, X_dense,\n                    X_data, X_indices, X_indptr, X_sparse_scaling,\n                    len(grp_ptr) - 1, np.zeros(1, dtype=np.int32),\n                    X_sparse_scaling.any())\n                theta /= scal\n            elif pb == LOGREG:\n                theta = y / (1 + np .exp(y * Xw)) / alpha\n                theta /= np.linalg.norm(X.T @ theta, ord=np.inf)\n        # celer modifies w, Xw, and theta in place:\n        if pb == GRPLASSO:  # TODO this if else scheme is complicated\n            sol = celer_grp(\n                is_sparse, LASSO, X_dense, grp_indices, grp_ptr, X_data,\n                X_indices,\n                X_indptr, X_sparse_scaling, y, alpha, w, Xw, theta,\n                norms_X_grp, tol, max_iter, max_epochs, gap_freq, p0=p0,\n                prune=prune, verbose=verbose)\n        elif pb == LASSO or (pb == LOGREG and not use_PN):\n            sol = celer(\n                is_sparse, pb,\n                X_dense, X_data, X_indices, X_indptr, X_sparse_scaling, y,\n                alpha, w, Xw, theta, norms_X_col,\n                max_iter=max_iter, gap_freq=gap_freq, max_epochs=max_epochs,\n                p0=p0, verbose=verbose, verbose_inner=verbose_inner,\n                use_accel=1, tol=tol, prune=prune, positive=positive)\n        else:  # pb == LOGREG and use_PN\n            sol = newton_celer(\n                is_sparse, X_dense, X_data, X_indices, X_indptr, y, alpha, w,\n                max_iter, verbose, verbose_inner, tol, prune, p0, True, K=6,\n                growth=2, blitz_sc=False)\n\n        coefs[:, t], thetas[t], dual_gaps[t] = sol[0], sol[1], sol[2][-1]\n        if return_n_iter:\n            n_iters[t] = len(sol[2])\n\n        if dual_gaps[t] > tol:\n            warnings.warn(\n                'Objective did not converge. Increasing `tol` may make the' +\n                ' solver faster without affecting the results much. \\n' +\n                'Fitting data with very small alpha causes precision issues.',\n                ConvergenceWarning)\n\n    results = alphas, coefs, dual_gaps\n    if return_thetas:\n        results += (thetas,)\n    if return_n_iter:\n        results += (n_iters,)\n\n    return results"
        },
        "newly_extracted_method": {
            "name": "_sparse_and_dense",
            "container_name": "Unknown",
            "source_code": "def _sparse_and_dense(X):\n    if sparse.issparse(X):\n        X_dense = np.empty([1, 1], order='F', dtype=X.data.dtype)\n        X_data = X.data\n        X_indptr = X.indptr\n        X_indices = X.indices\n    else:\n        X_dense = X\n        X_data = np.empty([1], dtype=X.dtype)\n        X_indices = np.empty([1], dtype=np.int32)\n        X_indptr = np.empty([1], dtype=np.int32)\n    return X_dense, X_data, X_indices, X_indptr"
        },
        "label": "positive",
        "id": "805be8d2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 24004
    },
    {
        "commit_hash": "d0fda7de3677a3ee1b691b00af31a6f5b9d0f363",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version', '-V', action='store_true', help='show version'\n    )\n    parser.add_argument(\n        '--reset-config', action='store_true', help='reset qt config'\n    )\n    parser.add_argument(\n        '--logger-level',\n        default='info',\n        choices=['debug', 'info', 'warning', 'fatal', 'error'],\n        help='logger level',\n    )\n    parser.add_argument('filename', nargs='?', help='image or label filename')\n    parser.add_argument(\n        '--output',\n        '-O',\n        '-o',\n        help='output file or directory (if it ends with .json it is '\n             'recognized as file, else as directory)'\n    )\n    default_config_file = os.path.join(os.path.expanduser('~'), '.labelmerc')\n    parser.add_argument(\n        '--config',\n        dest='config_file',\n        help='config file (default: %s)' % default_config_file,\n        default=default_config_file,\n    )\n    # config for the gui\n    parser.add_argument(\n        '--nodata',\n        dest='store_data',\n        action='store_false',\n        help='stop storing image data to JSON file',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--autosave',\n        dest='auto_save',\n        action='store_true',\n        help='auto save',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--nosortlabels',\n        dest='sort_labels',\n        action='store_false',\n        help='stop sorting labels',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--flags',\n        help='comma separated list of flags OR file containing flags',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--labelflags',\n        dest='label_flags',\n        help='yaml string of label specific flags OR file containing json '\n             'string of label specific flags (ex. {person-\\d+: [male, tall], '\n             'dog-\\d+: [black, brown, white], .*: [occluded]})',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--labels',\n        help='comma separated list of labels OR file containing labels',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--validatelabel',\n        dest='validate_label',\n        choices=['exact', 'instance'],\n        help='label validation types',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--keep-prev',\n        action='store_true',\n        help='keep annotation of previous frame',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--epsilon',\n        type=float,\n        help='epsilon to find nearest vertex on canvas',\n        default=argparse.SUPPRESS,\n    )\n    args = parser.parse_args()\n\n    if args.version:\n        print('{0} {1}'.format(__appname__, __version__))\n        sys.exit(0)\n\n    logger.setLevel(getattr(logging, args.logger_level.upper()))\n\n    if hasattr(args, 'flags'):\n        if os.path.isfile(args.flags):\n            with codecs.open(args.flags, 'r', encoding='utf-8') as f:\n                args.flags = [l.strip() for l in f if l.strip()]\n        else:\n            args.flags = [l for l in args.flags.split(',') if l]\n\n    if hasattr(args, 'labels'):\n        if os.path.isfile(args.labels):\n            with codecs.open(args.labels, 'r', encoding='utf-8') as f:\n                args.labels = [l.strip() for l in f if l.strip()]\n        else:\n            args.labels = [l for l in args.labels.split(',') if l]\n\n    if hasattr(args, 'label_flags'):\n        if os.path.isfile(args.label_flags):\n            with codecs.open(args.label_flags, 'r', encoding='utf-8') as f:\n                args.label_flags = yaml.safe_load(f)\n        else:\n            args.label_flags = yaml.safe_load(args.label_flags)\n\n    config_from_args = args.__dict__\n    config_from_args.pop('version')\n    reset_config = config_from_args.pop('reset_config')\n    filename = config_from_args.pop('filename')\n    output = config_from_args.pop('output')\n    config_file = config_from_args.pop('config_file')\n    config = get_config(config_from_args, config_file)\n\n    if not config['labels'] and config['validate_label']:\n        logger.error('--labels must be specified with --validatelabel or '\n                     'validate_label: true in the config file '\n                     '(ex. ~/.labelmerc).')\n        sys.exit(1)\n\n    output_file = None\n    output_dir = None\n    if output is not None:\n        if output.endswith('.json'):\n            output_file = output\n        else:\n            output_dir = output\n\n    translator = QtCore.QTranslator()\n    translator.load(\n        QtCore.QLocale.system().name(),\n        osp.dirname(osp.abspath(__file__)) + '/translate'\n    )\n    app = QtWidgets.QApplication(sys.argv)\n    app.setApplicationName(__appname__)\n    app.setWindowIcon(newIcon('icon'))\n    app.installTranslator(translator)\n    win = MainWindow(\n        config=config,\n        filename=filename,\n        output_file=output_file,\n        output_dir=output_dir,\n    )\n\n    if reset_config:\n        logger.info('Resetting Qt config: %s' % win.settings.fileName())\n        win.settings.clear()\n        sys.exit(0)\n\n    win.show()\n    win.raise_()\n    sys.exit(app.exec_())",
            "file_path": "commits/d0fda7de3677a3ee1b691b00af31a6f5b9d0f363/Before/labelme#main.py"
        },
        "refactored_code": {
            "source_code": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version', '-V', action='store_true', help='show version'\n    )\n    parser.add_argument(\n        '--reset-config', action='store_true', help='reset qt config'\n    )\n    parser.add_argument(\n        '--logger-level',\n        default='info',\n        choices=['debug', 'info', 'warning', 'fatal', 'error'],\n        help='logger level',\n    )\n    parser.add_argument('filename', nargs='?', help='image or label filename')\n    parser.add_argument(\n        '--output',\n        '-O',\n        '-o',\n        help='output file or directory (if it ends with .json it is '\n             'recognized as file, else as directory)'\n    )\n    default_config_file = os.path.join(os.path.expanduser('~'), '.labelmerc')\n    parser.add_argument(\n        '--config',\n        dest='config',\n        help='config file or yaml-format string (default: {})'.format(\n            default_config_file\n        ),\n        default=default_config_file,\n    )\n    # config for the gui\n    parser.add_argument(\n        '--nodata',\n        dest='store_data',\n        action='store_false',\n        help='stop storing image data to JSON file',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--autosave',\n        dest='auto_save',\n        action='store_true',\n        help='auto save',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--nosortlabels',\n        dest='sort_labels',\n        action='store_false',\n        help='stop sorting labels',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--flags',\n        help='comma separated list of flags OR file containing flags',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--labelflags',\n        dest='label_flags',\n        help='yaml string of label specific flags OR file containing json '\n             'string of label specific flags (ex. {person-\\d+: [male, tall], '\n             'dog-\\d+: [black, brown, white], .*: [occluded]})',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--labels',\n        help='comma separated list of labels OR file containing labels',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--validatelabel',\n        dest='validate_label',\n        choices=['exact', 'instance'],\n        help='label validation types',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--keep-prev',\n        action='store_true',\n        help='keep annotation of previous frame',\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        '--epsilon',\n        type=float,\n        help='epsilon to find nearest vertex on canvas',\n        default=argparse.SUPPRESS,\n    )\n    args = parser.parse_args()\n\n    if args.version:\n        print('{0} {1}'.format(__appname__, __version__))\n        sys.exit(0)\n\n    logger.setLevel(getattr(logging, args.logger_level.upper()))\n\n    if hasattr(args, 'flags'):\n        if os.path.isfile(args.flags):\n            with codecs.open(args.flags, 'r', encoding='utf-8') as f:\n                args.flags = [l.strip() for l in f if l.strip()]\n        else:\n            args.flags = [l for l in args.flags.split(',') if l]\n\n    if hasattr(args, 'labels'):\n        if os.path.isfile(args.labels):\n            with codecs.open(args.labels, 'r', encoding='utf-8') as f:\n                args.labels = [l.strip() for l in f if l.strip()]\n        else:\n            args.labels = [l for l in args.labels.split(',') if l]\n\n    if hasattr(args, 'label_flags'):\n        if os.path.isfile(args.label_flags):\n            with codecs.open(args.label_flags, 'r', encoding='utf-8') as f:\n                args.label_flags = yaml.safe_load(f)\n        else:\n            args.label_flags = yaml.safe_load(args.label_flags)\n\n    config_from_args = args.__dict__\n    config_from_args.pop('version')\n    reset_config = config_from_args.pop('reset_config')\n    filename = config_from_args.pop('filename')\n    output = config_from_args.pop('output')\n    config_file_or_yaml = config_from_args.pop('config')\n    config = yaml.safe_load(config_file_or_yaml)\n    if not isinstance(config, dict):\n        logger.info('Loading config file from: {}'.format(config))\n        with open(config) as f:\n            config = yaml.safe_load(f)\n    config.update(config_from_args)  # prioritize config_from_args\n    config = get_config(config)\n\n    if not config['labels'] and config['validate_label']:\n        logger.error('--labels must be specified with --validatelabel or '\n                     'validate_label: true in the config file '\n                     '(ex. ~/.labelmerc).')\n        sys.exit(1)\n\n    output_file = None\n    output_dir = None\n    if output is not None:\n        if output.endswith('.json'):\n            output_file = output\n        else:\n            output_dir = output\n\n    translator = QtCore.QTranslator()\n    translator.load(\n        QtCore.QLocale.system().name(),\n        osp.dirname(osp.abspath(__file__)) + '/translate'\n    )\n    app = QtWidgets.QApplication(sys.argv)\n    app.setApplicationName(__appname__)\n    app.setWindowIcon(newIcon('icon'))\n    app.installTranslator(translator)\n    win = MainWindow(\n        config=config,\n        filename=filename,\n        output_file=output_file,\n        output_dir=output_dir,\n    )\n\n    if reset_config:\n        logger.info('Resetting Qt config: %s' % win.settings.fileName())\n        win.settings.clear()\n        sys.exit(0)\n\n    win.show()\n    win.raise_()\n    sys.exit(app.exec_())",
            "file_path": "commits/d0fda7de3677a3ee1b691b00af31a6f5b9d0f363/After/labelme#main.py"
        },
        "original_variable_name": "config_file",
        "new_variable_name": "config_file_or_yaml",
        "label": "positive",
        "id": "80679bc8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 11476
    },
    {
        "commit_hash": "be65ce986a45bf2f35b5494db3fa6e993b905aeb",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def DIN(feature_dim_dict, seq_feature_list, embedding_size=8, hist_len_max=16,\n        dnn_use_bn=False, dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40),\n        att_activation=\"dice\", att_weight_normalization=False,\n        l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, init_std=0.0001, seed=1024, task='binary'):\n    \"\"\"Instantiates the Deep Interest Network architecture.\n\n    :param feature_dim_dict: dict,to indicate sparse field (**now only support sparse feature**)like {'sparse':{'field_1':4,'field_2':3,'field_3':2},'dense':[]}\n    :param seq_feature_list: list,to indicate  sequence sparse field (**now only support sparse feature**),must be a subset of ``feature_dim_dict[\"sparse\"]``\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param hist_len_max: positive int, to indicate the max length of seq input\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param dnn_activation: Activation function to use in deep net\n    :param att_hidden_size: list,list of positive integer , the layer number and units in each layer of attention net\n    :param att_activation: Activation function to use in attention net\n    :param att_weight_normalization: bool.Whether normalize the attention score of local activation unit.\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n    check_feature_config_dict(feature_dim_dict)\n\n    sparse_input, dense_input, user_behavior_input = get_input(\n        feature_dim_dict, seq_feature_list, hist_len_max)\n\n    sparse_embedding_dict = {feat.name: Embedding(feat.dimension, embedding_size,\n                                                  embeddings_initializer=RandomNormal(\n                                                      mean=0.0, stddev=init_std, seed=seed),\n                                                  embeddings_regularizer=l2(\n                                                      l2_reg_embedding),\n                                                  name='sparse_emb_' + str(i) + '-' + feat.name,\n                                                  mask_zero=(feat.name in seq_feature_list)) for i, feat in\n                             enumerate(feature_dim_dict[\"sparse\"])}\n\n    query_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_dim_dict['sparse'],\n                                            seq_feature_list, seq_feature_list)\n\n    keys_emb_list = get_embedding_vec_list(sparse_embedding_dict, user_behavior_input, feature_dim_dict['sparse'],\n                                           seq_feature_list, seq_feature_list)\n\n    deep_input_emb_list = get_embedding_vec_list(sparse_embedding_dict, sparse_input, feature_dim_dict['sparse'],\n                                                 mask_feat_list=seq_feature_list)\n\n    keys_emb = concat_fun(keys_emb_list)\n    deep_input_emb = concat_fun(deep_input_emb_list)\n\n    query_emb = concat_fun(query_emb_list)\n\n    hist = AttentionSequencePoolingLayer(att_hidden_size, att_activation,\n                                         weight_normalization=att_weight_normalization, supports_masking=True)([\n        query_emb, keys_emb])\n\n    deep_input_emb = Concatenate()([NoMask()(deep_input_emb), hist])\n    deep_input_emb = Flatten()(deep_input_emb)\n    if len(dense_input) > 0:\n        deep_input_emb = Concatenate()([deep_input_emb] + list(dense_input.values()))\n\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, dnn_use_bn, seed)(deep_input_emb)\n    final_logit = Dense(1, use_bias=False)(output)\n\n    output = PredictionLayer(task)(final_logit)\n    model_input_list = get_inputs_list([sparse_input, dense_input, user_behavior_input])\n\n    model = Model(inputs=model_input_list, outputs=output)\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/Before/deepctr#models#din.py"
        },
        "refactored_code": {
            "source_code": "def DIN(dnn_feature_columns, history_feature_list, embedding_size=8, hist_len_max=16, dnn_use_bn=False,\n        dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40), att_activation=\"dice\",\n        att_weight_normalization=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, init_std=0.0001, seed=1024,\n        task='binary'):\n    \"\"\"Instantiates the Deep Interest Network architecture.\n\n    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n    :param history_feature_list: list,to indicate  sequence sparse field\n    :param embedding_size: positive integer,sparse feature embedding_size.\n    :param hist_len_max: positive int, to indicate the max length of seq input\n    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not in deep net\n    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of deep net\n    :param dnn_activation: Activation function to use in deep net\n    :param att_hidden_size: list,list of positive integer , the layer number and units in each layer of attention net\n    :param att_activation: Activation function to use in attention net\n    :param att_weight_normalization: bool.Whether normalize the attention score of local activation unit.\n    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n    :param init_std: float,to use as the initialize std of embedding vector\n    :param seed: integer ,to use as random seed.\n    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n    :return: A Keras model instance.\n\n    \"\"\"\n\n\n    features = build_input_features(dnn_feature_columns)\n\n    sparse_feature_columns = list(filter(lambda x:isinstance(x,SparseFeat),dnn_feature_columns)) if dnn_feature_columns else []\n    dense_feature_columns = list(\n        filter(lambda x: isinstance(x, DenseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n    varlen_sparse_feature_columns = list(filter(lambda x: isinstance(x, VarLenSparseFeat), dnn_feature_columns)) if dnn_feature_columns else []\n\n\n    history_feature_columns = []\n    sparse_varlen_feature_columns = []\n    history_fc_names = list(map(lambda x: \"hist_\" + x, history_feature_list))\n    for fc in varlen_sparse_feature_columns:\n        feature_name = fc.name\n        if feature_name in history_fc_names:\n            history_feature_columns.append(fc)\n        else:\n            sparse_varlen_feature_columns.append(fc)\n\n\n    inputs_list = list(features.values())\n\n\n    embedding_dict = create_embedding_matrix(dnn_feature_columns,l2_reg_embedding,init_std,seed,embedding_size, prefix=\"\")\n\n\n    query_emb_list = embedding_lookup(embedding_dict,features,sparse_feature_columns,history_feature_list,history_feature_list)#query\u662f\u5355\u72ec\u7684\n    keys_emb_list = embedding_lookup(embedding_dict, features, history_feature_columns, history_fc_names, history_fc_names)\n    dnn_input_emb_list = embedding_lookup(embedding_dict,features,sparse_feature_columns,mask_feat_list=history_feature_list)\n    dense_value_list = get_dense_input(features, dense_feature_columns)\n\n    sequence_embed_dict = varlen_embedding_lookup(embedding_dict,features,sparse_varlen_feature_columns)\n    sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, features, sparse_varlen_feature_columns)\n    dnn_input_emb_list += sequence_embed_list\n\n\n    keys_emb = concat_fun(keys_emb_list)\n    deep_input_emb = concat_fun(dnn_input_emb_list)\n    query_emb = concat_fun(query_emb_list)\n\n    hist = AttentionSequencePoolingLayer(att_hidden_size, att_activation,\n                                         weight_normalization=att_weight_normalization, supports_masking=True)([\n        query_emb, keys_emb])\n\n    deep_input_emb = Concatenate()([NoMask()(deep_input_emb), hist])\n    deep_input_emb = Flatten()(deep_input_emb)\n    dnn_input = combined_dnn_input([deep_input_emb],dense_value_list)\n    output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn,\n                 dnn_dropout, dnn_use_bn, seed)(dnn_input)\n    final_logit = Dense(1, use_bias=False)(output)\n\n    output = PredictionLayer(task)(final_logit)\n\n    model = Model(inputs=inputs_list, outputs=output)\n    return model",
            "file_path": "commits/be65ce986a45bf2f35b5494db3fa6e993b905aeb/After/deepctr#models#din.py"
        },
        "variable_name": "feature_name",
        "label": "negative",
        "id": "8069be08-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 9367
    },
    {
        "commit_hash": "8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "bisect_inbound",
            "container_name": "Bisector",
            "source_code": "def bisect_inbound(self, inbound_revisions=None):\n        launcher = self.prepare_bisect(inbound_revisions)\n        launcher.start()\n\n        verdict = self._get_verdict('inbound', offer_skip=False)\n        info = launcher.get_app_info()\n        launcher.stop()\n        if verdict == 'g':\n            self.last_good_revision = info['application_changeset']\n        elif verdict == 'b':\n            self.first_bad_revision = info['application_changeset']\n        elif verdict == 'r':\n            # do the same thing over again\n            self.bisect_inbound(inbound_revisions=inbound_revisions)\n            return\n        elif verdict == 'e':\n            self._logger.info('Newest known good inbound revision: %s'\n                              % self.last_good_revision)\n            self._logger.info('Oldest known bad inbound revision: %s'\n                              % self.first_bad_revision)\n\n            self._logger.info('To resume, run:')\n            self.print_inbound_resume_info(self.last_good_revision,\n                                           self.first_bad_revision)\n            return\n\n        if len(inbound_revisions) > 1 and verdict in ('g', 'b'):\n            if verdict == 'g':\n                revisions_left = inbound_revisions[mid:]\n            else:\n                revisions_left = inbound_revisions[:mid]\n            revisions_left.ensure_limits()\n            if len(revisions_left) > 0:\n                self.print_inbound_regression_progress(inbound_revisions,\n                                                       revisions_left)\n            self.bisect_inbound(revisions_left)\n        else:\n            # no more inbounds to be bisect, we must build\n            self._logger.info(\"No more inbounds to bisect\")\n            self.print_range()\n            self.offer_build(self.last_good_revision, self.first_bad_revision)",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/Before/mozregression#regression.py"
        },
        "inlined_method": {
            "name": "prepare_bisect",
            "container_name": "Bisector",
            "source_code": "def prepare_bisect(self, inbound_revisions=None):\n        self.found_repo = get_repo_url(inbound_branch=self.fetch_config.inbound_branch)\n\n        if inbound_revisions is None:\n            self._logger.info(\"Getting inbound builds between %s and %s\"\n                              % (self.last_good_revision,\n                                 self.first_bad_revision))\n            # anything within twelve hours is potentially within the range\n            # (should be a tighter but some older builds have wrong timestamps,\n            # see https://bugzilla.mozilla.org/show_bug.cgi?id=1018907 ...\n            # we can change this at some point in the future, after those builds\n            # expire)\n            build_finder = BuildsFinder(self.fetch_config)\n            inbound_revisions = build_finder.get_build_infos(self.last_good_revision,\n                                                             self.first_bad_revision,\n                                                             range=60*60*12)\n\n        mid = inbound_revisions.mid_point()\n        if mid == 0:\n            self._logger.info(\"Oh noes, no (more) inbound revisions :(\")\n            self.print_range()\n            self.offer_build(self.last_good_revision,\n                             self.first_bad_revision)\n            return\n        # hardcode repo to mozilla-central (if we use inbound, we may be\n        # missing some revisions that went into the nightlies which we may\n        # also be comparing against...)\n\n        self._logger.info(\"Testing inbound build with timestamp %s,\"\n                          \" revision %s\"\n                          % (inbound_revisions[mid]['timestamp'],\n                             inbound_revisions[mid]['revision']))\n        build_url = inbound_revisions[mid]['build_url']\n        persist_prefix='%s--%s--' % (inbound_revisions[mid]['timestamp'],\n                                   self.fetch_config.inbound_branch)\n        return create_launcher(self.fetch_config.app_name,\n                                   build_url,\n                                   persist=self.options.persist,\n                                   persist_prefix=persist_prefix)",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/Before/mozregression#regression.py"
        },
        "caller": {
            "name": "bisect_inbound",
            "container_name": "Bisector",
            "source_code": "def bisect_inbound(self, inbound_revisions=None):\n        self.found_repo = get_repo_url(inbound_branch=self.fetch_config.inbound_branch)\n\n        if inbound_revisions is None:\n            self._logger.info(\"Getting inbound builds between %s and %s\"\n                              % (self.last_good_revision,\n                                 self.first_bad_revision))\n            # anything within twelve hours is potentially within the range\n            # (should be a tighter but some older builds have wrong timestamps,\n            # see https://bugzilla.mozilla.org/show_bug.cgi?id=1018907 ...\n            # we can change this at some point in the future, after those builds\n            # expire)\n            build_finder = BuildsFinder(self.fetch_config)\n            inbound_revisions = build_finder.get_build_infos(self.last_good_revision,\n                                                             self.first_bad_revision,\n                                                             range=60*60*12)\n\n        mid = inbound_revisions.mid_point()\n        if mid == 0:\n            self._logger.info(\"Oh noes, no (more) inbound revisions :(\")\n            self.print_range()\n            self.offer_build(self.last_good_revision,\n                             self.first_bad_revision)\n            return\n        # hardcode repo to mozilla-central (if we use inbound, we may be\n        # missing some revisions that went into the nightlies which we may\n        # also be comparing against...)\n\n        self._logger.info(\"Testing inbound build with timestamp %s,\"\n                          \" revision %s\"\n                          % (inbound_revisions[mid]['timestamp'],\n                             inbound_revisions[mid]['revision']))\n        build_url = inbound_revisions[mid]['build_url']\n        persist_prefix='%s--%s--' % (inbound_revisions[mid]['timestamp'],\n                                   self.fetch_config.inbound_branch)\n        launcher = create_launcher(self.fetch_config.app_name,\n                                   build_url,\n                                   persist=self.options.persist,\n                                   persist_prefix=persist_prefix)\n\n        launcher.start()\n\n        verdict = self._get_verdict('inbound', offer_skip=False)\n        info = launcher.get_app_info()\n        launcher.stop()\n        if verdict == 'g':\n            self.last_good_revision = info['application_changeset']\n        elif verdict == 'b':\n            self.first_bad_revision = info['application_changeset']\n        elif verdict == 'r':\n            # do the same thing over again\n            self.bisect_inbound(inbound_revisions=inbound_revisions)\n            return\n        elif verdict == 'e':\n            self._logger.info('Newest known good inbound revision: %s'\n                              % self.last_good_revision)\n            self._logger.info('Oldest known bad inbound revision: %s'\n                              % self.first_bad_revision)\n\n            self._logger.info('To resume, run:')\n            self.print_inbound_resume_info(self.last_good_revision,\n                                           self.first_bad_revision)\n            return\n\n        if len(inbound_revisions) > 1 and verdict in ('g', 'b'):\n            if verdict == 'g':\n                revisions_left = inbound_revisions[mid:]\n            else:\n                revisions_left = inbound_revisions[:mid]\n            revisions_left.ensure_limits()\n            if len(revisions_left) > 0:\n                self.print_inbound_regression_progress(inbound_revisions,\n                                                       revisions_left)\n            self.bisect_inbound(revisions_left)\n        else:\n            # no more inbounds to be bisect, we must build\n            self._logger.info(\"No more inbounds to bisect\")\n            self.print_range()\n            self.offer_build(self.last_good_revision, self.first_bad_revision)",
            "file_path": "commits/8138b2cf8deeaf9bcb94eaa9ab49fb3c8cce7759/After/mozregression#regression.py"
        },
        "label": "positive",
        "id": "805edac4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 8786
    },
    {
        "commit_hash": "9ed3c96c5c0125c73b8a8ea9b1998cbf12a9b34d",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "log_pdf",
            "container_name": "ComplexWatson",
            "source_code": "def log_pdf(x, loc, scale):\n        \"\"\" Calculates logarithm of pdf function.\n\n        Args:\n            x: Assumes shape (..., D).\n            loc: Mode vector. Assumes corresponding shape (..., D).\n            scale: Concentration parameter with shape (...).\n\n        Returns:\n        \"\"\"\n        # For now, we assume that the caller does proper expansion\n        assert x.ndim == loc.ndim\n        assert x.ndim - 1 == scale.ndim\n\n        result = np.einsum('...d,...d', x, loc.conj())\n        result = result.real ** 2 + result.imag ** 2\n        result *= scale\n        result -= ComplexWatson.log_norm(scale, x.shape[-1])\n        return result"
        },
        "original_method_after_refactoring": {
            "name": "log_pdf",
            "container_name": "ComplexWatson",
            "source_code": "def log_pdf(self, x):\n        \"\"\" Calculates logarithm of pdf function.\n\n        Args:\n            x: Assumes shape (..., D).\n            loc: Mode vector. Assumes corresponding shape (..., D).\n            scale: Concentration parameter with shape (...).\n\n        Returns:\n        \"\"\"\n        result = np.einsum(\"...d,...d\", x, self.mode[..., None, :].conj())\n        result = result.real ** 2 + result.imag ** 2\n        result *= self.concentration[..., None]\n        result -= self.log_norm()\n        return result"
        },
        "newly_extracted_method": {
            "name": "_fit",
            "container_name": "ComplexWatsonTrainer",
            "source_code": "def _fit(self, x, saliency) -> ComplexWatson:\n        if self.dimension is None:\n            self.dimension = x.shape[-1]\n        else:\n            assert self.dimension == x.shape[-1], (\n                \"You initialized the trainer with a different dimension than \"\n                \"you are using to fit a model. Use a new trainer, when you \"\n                \"change the dimension.\"\n            )\n\n        if saliency is None:\n            covariance = np.einsum(\n                \"...nd,...nD->...dD\", x, x.conj()\n            )\n            denominator = np.array(x.shape[-2])\n        else:\n            covariance = np.einsum(\n                \"...n,...nd,...nD->...dD\", saliency, x, x.conj()\n            )\n            denominator = np.einsum(\"...n->...\", saliency)[..., None, None]\n\n        covariance /= denominator\n        mode, eigenvalues = get_pca(covariance)\n        concentration = self.hypergeometric_ratio_inverse(eigenvalues)\n        return ComplexWatson(mode=mode, concentration=concentration)"
        },
        "label": "negative",
        "id": "805be5da-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2545
    },
    {
        "commit_hash": "305a0fdd1a0d711d62f9c7d85fd2cbb6166d1418",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "_run_pipeline",
            "container_name": "EMeter",
            "source_code": "def _run_pipeline(self, nodes, **load_kwargs): \n        self._sanity_check_before_processing()\n        pipeline = Pipeline(nodes)\n        pipeline.run(meter=self, **load_kwargs)\n        return pipeline.results",
            "file_path": "commits/305a0fdd1a0d711d62f9c7d85fd2cbb6166d1418/Before/nilmtk#emeter.py"
        },
        "inlined_method": {
            "name": "_sanity_check_before_processing",
            "container_name": "EMeter",
            "source_code": "def _sanity_check_before_processing(self):\n        if self.store is None:\n            msg = (\"'meter.loader' is not set!\"\n                   \" Cannot process data without a loader!\")\n            raise RuntimeError(msg)",
            "file_path": "commits/305a0fdd1a0d711d62f9c7d85fd2cbb6166d1418/Before/nilmtk#emeter.py"
        },
        "caller": {
            "name": "_run_pipeline",
            "container_name": "EMeter",
            "source_code": "def _run_pipeline(self, nodes, **load_kwargs): \n        if self.store is None:\n            msg = (\"'meter.loader' is not set!\"\n                   \" Cannot process data without a loader!\")\n            raise RuntimeError(msg)\n        pipeline = Pipeline(nodes)\n        pipeline.run(meter=self, **load_kwargs)\n        return pipeline.results",
            "file_path": "commits/305a0fdd1a0d711d62f9c7d85fd2cbb6166d1418/After/nilmtk#emeter.py"
        },
        "label": "positive",
        "id": "805edbaa-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1379
    },
    {
        "commit_hash": "b09454afb34000634c8a77050135e3201f6f365d",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def assert_is_detection_dataset(dataset, n_fg_class, repeat=10):\n    \"\"\"Checks if a dataset satisfies detection dataset APIs.\n\n    This function checks if a given dataset satisfies detection dataset APIs\n    or not.\n    If the dataset does not satifiy the APIs, this function raises an\n    :class:`AssertionError`.\n\n    Args:\n        dataset: A dataset to be checked.\n        n_fg_class (int): The number of foreground classes.\n        repeat (int): The number of trials. This function picks\n            an example randomly and checks it. This argmuments determines,\n            how many times this function picks and checks.\n            The default value is :obj:`10`.\n    \"\"\"\n\n    assert len(dataset) > 0, 'The length of dataset must be greater than zero.'\n\n    for _ in six.moves.range(repeat):\n        i = np.random.randint(0, len(dataset))\n        sample = dataset[i]\n\n        assert len(sample) >= 3, \\\n            'Each example must have at least three elements:' \\\n            'img, bbox and label.'\n\n        img, bbox, label = sample[:3]\n\n        assert_is_image(img, color=True)\n        assert_is_bbox(bbox, size=img.shape[1:])\n\n        assert isinstance(label, np.ndarray), \\\n            'label must be a numpy.ndarray.'\n        assert label.dtype == np.int32, \\\n            'The type of label must be numpy.int32.'\n        assert label.shape[1:] == (), \\\n            'The shape of label must be (*,).'\n        assert len(label) == len(bbox), \\\n            'The length of label must be same as that of bbox.'\n        assert label.min() >= 0 and label.max() < n_fg_class, \\\n            'The value of label must be in [0, n_fg_class - 1].'",
            "file_path": "commits/b09454afb34000634c8a77050135e3201f6f365d/Before/chainercv#utils#testing#assertions#assert_is_detection_dataset.py"
        },
        "refactored_code": {
            "source_code": "def assert_is_detection_dataset(dataset, n_fg_class, n_example=None):\n    \"\"\"Checks if a dataset satisfies detection dataset APIs.\n\n    This function checks if a given dataset satisfies detection dataset APIs\n    or not.\n    If the dataset does not satifiy the APIs, this function raises an\n    :class:`AssertionError`.\n\n    Args:\n        dataset: A dataset to be checked.\n        n_fg_class (int): The number of foreground classes.\n        n_example (int): The number of examples to be checked.\n            If this argument is specified, this function picks\n            examples ramdomly and checks them. Otherwise,\n            this function checks all examples.\n\n    \"\"\"\n\n    assert len(dataset) > 0, 'The length of dataset must be greater than zero.'\n\n    if n_example:\n        for _ in six.moves.range(n_example):\n            i = np.random.randint(0, len(dataset))\n            _check_example(dataset[i], n_fg_class)\n    else:\n        for i in six.moves.range(len(dataset)):\n            _check_example(dataset[i], n_fg_class)",
            "file_path": "commits/b09454afb34000634c8a77050135e3201f6f365d/After/chainercv#utils#testing#assertions#assert_is_detection_dataset.py"
        },
        "variable_name": "sample",
        "label": "positive",
        "id": "806ae774-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3186
    },
    {
        "commit_hash": "bbcd9df7e7b55415cee666d891cd7c0d291e433f",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "forward",
            "container_name": "TNet",
            "source_code": "def forward(self, input):\n        flat = input.view(input.size(0), -1)\n        mp = torch.sum(flat, dim=1) / (32. * 32.)\n        sp = torch.std(flat, dim=1) + 1e-7\n        x_features = self.features(\n            (input - mp.unsqueeze(-1).unsqueeze(-1).expand_as(input)) / sp.unsqueeze(-1).unsqueeze(1).expand_as(input))\n        x = x_features.view(x_features.size(0), -1)\n        return L2Norm()(x)"
        },
        "original_method_after_refactoring": {
            "name": "forward",
            "container_name": "HardNet",
            "source_code": "def forward(self, input):\n        x_features = self.features(self.input_norm(input))\n        x = x_features.view(x_features.size(0), -1)\n        return L2Norm()(x)"
        },
        "newly_extracted_method": {
            "name": "input_norm",
            "container_name": "HardNet",
            "source_code": "def input_norm(self,x):\n        flat = x.view(x.size(0), -1)\n        mp = torch.sum(flat, dim=1) / (32. * 32.)\n        sp = torch.std(flat, dim=1) + 1e-7\n        return (x - mp.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand_as(x)) / sp.unsqueeze(-1).unsqueeze(-1).unsqueeze(1).expand_as(x)"
        },
        "label": "positive",
        "id": "805c0326-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1165
    },
    {
        "commit_hash": "3a230fa1a439a7c6b56099d450faf5702ac5b4ae",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def main():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--host\", type=str, default=\"0.0.0.0\", help=\"Host IP to bind to\")\n    parser.add_argument(\n        \"-p\", \"--port\", type=int, default=50051, help=\"Port to bind to\")\n    parser.add_argument(\n        \"--redis-address\",\n        required=False,\n        type=str,\n        help=\"Address to use to connect to Ray\")\n    parser.add_argument(\n        \"--redis-password\",\n        required=False,\n        type=str,\n        help=\"Password for connecting to Redis\")\n    args = parser.parse_args()\n    logging.basicConfig(level=\"INFO\")\n    if args.redis_address:\n        if args.redis_password:\n            ray.init(\n                address=args.redis_address,\n                _redis_password=args.redis_password)\n        else:\n            ray.init(address=args.redis_address)\n    else:\n        ray.init()\n    hostport = \"%s:%d\" % (args.host, args.port)\n    logger.info(f\"Starting Ray Client server on {hostport}\")\n    server = serve(hostport)\n    try:\n        while True:\n            time.sleep(1000)\n    except KeyboardInterrupt:\n        server.stop(0)",
            "file_path": "commits/3a230fa1a439a7c6b56099d450faf5702ac5b4ae/Before/python#ray#util#client#server#server.py"
        },
        "refactored_code": {
            "source_code": "def main():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--host\", type=str, default=\"0.0.0.0\", help=\"Host IP to bind to\")\n    parser.add_argument(\n        \"-p\", \"--port\", type=int, default=50051, help=\"Port to bind to\")\n    parser.add_argument(\n        \"--redis-address\",\n        required=False,\n        type=str,\n        help=\"Address to use to connect to Ray\")\n    parser.add_argument(\n        \"--redis-password\",\n        required=False,\n        type=str,\n        help=\"Password for connecting to Redis\")\n    args = parser.parse_args()\n    logging.basicConfig(level=\"INFO\")\n\n    ray_connect_handler = create_ray_handler(args.redis_address,\n                                             args.redis_password)\n\n    hostport = \"%s:%d\" % (args.host, args.port)\n    logger.info(f\"Starting Ray Client server on {hostport}\")\n    server = serve(hostport, ray_connect_handler)\n    try:\n        while True:\n            time.sleep(1000)\n    except KeyboardInterrupt:\n        server.stop(0)",
            "file_path": "commits/3a230fa1a439a7c6b56099d450faf5702ac5b4ae/After/python#ray#util#client#server#server.py"
        },
        "variable_name": "ray_connect_handler",
        "label": "positive",
        "id": "8069bcfa-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2613
    },
    {
        "commit_hash": "145882bbe3addf859c7ff2ecc36993f6f5506b10",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def projections(pmf, subdivisions, ops=None):\n    \"\"\"\n    Returns the projections on the way to the nearest grid point.\n\n    The original pmf is included in the final output.\n\n    Parameters\n    ----------\n    pmf : NumPy array, shape (n,) or (k, n)\n        The pmf on the ``(n-1)``-simplex. Optionally, provide `k` pmfs.\n    subdivisions : int\n        The number of subdivisions for the interval [0, 1]. The grid considered\n        is such that each component will take on values at the boundaries of\n        the subdivisions. For example, subdivisions corresponds to\n        :math:`[[0, 1/2], [1/2, 1]]` and thus, each component can take the\n        values 0, 1/2, or 1. So one possible pmf would be (1/2, 1/2, 0).\n    method : str\n        The algorithm used to determine what `nearest` means. The default\n        method, 'componentL1', moves each component to its nearest grid\n        value using the L1 norm.\n\n    Other Parameters\n    ----------------\n    ops : list\n        A list of `n-1` callables, where `n` the number of components in the\n        pmf. Each element in the list is a callable the determines how the\n        downsampled pmf's are constructed by specifying which of the lower\n        and upper clamped location indexes should be chosen. If `None`, then\n        `ops` is a list of `np.argmin` and will select the closest grid point.\n\n    Returns\n    -------\n    d : NumPy array, shape (n,n) or (n,k,n)\n        The projections leading to the downsampled pmf.\n\n    See Also\n    --------\n    downsample, dit.simplex_grid\n\n    \"\"\"\n    locs = np.linspace(0, 1, subdivisions + 1)\n\n    out = np.atleast_2d(pmf).transpose().copy()\n    projs = [out.copy()]\n\n    if ops is None:\n        # Take closest point in regional cell.\n        ops = [np.argmin] * (out.shape[0] - 1)\n\n    # Go through each component and move to closest component.\n    for i, op in zip(range(out.shape[0] - 1), ops):\n        _downsample_componentL1(out, i, op, locs)\n        projs.append(out.copy())\n\n    projs = np.asarray(projs)\n    projs = np.swapaxes(projs, 1, 2)\n    if len(pmf.shape) == 1:\n        projs = projs[:,0,:]\n    return projs",
            "file_path": "commits/145882bbe3addf859c7ff2ecc36993f6f5506b10/Before/dit#math#pmfops.py"
        },
        "refactored_code": {
            "source_code": "def projections(pmf, subdivisions, ops=None):\n    \"\"\"\n    Returns the projections on the way to the nearest grid point.\n\n    The original pmf is included in the final output.\n\n    Parameters\n    ----------\n    pmf : NumPy array, shape (n,) or (k, n)\n        The pmf on the ``(n-1)``-simplex. Optionally, provide `k` pmfs.\n    subdivisions : int\n        The number of subdivisions for the interval [0, 1]. The grid considered\n        is such that each component will take on values at the boundaries of\n        the subdivisions. For example, subdivisions corresponds to\n        :math:`[[0, 1/2], [1/2, 1]]` and thus, each component can take the\n        values 0, 1/2, or 1. So one possible pmf would be (1/2, 1/2, 0).\n    method : str\n        The algorithm used to determine what `nearest` means. The default\n        method, 'componentL1', moves each component to its nearest grid\n        value using the L1 norm.\n\n    Other Parameters\n    ----------------\n    ops : list\n        A list of `n-1` callables, where `n` the number of components in the\n        pmf. Each element in the list is a callable the determines how the\n        downsampled pmf's are constructed by specifying which of the lower\n        and upper clamped location indexes should be chosen. If `None`, then\n        `ops` is a list of `np.argmin` and will select the closest grid point.\n\n    Returns\n    -------\n    d : NumPy array, shape (n,n) or (n,k,n)\n        The projections leading to the downsampled pmf.\n\n    See Also\n    --------\n    downsample, dit.simplex_grid\n\n    \"\"\"\n    locs = np.linspace(0, 1, subdivisions + 1)\n\n    out = np.atleast_2d(pmf).transpose().copy()\n    projs = [out.copy()]\n\n    if ops is None:\n        # Take closest point in regional cell.\n        ops = [np.argmin] * (out.shape[0] - 1)\n\n    # Go through each component and move to closest component.\n    for i, op in zip(range(out.shape[0] - 1), ops):\n        locations = _downsample_componentL1(out, i, op, locs)\n        projs.append(out.copy())\n\n    projs = np.asarray(projs)\n    projs = np.swapaxes(projs, 1, 2)\n    if len(pmf.shape) == 1:\n        projs = projs[:,0,:]\n    return projs",
            "file_path": "commits/145882bbe3addf859c7ff2ecc36993f6f5506b10/After/dit#math#pmfops.py"
        },
        "variable_name": "locations",
        "label": "positive",
        "id": "8069bb38-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4710
    },
    {
        "commit_hash": "ef86d2e73e7ce03c4184a04a336d96caf661269a",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _build(self, inputs):\n    \"\"\"Connects the Conv1DTranspose module into the graph.\n\n    If this is not the first time the module has been connected to the graph,\n    the input Tensor provided here must have the same final 2 dimensions, in\n    order for the existing variables to be the correct size for the\n    multiplication. The batch size may differ for each connection.\n\n    Args:\n      inputs: A 3D Tensor of shape `[batch_size, input_length, input_channels]`.\n    Returns:\n      A 3D Tensor of shape `[batch_size, output_length, output_channels]`.\n\n    Raises:\n      ValueError: If connecting the module into the graph any time after the\n        first time and the inferred size of the input does not match previous\n        invocations.\n      base.IncompatibleShapeError: If the input tensor has the wrong number\n          of dimensions.\n      base.IncompatibleShapeError: If the input tensor has an unknown\n          `input_channels`.\n      base.UnderspecifiedError: If the input tensor has unknown `batch_size`.\n      base.IncompatibleShapeError: If `output_shape` is not an integer or\n          iterable of length 1.\n      TypeError: If input Tensor dtype is not tf.float32.\n    \"\"\"\n    # Handle input whose shape is unknown during graph creation.\n    self._input_shape = tuple(inputs.get_shape().as_list())\n\n    if len(self._input_shape) != 3:\n      raise base.IncompatibleShapeError(\n          \"Input Tensor must have shape (batch_size, input_length, \"\n          \"input_channels)\")\n\n    if self._input_shape[2] is None:\n      raise base.UnderspecifiedError(\n          \"Number of input channels must be known at module build time\")\n    input_channels = self._input_shape[2]\n\n    if self._input_shape[0] is None:\n      raise base.UnderspecifiedError(\n          \"Batch size must be known at module build time\")\n    batch_size = self._input_shape[0]\n\n    if self._use_default_output_shape:\n      self._output_shape = (\n          lambda: _default_transpose_size(self._input_shape[1:-1],  # pylint: disable=g-long-lambda\n                                          self.stride[2],\n                                          kernel_shape=self.kernel_shape,\n                                          padding=self.padding))\n\n    if len(self.output_shape) != 1:\n      raise base.IncompatibleShapeError(\n          \"Output shape must be specified as (output_length)\")\n\n    if inputs.dtype != tf.float32:\n      raise TypeError(\"Input must have dtype tf.float32, but dtype was {}\"\n                      .format(inputs.dtype))\n\n    weight_shape = (\n        1,\n        self._kernel_shape[0],\n        self.output_channels,\n        input_channels)\n\n    bias_shape = (self.output_channels,)\n\n    if \"w\" not in self._initializers:\n      fan_in_shape = (weight_shape[1], weight_shape[3])\n      self._initializers[\"w\"] = create_weight_initializer(fan_in_shape)\n\n    if \"b\" not in self._initializers and self._use_bias:\n      self._initializers[\"b\"] = create_bias_initializer(bias_shape)\n\n    self._w = tf.get_variable(\"w\",\n                              shape=weight_shape,\n                              initializer=self._initializers[\"w\"],\n                              partitioner=self._partitioners.get(\"w\", None),\n                              regularizer=self._regularizers.get(\"w\", None))\n\n    tf_out_shape = ((batch_size, 1,) + self._output_shape +\n                    (self.output_channels,))\n\n    # Add an extra dimension to the input - a height of 1.\n    inputs = tf.expand_dims(inputs, 1)\n\n    outputs = tf.nn.conv2d_transpose(inputs,\n                                     self._w,\n                                     tf_out_shape,\n                                     strides=self._stride,\n                                     padding=self._padding)\n\n    if self._use_bias:\n      self._b = tf.get_variable(\"b\",\n                                shape=bias_shape,\n                                initializer=self._initializers[\"b\"],\n                                partitioner=self._partitioners.get(\"b\", None),\n                                regularizer=self._regularizers.get(\"b\", None))\n      outputs += self._b\n\n    # Remove the superfluous height dimension to return a 3D tensor.\n    outputs = tf.squeeze(outputs, [1])\n\n    return outputs",
            "file_path": "commits/ef86d2e73e7ce03c4184a04a336d96caf661269a/Before/sonnet#python#modules#conv.py"
        },
        "refactored_code": {
            "source_code": "def _build(self, inputs):\n    \"\"\"Connects the Conv1DTranspose module into the graph.\n\n    If this is not the first time the module has been connected to the graph,\n    the input Tensor provided here must have the same final 2 dimensions, in\n    order for the existing variables to be the correct size for the\n    multiplication. The batch size may differ for each connection.\n\n    Args:\n      inputs: A 3D Tensor of shape `[batch_size, input_length, input_channels]`.\n    Returns:\n      A 3D Tensor of shape `[batch_size, output_length, output_channels]`.\n\n    Raises:\n      ValueError: If connecting the module into the graph any time after the\n        first time and the inferred size of the input does not match previous\n        invocations.\n      base.IncompatibleShapeError: If the input tensor has the wrong number\n          of dimensions.\n      base.IncompatibleShapeError: If the input tensor has an unknown\n          `input_channels`.\n      base.IncompatibleShapeError: If `output_shape` is not an integer or\n          iterable of length 1.\n      TypeError: If input Tensor dtype is not tf.float32.\n    \"\"\"\n    # Handle input whose shape is unknown during graph creation.\n    self._input_shape = tuple(inputs.get_shape().as_list())\n\n    if len(self._input_shape) != 3:\n      raise base.IncompatibleShapeError(\n          \"Input Tensor must have shape (batch_size, input_length, \"\n          \"input_channels)\")\n\n    if self._input_shape[2] is None:\n      raise base.UnderspecifiedError(\n          \"Number of input channels must be known at module build time\")\n    input_channels = self._input_shape[2]\n\n    if self._use_default_output_shape:\n      self._output_shape = (\n          lambda: _default_transpose_size(self._input_shape[1:-1],  # pylint: disable=g-long-lambda\n                                          self.stride[2],\n                                          kernel_shape=self.kernel_shape,\n                                          padding=self.padding))\n\n    if len(self.output_shape) != 1:\n      raise base.IncompatibleShapeError(\n          \"Output shape must be specified as (output_length)\")\n\n    if inputs.dtype != tf.float32:\n      raise TypeError(\"Input must have dtype tf.float32, but dtype was {}\"\n                      .format(inputs.dtype))\n\n    weight_shape = (\n        1,\n        self._kernel_shape[0],\n        self.output_channels,\n        input_channels)\n\n    bias_shape = (self.output_channels,)\n\n    if \"w\" not in self._initializers:\n      fan_in_shape = (weight_shape[1], weight_shape[3])\n      self._initializers[\"w\"] = create_weight_initializer(fan_in_shape)\n\n    if \"b\" not in self._initializers and self._use_bias:\n      self._initializers[\"b\"] = create_bias_initializer(bias_shape)\n\n    self._w = tf.get_variable(\"w\",\n                              shape=weight_shape,\n                              initializer=self._initializers[\"w\"],\n                              partitioner=self._partitioners.get(\"w\", None),\n                              regularizer=self._regularizers.get(\"w\", None))\n\n    batch_size = tf.expand_dims(tf.shape(inputs)[0], 0)\n    out_shape = (1, self.output_shape[0])\n    out_channels = (self.output_channels,)\n    out_shape_tuple = out_shape + out_channels\n    conv_output_shape = tf.convert_to_tensor(out_shape_tuple)\n    tf_out_shape = tf.concat([batch_size, conv_output_shape], 0)\n\n    # Add an extra dimension to the input - a height of 1.\n    inputs = tf.expand_dims(inputs, 1)\n\n    outputs = tf.nn.conv2d_transpose(inputs,\n                                     self._w,\n                                     tf_out_shape,\n                                     strides=self._stride,\n                                     padding=self._padding)\n\n    if self._use_bias:\n      self._b = tf.get_variable(\"b\",\n                                shape=bias_shape,\n                                initializer=self._initializers[\"b\"],\n                                partitioner=self._partitioners.get(\"b\", None),\n                                regularizer=self._regularizers.get(\"b\", None))\n      outputs += self._b\n\n    # Remove the superfluous height dimension to return a 3D tensor.\n    outputs = tf.squeeze(outputs, [1])\n\n    # Set the tensor sizes in order for shape inference.\n    batch_size_value = inputs.get_shape()[0]\n    output_shape_value = ((batch_size_value,) + self.output_shape +\n                          (self.output_channels,))\n    outputs.set_shape(output_shape_value)\n    return outputs",
            "file_path": "commits/ef86d2e73e7ce03c4184a04a336d96caf661269a/After/sonnet#python#modules#conv.py"
        },
        "original_variable_name": "batch_size",
        "new_variable_name": "batch_size_value",
        "label": "positive",
        "id": "80679182-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 9277
    },
    {
        "commit_hash": "452ba701d7d365c22764cbdf0dca46e0df5b6d8a",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_japanese_handicap_handling(self):\n        final_board = go.load_board('''\n            .........\n            .........\n            ......B..\n            .........\n            ....W....\n            .........\n            ..B...B..\n            .........\n            .........\n        ''')\n        final_position = go.Position(\n            board=final_board,\n            n=2,\n            komi=5.5,\n            caps=(0, 0),\n            groups=go.deduce_groups(final_board),\n            ko=None,\n            last=pc('E5'),\n            last2=pc('G3'),\n            player1turn=False,\n        )\n        sgf = sgf_wrapper.SgfWrapper(JAPANESE_HANDICAP_SGF)\n        positions = list(sgf.get_main_branch())\n        self.assertEqualPositions(final_position, positions[-1])",
            "file_path": "commits/452ba701d7d365c22764cbdf0dca46e0df5b6d8a/Before/tests#test_sgf_wrapper.py"
        },
        "refactored_code": {
            "source_code": "def test_japanese_handicap_handling(self):\n        final_board = go.load_board('''\n            .........\n            .........\n            ......B..\n            .........\n            ....W....\n            .........\n            ..B...B..\n            .........\n            .........\n        ''')\n        final_position = go.Position(\n            board=final_board,\n            n=2,\n            komi=5.5,\n            caps=(0, 0),\n            groups=go.deduce_groups(final_board),\n            ko=None,\n            last=pc('E5'),\n            last2=pc('G3'),\n            player1turn=False,\n        )\n        sgf = sgf_wrapper.SgfWrapper(JAPANESE_HANDICAP_SGF)\n        positions_w_context = list(sgf.get_main_branch())\n        self.assertEqualPositions(final_position, positions_w_context[-1].position)",
            "file_path": "commits/452ba701d7d365c22764cbdf0dca46e0df5b6d8a/After/tests#test_sgf_wrapper.py"
        },
        "original_variable_name": "positions",
        "new_variable_name": "positions_w_context",
        "label": "positive",
        "id": "8067a424-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1971
    },
    {
        "commit_hash": "aee2e5f8e8cbc80632f13261318ef244600db246",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def __call__(self, image, labels=None):\n\n        img_height, img_width = image.shape[:2]\n\n        # Coordinates are expected to be in the 'corners' format.\n        xmin = 1\n        ymin = 2\n        xmax = 3\n        ymax = 4\n\n        counter = -1\n\n        while True: # Keep going until we either find a valid patch or return the original image.\n\n            counter += 1\n\n            p = np.random.uniform(0,1)\n            if p >= (1.0-self.prob):\n\n                # In case we have a bound generator, pick a lower and upper bound for the patch validator.\n                if not ((self.patch_validator is None) or (self.bound_generator is None)):\n                    self.patch_validator.bounds = self.bound_generator()\n\n                print(\"trying bounds:\", self.patch_validator.bounds)\n\n                # Use at most `self.n_trials_max` attempts to find a crop\n                # that meets our requirements.\n                for _ in range(self.n_trials_max):\n\n                    # Determine the size of the sample patch.\n                    patch_height = int(np.random.uniform(self.min_scale, self.max_scale) * img_height)\n                    patch_width = int(np.random.uniform(self.min_scale, self.max_scale) * img_width)\n\n                    # Check if the resulting patch meets the aspect ratio requirements.\n                    aspect_ratio = patch_height / patch_width\n                    if not (self.min_aspect_ratio <= aspect_ratio <= self.max_aspect_ratio):\n                        continue\n\n                    # Compute how much room we have in both dimensions to sample a patch.\n                    # A negative number here means that we want to sample a patch that is larger than the original image\n                    # in the respective dimension, in which case the image will be padded along that dimension.\n                    y_range = img_height - patch_height\n                    x_range = img_width - patch_width\n\n                    # Select a random top left corner for the sample position from the possible positions.\n                    if y_range >= 0: patch_ymin = np.random.randint(0, y_range + 1) # There are y_range + 1 possible positions for the crop in the vertical dimension.\n                    else: patch_ymin = np.random.randint(y_range, 1) # The possible positions for the image on the background canvas in the vertical dimension.\n                    if x_range >= 0: patch_xmin = np.random.randint(0, x_range + 1) # There are x_range + 1 possible positions for the crop in the horizontal dimension.\n                    else: patch_xmin = np.random.randint(x_range, 1) # The possible positions for the image on the background canvas in the horizontal dimension.\n\n                    if labels is None:\n                        # Create a patch sampler object.\n                        sample_patch = CropPad(patch_ymin=patch_ymin,\n                                               patch_xmin=patch_xmin,\n                                               patch_height=patch_height,\n                                               patch_width=patch_width,\n                                               clip_boxes=self.clip_boxes,\n                                               box_filter=self.box_filter)\n                        # Sample the patch.\n                        return sample_patch(image)\n                    else:\n                        if self.patch_validator is None: # We will accept any patch as valid.\n                            # Create a patch sampler object.\n                            sample_patch = CropPad(patch_ymin=patch_ymin,\n                                                   patch_xmin=patch_xmin,\n                                                   patch_height=patch_height,\n                                                   patch_width=patch_width,\n                                                   clip_boxes=self.clip_boxes,\n                                                   box_filter=self.box_filter)\n                            # Sample the patch.\n                            return sample_patch(image, labels)\n                        else:\n                            # Translate the box coordinates to the patch's coordinate system.\n                            new_labels = np.copy(labels)\n                            new_labels[:, [ymin, ymax]] -= patch_ymin\n                            new_labels[:, [xmin, xmax]] -= patch_xmin\n                            # Check if the patch contains the minimum number of boxes we require.\n                            if self.patch_validator(patch_height=patch_height,\n                                                    patch_width=patch_width,\n                                                    labels=new_labels):\n                                print(\"success with rbounds:\", self.patch_validator.bounds)\n                                print(\"counter:\", counter)\n                                print(\"trial number:\", _)\n                                # Create a patch sampler object.\n                                sample_patch = CropPad(patch_ymin=patch_ymin,\n                                                       patch_xmin=patch_xmin,\n                                                       patch_height=patch_height,\n                                                       patch_width=patch_width,\n                                                       clip_boxes=self.clip_boxes,\n                                                       box_filter=self.box_filter)\n                                # Sample the patch.\n                                return sample_patch(image, labels)\n\n            else:\n                print(\"success with original image.\")\n                print(\"counter:\", counter)\n                if labels is None:\n                    return image\n                else:\n                    return image, labels",
            "file_path": "commits/aee2e5f8e8cbc80632f13261318ef244600db246/Before/data_generator#object_detection_2d_patch_sample_ops.py"
        },
        "refactored_code": {
            "source_code": "def __call__(self):\n        '''\n        Returns:\n            A 4-tuple `(ymin, xmin, height, width)` that represents the coordinates\n            of the generated patch.\n        '''\n\n        # Get the patch height and width.\n\n        if self.must_match == 'h_w': # Aspect is the dependent variable.\n            if not self.scale_uniformly:\n                # Get the height.\n                if self.patch_height is None:\n                    patch_height = int(np.random.uniform(self.min_scale, self.max_scale) * self.img_height)\n                else:\n                    patch_height = self.patch_height\n                # Get the width.\n                if self.patch_width is None:\n                    patch_width = int(np.random.uniform(self.min_scale, self.max_scale) * self.img_width)\n                else:\n                    patch_width = self.patch_width\n            else:\n                scaling_factor = np.random.uniform(self.min_scale, self.max_scale)\n                patch_height = int(scaling_factor * self.img_height)\n                patch_width = int(scaling_factor * self.img_width)\n\n        if self.must_match == 'h_ar': # Width is the dependent variable.\n            # Get the height.\n            if self.patch_height is None:\n                patch_height = int(np.random.uniform(self.min_scale, self.max_scale) * self.img_height)\n            else:\n                patch_height = self.patch_height\n            # Get the aspect ratio.\n            if self.patch_aspect_ratio is None:\n                patch_aspect_ratio = np.random.uniform(self.min_aspect_ratio, self.max_aspect_ratio)\n            else:\n                patch_aspect_ratio = self.patch_aspect_ratio\n            # Get the width.\n            patch_width = int(patch_height * patch_aspect_ratio)\n\n        if self.must_match == 'w_ar': # Height is the dependent variable.\n            # Get the width.\n            if self.patch_width is None:\n                patch_width = int(np.random.uniform(self.min_scale, self.max_scale) * self.img_width)\n            else:\n                patch_width = self.patch_width\n            # Get the aspect ratio.\n            if self.patch_aspect_ratio is None:\n                patch_aspect_ratio = np.random.uniform(self.min_aspect_ratio, self.max_aspect_ratio)\n            else:\n                patch_aspect_ratio = self.patch_aspect_ratio\n            # Get the height.\n            patch_height = int(patch_width / patch_aspect_ratio)\n\n        # Get the top left corner coordinates of the patch.\n\n        if self.patch_ymin is None:\n            # Compute how much room we have along the vertical axis to place the patch.\n            # A negative number here means that we want to sample a patch that is larger than the original image\n            # in the vertical dimension, in which case the patch will be placed such that it fully contains the\n            # image in the vertical dimension.\n            y_range = self.img_height - patch_height\n            # Select a random top left corner for the sample position from the possible positions.\n            if y_range >= 0: patch_ymin = np.random.randint(0, y_range + 1) # There are y_range + 1 possible positions for the crop in the vertical dimension.\n            else: patch_ymin = np.random.randint(y_range, 1) # The possible positions for the image on the background canvas in the vertical dimension.\n        else:\n            patch_ymin = self.patch_ymin\n\n        if self.patch_xmin is None:\n            # Compute how much room we have along the horizontal axis to place the patch.\n            # A negative number here means that we want to sample a patch that is larger than the original image\n            # in the horizontal dimension, in which case the patch will be placed such that it fully contains the\n            # image in the horizontal dimension.\n            x_range = self.img_width - patch_width\n            # Select a random top left corner for the sample position from the possible positions.\n            if x_range >= 0: patch_xmin = np.random.randint(0, x_range + 1) # There are x_range + 1 possible positions for the crop in the horizontal dimension.\n            else: patch_xmin = np.random.randint(x_range, 1) # The possible positions for the image on the background canvas in the horizontal dimension.\n        else:\n            patch_xmin = self.patch_xmin\n\n        return (patch_ymin, patch_xmin, patch_height, patch_width)",
            "file_path": "commits/aee2e5f8e8cbc80632f13261318ef244600db246/After/data_generator#object_detection_2d_patch_sample_ops.py"
        },
        "original_variable_name": "patch_width",
        "new_variable_name": "scaling_factor",
        "label": "positive",
        "id": "80679c9a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 10862
    },
    {
        "commit_hash": "41542e4390b3de8beac4222a9e58925e56c872a5",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def _prepare_data(self, x, y, validation_data, validation_split):\n        \"\"\"Convert the data to tf.data.Dataset.\"\"\"\n        # Check validation information.\n        if not validation_data and not validation_split:\n            raise ValueError('Either validation_data or validation_split '\n                             'should be provided.')\n        # TODO: Handle other types of input, zip dataset, tensor, dict.\n        # Prepare the dataset.\n        self._check_data_format(x, y)\n        dataset = self._process_xy(x, y, True)\n        if validation_data:\n            self._split_dataset = False\n            if isinstance(validation_data, tf.data.Dataset):\n                x_val = validation_data\n                y_val = None\n            else:\n                x_val, y_val = validation_data\n            self._check_data_format(x_val, y_val, validation=True)\n            validation_data = self._process_xy(x_val, y_val, False)\n        # Split the data with validation_split.\n        if validation_data is None and validation_split:\n            self._split_dataset = True\n            dataset, validation_data = data_utils.split_dataset(\n                dataset,\n                validation_split)\n        return dataset, validation_data",
            "file_path": "commits/41542e4390b3de8beac4222a9e58925e56c872a5/Before/autokeras#auto_model.py"
        },
        "refactored_code": {
            "source_code": "def _prepare_data(self, x, y, validation_data, validation_split):\n        \"\"\"Convert the data to tf.data.Dataset.\"\"\"\n        # Check validation information.\n        if not validation_data and not validation_split:\n            raise ValueError('Either validation_data or validation_split '\n                             'should be provided.')\n        # TODO: Handle other types of input, zip dataset, tensor, dict.\n        # Prepare the dataset.\n        self._check_data_format(x, y)\n        dataset = self._process_xy(x, y, fit=True)\n        if validation_data:\n            self._split_dataset = False\n            if isinstance(validation_data, tf.data.Dataset):\n                x_val = validation_data\n                y_val = None\n            else:\n                x_val, y_val = validation_data\n            validation_data = self._process_xy(x_val, y_val, validation=True)\n        # Split the data with validation_split.\n        if validation_data is None and validation_split:\n            self._split_dataset = True\n            dataset, validation_data = data_utils.split_dataset(\n                dataset,\n                validation_split)\n        return dataset, validation_data",
            "file_path": "commits/41542e4390b3de8beac4222a9e58925e56c872a5/After/autokeras#auto_model.py"
        },
        "variable_name": "validation_data",
        "label": "negative",
        "id": "8069bdc2-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2816
    },
    {
        "commit_hash": "a90badddc61b7b290fc75c857fa567644a529912",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def bernsen(f, radius, contrast_threshold, gthresh=None):\n    '''\n    thresholded = bernsen(f, radius, contrast_threshold, gthresh={128})\n\n    Bernsen local thresholding\n\n    Parameters\n    ----------\n    f : ndarray\n        input image\n    radius : integer\n        radius of circle (to consider \"local\")\n    contrast_threshold : integer\n        contrast threshold\n    gthresh : numeric, optional\n        global threshold to fall back in low contrast regions\n\n    Returns\n    -------\n    thresholded : binary ndarray\n    '''\n    from mahotas import morph\n    from mahotas.convolve import rank_filter\n    if gthresh is None:\n        gthresh = 128\n    circle = morph.circle_se(radius)\n    fmax = rank_filter(f, circle, circle.sum()-1)\n    fmin = rank_filter(f, circle, 0)\n    fptp = fmax - fmin\n    fmean = fmax/.2 + fmin/.2 # Do not use (fmax + fmin) as that may overflow\n    return np.choose(fptp < contrast_threshold, (fmean < gthresh, fmean > f))",
            "file_path": "commits/a90badddc61b7b290fc75c857fa567644a529912/Before/mahotas#thresholding.py"
        },
        "refactored_code": {
            "source_code": "def bernsen(f, radius, contrast_threshold, gthresh=None):\n    '''\n    thresholded = bernsen(f, radius, contrast_threshold, gthresh={128})\n\n    Bernsen local thresholding\n\n    Parameters\n    ----------\n    f : ndarray\n        input image\n    radius : integer\n        radius of circle (to consider \"local\")\n    contrast_threshold : integer\n        contrast threshold\n    gthresh : numeric, optional\n        global threshold to fall back in low contrast regions\n\n    Returns\n    -------\n    thresholded : binary ndarray\n\n    See Also\n    --------\n    gbernsen : function\n        Generalised Bernsen thresholding\n    '''\n    from mahotas.morph import circle_se\n    if gthresh is None:\n        gthresh = 128\n    return gbernsen(f, circle_se(radius), contrast_threshold, gthresh)",
            "file_path": "commits/a90badddc61b7b290fc75c857fa567644a529912/After/mahotas#thresholding.py"
        },
        "variable_name": "circle",
        "label": "positive",
        "id": "806ae79c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2126
    },
    {
        "commit_hash": "594e504f822a1c8d094ac24f4ef76cb306914e26",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "__early_downsample",
            "container_name": "constantq",
            "source_code": "def __early_downsample(y, sr, hop_length, res_type, n_octaves,\n                       nyquist, filter_cutoff):\n    '''Perform early downsampling on an audio signal, if it applies.'''\n\n    if res_type != 'kaiser_fast':\n        return y, sr, hop_length\n\n    downsample_count1 = int(np.ceil(np.log2(audio.BW_FASTEST * nyquist /\n                                            filter_cutoff)) - 1)\n    num_twos = __num_two_factors(hop_length)\n    downsample_count2 = max(0, num_twos - n_octaves + 1)\n    downsample_count = min(downsample_count1, downsample_count2)\n\n    if downsample_count > 0:\n        downsample_factor = 2.0**(downsample_count)\n\n        assert hop_length % downsample_factor == 0\n        hop_length //= downsample_factor\n\n        if len(y) < downsample_factor:\n            raise ParameterError('Input signal length={:d} is too short for '\n                                 '{:d}-octave CQT'.format(len(y), n_octaves))\n\n        # The additional scaling of sqrt(downsample_factor) here is to implicitly\n        # rescale the filters\n        y = np.sqrt(downsample_factor) * audio.resample(y, sr, sr / downsample_factor,\n                                                        res_type=res_type, scale=True)\n\n        sr /= downsample_factor\n\n    return y, sr, hop_length"
        },
        "original_method_after_refactoring": {
            "name": "__early_downsample",
            "container_name": "constantq",
            "source_code": "def __early_downsample(y, sr, hop_length, res_type, n_octaves,\n                       nyquist, filter_cutoff):\n    '''Perform early downsampling on an audio signal, if it applies.'''\n\n    downsample_count = __early_downsample_count(nyquist, filter_cutoff,\n                                                hop_length, n_octaves)\n\n    if downsample_count > 0 and res_type == 'kaiser_fast':\n        downsample_factor = 2.0**(downsample_count)\n\n        assert hop_length % downsample_factor == 0\n        hop_length //= downsample_factor\n\n        if len(y) < downsample_factor:\n            raise ParameterError('Input signal length={:d} is too short for '\n                                 '{:d}-octave CQT'.format(len(y), n_octaves))\n\n        # The additional scaling of sqrt(downsample_factor) here is to implicitly\n        # rescale the filters\n        y = np.sqrt(downsample_factor) * audio.resample(y, sr, sr / downsample_factor,\n                                                        res_type=res_type, scale=True)\n\n        sr /= downsample_factor\n\n    return y, sr, hop_length"
        },
        "newly_extracted_method": {
            "name": "__early_downsample_count",
            "container_name": "Unknown",
            "source_code": "def __early_downsample_count(nyquist, filter_cutoff, hop_length, n_octaves):\n    '''Compute the number of early downsampling operations'''\n\n    downsample_count1 = int(np.ceil(np.log2(audio.BW_FASTEST * nyquist /\n                                            filter_cutoff)) - 1)\n    num_twos = __num_two_factors(hop_length)\n    downsample_count2 = max(0, num_twos - n_octaves + 1)\n\n    return min(downsample_count1, downsample_count2)"
        },
        "label": "positive",
        "id": "805be9b8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3191
    },
    {
        "commit_hash": "7c4f035497540e3217042201d08693a5ecc12b55",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _resample_bspline(self, inputs, sample_coords):\n\n        in_size = inputs.get_shape().as_list()\n        in_spatial_size = in_size[1:-1]\n        in_spatial_rank = infer_spatial_rank(inputs)\n        batch_size = in_size[0]\n\n        out_spatial_rank = infer_spatial_rank(sample_coords)\n        input_size = tf.reshape(\n            in_spatial_size, [1] * (out_spatial_rank + 1) + [-1])\n        if in_spatial_rank == 2:\n            raise NotImplementedError(\n                'bspline interpolation not implemented for 2d yet')\n        index_voxel_coords = tf.floor(sample_coords)\n        # Compute voxels to use for interpolation\n        grid = tf.meshgrid([-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           indexing='ij')\n        offset_shape = [1, 4 ** in_spatial_rank] + \\\n                       [1] * out_spatial_rank + [in_spatial_rank]\n        offsets = tf.reshape(tf.stack(grid, 3), offset_shape)\n        preboundary_spatial_coords = offsets + \\\n                                     tf.expand_dims(\n                                         tf.cast(index_voxel_coords, tf.int32),\n                                         1)\n        spatial_coords = self.boundary_func(\n            preboundary_spatial_coords, input_size)\n        sz = spatial_coords.get_shape().as_list()\n\n        # Compute weights for each voxel\n        def build_coef(u, d):\n            coeff_list = [tf.pow(1 - u, 3),\n                          3 * tf.pow(u, 3) - 6 * tf.pow(u, 2) + 4,\n                          -3 * tf.pow(u, 3) + 3 * tf.pow(u, 2) + 3 * u + 1,\n                          tf.pow(u, 3)]\n            return tf.concat(coeff_list, d) / 6\n\n        weight = tf.reshape(sample_coords - index_voxel_coords,\n                            [batch_size, -1, 3])\n        coef_shape = [batch_size, 1, 1, 1, -1]\n        Bu = build_coef(tf.reshape(weight[:, :, 0], coef_shape), 1)\n        Bv = build_coef(tf.reshape(weight[:, :, 1], coef_shape), 2)\n        Bw = build_coef(tf.reshape(weight[:, :, 2], coef_shape), 3)\n        all_weights = tf.reshape(Bu * Bv * Bw, [batch_size] + sz[1:-1] + [1])\n        # Gather voxel values and compute weighted sum\n        batch_coords = tf.reshape(\n            tf.range(batch_size), [batch_size] + [1] * (len(sz) - 1))\n        batch_coords = tf.tile(batch_coords, [1] + sz[1:-1] + [1])\n        raw_samples = tf.gather_nd(\n            inputs, tf.concat([batch_coords, spatial_coords], -1))\n        return tf.reduce_sum(all_weights * raw_samples, reduction_indices=1)",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/Before/niftynet#layer#resampler.py"
        },
        "refactored_code": {
            "source_code": "def _resample_bspline(self, inputs, sample_coords):\n        in_size = inputs.get_shape().as_list()\n        batch_size = in_size[0]\n        in_spatial_size = in_size[1:-1]\n        in_spatial_rank = infer_spatial_rank(inputs)\n\n        out_spatial_rank = infer_spatial_rank(sample_coords)\n        if in_spatial_rank == 2:\n            raise NotImplementedError(\n                'bspline interpolation not implemented for 2d yet')\n        floor_coords = tf.floor(sample_coords)\n\n        # Compute voxels to use for interpolation\n        grid = tf.meshgrid([-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           [-1, 0, 1, 2],\n                           indexing='ij')\n        offset_shape = [1, -1] + [1] * out_spatial_rank + [in_spatial_rank]\n        offsets = tf.reshape(tf.stack(grid, 3), offset_shape)\n        spatial_coords = \\\n            offsets + tf.expand_dims(tf.cast(floor_coords, tf.int32), 1)\n        spatial_coords = self.boundary_func(spatial_coords, in_spatial_size)\n        knot_size = spatial_coords.get_shape().as_list()\n\n        # Compute weights for each voxel\n        def build_coef(u, d):\n            coeff_list = [tf.pow(1 - u, 3),\n                          3 * tf.pow(u, 3) - 6 * tf.pow(u, 2) + 4,\n                          -3 * tf.pow(u, 3) + 3 * tf.pow(u, 2) + 3 * u + 1,\n                          tf.pow(u, 3)]\n            return tf.concat(coeff_list, d) / 6\n\n        weight = tf.reshape(sample_coords - floor_coords, [batch_size, -1, 3])\n        coef_shape = [batch_size, 1, 1, 1, -1]\n        Bu = build_coef(tf.reshape(weight[:, :, 0], coef_shape), 1)\n        Bv = build_coef(tf.reshape(weight[:, :, 1], coef_shape), 2)\n        Bw = build_coef(tf.reshape(weight[:, :, 2], coef_shape), 3)\n        all_weights = tf.reshape(Bu * Bv * Bw,\n                                 [batch_size] + knot_size[1:-1] + [1])\n        # Gather voxel values and compute weighted sum\n        batch_coords = tf.reshape(\n            tf.range(batch_size), [batch_size] + [1] * (len(knot_size) - 1))\n        batch_coords = tf.tile(batch_coords, [1] + knot_size[1:-1] + [1])\n        raw_samples = tf.gather_nd(\n            inputs, tf.concat([batch_coords, spatial_coords], -1))\n        return tf.reduce_sum(all_weights * raw_samples, reduction_indices=1)",
            "file_path": "commits/7c4f035497540e3217042201d08693a5ecc12b55/After/niftynet#layer#resampler.py"
        },
        "original_variable_name": "index_voxel_coords",
        "new_variable_name": "floor_coords",
        "label": "positive",
        "id": "80679d26-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5292
    },
    {
        "commit_hash": "a2edf27ded5e9c6fbd06e58dbceb7a5f4101bca0",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "conv_transpose1d",
            "container_name": "modules",
            "source_code": "def conv_transpose1d(in_channels, out_channels, kernel_size, dropout=0,\n                     std_mul=1.0, **kwargs):\n    m = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, **kwargs)\n    std = math.sqrt((std_mul * (1.0 - dropout)) / (m.kernel_size[0] * in_channels))\n    m.weight.data.normal_(mean=0, std=std)\n    m.bias.data.zero_()\n    return nn.utils.weight_norm(m)"
        },
        "original_method_after_refactoring": {
            "name": "conv_transpose1d",
            "container_name": "modules",
            "source_code": "def conv_transpose1d(in_channels, out_channels, kernel_size, dropout=0,\n                     std_mul=1.0, **kwargs):\n    m = nn.ConvTranspose1d(in_channels, out_channels, kernel_size, **kwargs)\n    m = m_modification(m,in_channels,dropout,std_mul)\n    return nn.utils.weight_norm(m)"
        },
        "newly_extracted_method": {
            "name": "m_modification",
            "container_name": "modules",
            "source_code": "def m_modification(m, in_channels, dropout, std_mul):\n    std = math.sqrt((std_mul * (1.0 - dropout)) / (m.kernel_size[0] * in_channels))\n    m.weight.data.normal_(mean=0, std=std)\n    m.bias.data.zero_()\n    return m"
        },
        "label": "positive",
        "id": "805bed1e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1216
    },
    {
        "commit_hash": "66416aa972b335d702089a17c53898497b04992f",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def call(self,\n           inputs: tf.Tensor,\n           training: bool = True,\n           mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n    \"\"\"Calls the document interaction layer to apply cross-document attention.\n\n    Args:\n      inputs: A tensor of shape [batch_size, list_size, feature_dims].\n      training: Whether in training or inference mode.\n      mask: A boolean tensor of shape [batch_size, list_size], which is True for\n        a valid example and False for invalid one. If this is `None`, then all\n        examples are treated as valid.\n\n    Returns:\n      A tensor of shape [batch_size, list_size, head_size].\n    \"\"\"\n    batch_size = tf.shape(inputs)[0]\n    list_size = tf.shape(inputs)[1]\n    if mask is None:\n      mask = tf.ones(shape=(batch_size, list_size), dtype=tf.bool)\n    input_tensor = self._input_projection(inputs, training=training)\n\n    q_mask = tf.cast(mask, dtype=tf.int32)\n    k_mask = q_mask[:, :self._topk] if self._topk else q_mask\n    attention_mask = nlp_modeling_layers.SelfAttentionMask()([q_mask, k_mask])\n\n    for attention_layer, dropout_layer, norm_layer in self._attention_layers:\n      # k_tensor, the keys and values attended over, is truncated when topk is\n      # specified. Note that the output shape is unchanged, as that is\n      # determined by query_tensor.\n      k_tensor = (\n          input_tensor[:, :self._topk, :] if self._topk else input_tensor)\n      output = attention_layer(\n          query=input_tensor,\n          value=k_tensor,\n          attention_mask=attention_mask,\n          training=training)\n      output = dropout_layer(output, training=training)\n      # Applying residual network here, similar to logic in Transformer.\n      input_tensor = norm_layer(output + input_tensor, training=training)\n\n    return input_tensor",
            "file_path": "commits/66416aa972b335d702089a17c53898497b04992f/Before/tensorflow_ranking#python#keras#layers.py"
        },
        "refactored_code": {
            "source_code": "def call(self,\n           inputs: tf.Tensor,\n           training: bool = True,\n           mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n    \"\"\"Calls the document interaction layer to apply cross-document attention.\n\n    Args:\n      inputs: A tensor of shape [batch_size, list_size, feature_dims].\n      training: Whether in training or inference mode.\n      mask: A boolean tensor of shape [batch_size, list_size], which is True for\n        a valid example and False for invalid one. If this is `None`, then all\n        examples are treated as valid.\n\n    Returns:\n      A tensor of shape [batch_size, list_size, head_size].\n    \"\"\"\n    batch_size = tf.shape(inputs)[0]\n    list_size = tf.shape(inputs)[1]\n    if mask is None:\n      mask = tf.ones(shape=(batch_size, list_size), dtype=tf.bool)\n    input_tensor = self._input_projection(inputs, training=training)\n\n    mask = tf.cast(mask, dtype=tf.int32)\n    attention_mask = nlp_modeling_layers.SelfAttentionMask()([mask, mask])\n\n    for attention_layer, dropout_layer, norm_layer in self._attention_layers:\n      output = attention_layer(\n          query=input_tensor,\n          value=input_tensor,\n          attention_mask=attention_mask,\n          training=training)\n      output = dropout_layer(output, training=training)\n      # Applying residual network here, similar to logic in Transformer.\n      input_tensor = norm_layer(output + input_tensor, training=training)\n\n    return input_tensor",
            "file_path": "commits/66416aa972b335d702089a17c53898497b04992f/After/tensorflow_ranking#python#keras#layers.py"
        },
        "original_variable_name": "q_mask",
        "new_variable_name": "mask",
        "label": "positive",
        "id": "80679de4-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3694
    },
    {
        "commit_hash": "81d24be624d6a0fb05fac14ffac02280ed0b70ad",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def test_bindcallargs2():\n    out = ((0, 1, 2), {})\n    assert_equal(bindcallargs(F2, d=0, e=1, f=2), out)\n    out = ((0, 1, 5), {})\n    assert_equal(bindcallargs(F2, d=0, e=1), out)\n    assert_raises(TypeError, bindcallargs, F2, d=0, f=2)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/Before/dit#utils#tests#test_bindargs3.py"
        },
        "refactored_code": {
            "source_code": "def test_bindcallargs2():\n    out = bindcallargs(F2, d=0, e=1, f=2)\n    out_ = ((), {'d':0, 'e':1, 'f':2})\n    assert_equal(out, out_)\n    out = bindcallargs(F2, d=0, e=1)\n    out_ = ((), {'d':0, 'e':1, 'f':5})\n    assert_equal(out, out_)\n    assert_raises(TypeError, bindcallargs, F2, d=0, f=2)",
            "file_path": "commits/81d24be624d6a0fb05fac14ffac02280ed0b70ad/After/dit#utils#tests#test_bindargs3.py"
        },
        "variable_name": "out",
        "label": "positive",
        "id": "8069ba02-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 898
    },
    {
        "commit_hash": "5d943f5a75afaa14a88704230a9cf660d8a54576",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def zerovec(self, x):\n        k = self._k\n        n = self._n\n        if k == 1:\n            return np.zeros(n)\n        return np.zeros(k, n)",
            "file_path": "commits/5d943f5a75afaa14a88704230a9cf660d8a54576/Before/pymanopt#manifolds#strictly_positive_vectors.py"
        },
        "refactored_code": {
            "source_code": "def zerovec(self, x):\n        return np.zeros(self._n, self._k)",
            "file_path": "commits/5d943f5a75afaa14a88704230a9cf660d8a54576/After/pymanopt#manifolds#strictly_positive_vectors.py"
        },
        "variable_name": "k",
        "label": "positive",
        "id": "806ae738-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 587
    },
    {
        "commit_hash": "b14ddcdcfb9c05bd1fdf7adf0eedf0737a97db27",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def precision_recall_score(model, test, train=None, k=10):\n    \"\"\"\n    Compute Precision@k and Recall@k scores. One score\n    is given for every user with interactions in the test\n    set, representing the Precision@k and Recall@k of all their\n    test items.\n\n    Parameters\n    ----------\n\n    model: fitted instance of a recommender model\n        The model to evaluate.\n    test: :class:`spotlight.interactions.Interactions`\n        Test interactions.\n    train: :class:`spotlight.interactions.Interactions`, optional\n        Train interactions. If supplied, scores of known\n        interactions will be set to very low values and so not\n        affect the MRR.\n    k: int or array of int,\n        The maximum number of predicted items\n    Returns\n    -------\n\n    (Precision@k, Recall@k): numpy array of shape (num_users,)\n        A tuple of Precisions@k and Recalls@k for each user in test.\n    \"\"\"\n\n    test = test.tocsr()\n\n    if train is not None:\n        train = train.tocsr()\n\n    if not isinstance(k, list):\n        ks = [k]\n    else:\n        ks = k\n\n    precisions = [list() for _ in range(len(ks))]\n    recalls = [list() for _ in range(len(ks))]\n\n    for user_id, row in enumerate(test):\n\n        if not len(row.indices):\n            continue\n\n        predictions = -model.predict(user_id)\n        predictions = predictions.argsort()\n\n        if train is not None:\n            rated = train[user_id].indices\n        else:\n            rated = []\n\n        predictions = [p for p in predictions if p not in rated]\n\n        targets = row.indices\n\n        for i, _k in enumerate(ks):\n            pred = predictions[:_k]\n            num_hit = len(set(pred).intersection(set(targets)))\n            precisions[i].append(float(num_hit) / len(pred))\n            recalls[i].append(float(num_hit) / len(targets))\n\n    precisions = [np.array(i) for i in precisions]\n    recalls = [np.array(i) for i in recalls]\n\n    if not isinstance(k, list):\n        precisions = precisions[0]\n        recalls = recalls[0]\n\n    return precisions, recalls",
            "file_path": "commits/b14ddcdcfb9c05bd1fdf7adf0eedf0737a97db27/Before/spotlight#evaluation.py"
        },
        "refactored_code": {
            "source_code": "def precision_recall_score(model, test, train=None, k=10):\n    \"\"\"\n    Compute Precision@k and Recall@k scores. One score\n    is given for every user with interactions in the test\n    set, representing the Precision@k and Recall@k of all their\n    test items.\n\n    Parameters\n    ----------\n\n    model: fitted instance of a recommender model\n        The model to evaluate.\n    test: :class:`spotlight.interactions.Interactions`\n        Test interactions.\n    train: :class:`spotlight.interactions.Interactions`, optional\n        Train interactions. If supplied, scores of known\n        interactions will not affect the computed metrics.\n    k: int or array of int,\n        The maximum number of predicted items\n    Returns\n    -------\n\n    (Precision@k, Recall@k): numpy array of shape (num_users, len(k))\n        A tuple of Precisions@k and Recalls@k for each user in test.\n        If k is a scalar, will return a tuple of vectors. If k is an\n        array, will return a tuple of arrays, where each row corresponds\n        to a user and each column corresponds to a value of k.\n    \"\"\"\n\n    test = test.tocsr()\n\n    if train is not None:\n        train = train.tocsr()\n\n    if np.isscalar(k):\n        k = np.array([k])\n\n    precision = []\n    recall = []\n\n    for user_id, row in enumerate(test):\n\n        if not len(row.indices):\n            continue\n\n        predictions = -model.predict(user_id)\n\n        if train is not None:\n            rated = train[user_id].indices\n            predictions[rated] = FLOAT_MAX\n\n        predictions = predictions.argsort()\n\n        targets = row.indices\n\n        user_precision, user_recall = zip(*[\n            _get_precision_recall(predictions, targets, x)\n            for x in k\n        ])\n\n        precision.append(user_precision)\n        recall.append(user_recall)\n\n    precision = np.array(precision).squeeze()\n    recall = np.array(recall).squeeze()\n\n    return precision, recall",
            "file_path": "commits/b14ddcdcfb9c05bd1fdf7adf0eedf0737a97db27/After/spotlight#evaluation.py"
        },
        "original_variable_name": "pred",
        "new_variable_name": "predictions",
        "label": "positive",
        "id": "80679bf0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4443
    },
    {
        "commit_hash": "f940ed909b1bb2b4e869abb9239d4f9b742c84a3",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def test_resid_plots(self):\n        \"\"\"\n        Assert no errors occur during Residual Plots integration\n        \"\"\"\n        model = SVR()\n        X_train, X_test, y_train, y_test = tts(X, y, test_size=0.5, random_state=42)\n        model.fit(X_train, y_train)\n        visualizer = ResidualsPlot(model)\n        visualizer.score(X_test, y_test)\n        visualizer.poof()\n        visualizer.ax.grid(False)\n        self.assert_images_similar(visualizer)",
            "file_path": "commits/f940ed909b1bb2b4e869abb9239d4f9b742c84a3/Before/tests#test_regressor#test_residuals.py"
        },
        "refactored_code": {
            "source_code": "def test_pred_error_integration(self):\n        \"\"\"\n        Integration test with image similarity on random data with SVR\n        \"\"\"\n        _, ax = plt.subplots()\n\n        visualizer = PredictionError(SVR(), ax=ax)\n\n        visualizer.fit(self.data.X.train, self.data.y.train)\n        visualizer.score(self.data.X.test, self.data.y.test)\n        visualizer.finalize()\n\n        self.assert_images_similar(visualizer, tol=10)",
            "file_path": "commits/f940ed909b1bb2b4e869abb9239d4f9b742c84a3/After/tests#test_regressor#test_residuals.py"
        },
        "variable_name": "model",
        "label": "positive",
        "id": "806aeb34-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1260
    },
    {
        "commit_hash": "f86ceee1b4a5cfa7ddc728eabcffc6327e853af3",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _build(self, helper, initial_state=None):\n        \"\"\"Performs decoding.\n\n        Args:\n            helper: An instance of `tf.contrib.seq2seq.Helper` that helps with\n                the decoding process. For example, use an instance of\n                `TrainingHelper` in training phase.\n            initial_state (optional): Initial state of decoding.\n                If `None` (default), zero state is used.\n            mode (optional): A member of\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`.\n                If `None`, :func:`~texar.context.global_mode` is used.\n                Note that if :attr:`cell` is given when constructing the\n                deocoder, the :attr:`mode` here does not have an effect to\n                :attr:`cell`.\n\n        Returns:\n            `(outputs, final_state, sequence_lengths)`: `outputs` is an object\n            containing the decoder output on all time steps, `final_state` is\n            the cell state of the final time step, `sequence_lengths` is a\n            Tensor of shape `[batch_size]`.\n        \"\"\"\n        self._helper = helper\n        if initial_state is not None:\n            self._initial_state = initial_state\n        else:\n            self._initial_state = self.zero_state(\n                batch_size=self.batch_size, dtype=tf.float32)\n\n        max_decoding_length_train = self._hparams.max_decoding_length_train\n        if max_decoding_length_train is None:\n            max_decoding_length_train = utils.MAX_SEQ_LENGTH\n        max_decoding_length_infer = self._hparams.max_decoding_length_infer\n        if max_decoding_length_infer is None:\n            max_decoding_length_infer = utils.MAX_SEQ_LENGTH\n        max_decoding_length = tf.cond(\n            #utils.is_train_mode(mode),\n            context.global_mode_train(),\n            lambda: max_decoding_length_train,\n            lambda: max_decoding_length_infer)\n        outputs, final_state, sequence_lengths = dynamic_decode(\n            decoder=self, maximum_iterations=max_decoding_length)\n\n        if not self._built:\n            self._add_internal_trainable_variables()\n            # Add trainable variables of `self._cell` which may be\n            # constructed externally.\n            self._add_trainable_variable(\n                layers.get_rnn_cell_trainable_variables(self._cell))\n            if isinstance(self._output_layer, tf.layers.Layer):\n                self._add_trainable_variable(\n                    self._output_layer.trainable_variables)\n            self._built = True\n\n        return outputs, final_state, sequence_lengths",
            "file_path": "commits/f86ceee1b4a5cfa7ddc728eabcffc6327e853af3/Before/texar#modules#decoders#rnn_decoder_base.py"
        },
        "refactored_code": {
            "source_code": "def _build(self, initial_state=None, max_decoding_length=None,\n               output_time_major=False, decoding_strategy=\"train_greedy\",\n               inputs=None, sequence_length=None, input_time_major=False,\n               embedding=None, start_tokens=None, end_token=None,\n               softmax_temperature=None, helper=None, mode=None, **kwargs):\n        \"\"\"Performs decoding. The decoder provides 3 ways to specify the\n        decoding strategy, with varying flexibility:\n\n        - :attr:`decoding_strategy` argument: A string taking value:\n\n            - \"train_greedy\": decoding in training fashion (i.e., feeding \\\n              ground truth to decode the next step), and each sample is \\\n              obtained by taking the argmax of the RNN output logits. \\\n              Arguments :attr:`(inputs, sequence_length, input_time_major)` \\\n              are required for this strategy, and argument :attr:`embedding` \\\n              is optional.\n            - \"infer_greedy\": decoding in inference fashion (i.e., feeding \\\n              the generated sample to decode the next step), and each sample\\\n              is obtained by taking the argmax of the RNN output logits.\\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n            - \"infer_sample\": decoding in inference fashion, and each sample \\\n              is obtained by random sampling from the RNN output distribution. \\\n              Arguments :attr:`(embedding, start_tokens, end_token)` are \\\n              required for this strategy.\n\n          This argument is used only when :attr:`helper` is `None`.\n\n        - :attr:`helper` argument: An instance of \\\n          :tf_main:`tf.contrib.seq2seq.Helper <contrib/seq2seq/Helper>`. This \\\n          provides a superset of decoding strategies than above, for example:\n\n            - :tf_main:`TrainingHelper\n              <contrib/seq2seq/TrainingHelper>` corresponding to the \\\n              :attr:`\"train_argmax\"` strategy.\n            - :tf_main:`ScheduledEmbeddingTrainingHelper\n              <contrib/seq2seq/ScheduledEmbeddingTrainingHelper>` and \\\n              :tf_main:`ScheduledOutputTrainingHelper\n              <contrib/seq2seq/ScheduledOutputTrainingHelper>` for scheduled \\\n              sampling.\n            - :class:`~texar.modules.SoftmaxEmbeddingHelper` and \\\n              :class:`~texar.modules.GumbelSoftmaxEmbeddingHelper` for \\\n              soft decoding and gradient backpropagation.\n\n          This means gives the maximal flexibility of configuring the decoding\\\n          strategy.\n\n        - :attr:`hparams[\"helper_train\"]` and :attr:`hparams[\"helper_infer\"]`:\\\n          Specifying the helper through hyperparameters. Train and infer \\\n          strategy is toggled based on :attr:`mode`. Appriopriate arguments \\\n          (e.g., :attr:`inputs`, :attr:`start_tokens`, etc) are selected to \\\n          construct the helper. Additional construction arguments can be \\\n          provided either through :attr:`**kwargs`, or through \\\n          :attr:`hparams[\"helper_train/infer\"][\"kwargs\"]`.\n\n          This means is used only when :attr:`decoding_strategy` and \\\n          :attr:`helper` are both `None`.\n\n        Args:\n            initial_state (optional): Initial state of decoding.\n                If `None` (default), zero state is used.\n            max_decoding_length: A int scalar Tensor indicating the maximum\n                allowed number of decoding steps. If `None` (default), either\n                :attr:`hparams[\"max_decoding_length_train\"]` or\n                :attr:`hparams[\"max_decoding_length_infer\"]` is used\n                according to :attr:`mode`.\n            output_time_major (bool): If `True`, outputs are returned as\n                time major tensors. If `False` (default), outputs are returned\n                as batch major tensors.\n            decoding_strategy (str, optional): A string specifying the decoding\n                strategy. Different arguments are required based on the\n                strategy.\n                Ignored if :attr:`helper` is given.\n            inputs (optional): Input tensors. Used when\n                :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n\n                If :attr:`embedding` is `None`, :attr:`inputs` is directly\n                fed to the decoder. E.g., in `\"train_greedy\"` strategy,\n                :attr:`inputs` must be a 3D Tensor of shape\n                `[batch_size, max_time, emb_dim]` (or\n                `[max_time, batch_size, emb_dim]` if :attr:`input_time_major`\n                is `True`).\n\n                If :attr:`embedding` is given, :attr:`inputs` is used as index\n                to look up embeddings to be fed in the decoder. Requirements on\n                :attr:`inputs` depend on :attr:`embedding`.\n                E.g., if :attr:`embedding` is an instance of\n                :class:`~texar.modules.WordEmbedder`,\n                then :attr:`inputs` is usually a 2D int Tensor\n                `[batch_size, max_time]` (or\n                `[max_time, batch_size]` if :attr:`input_time_major`\n                is `True`) containing the token indexes.\n            sequence_length (optional): A 1D int Tensor containing the\n                sequence length of :attr:`inputs`.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            input_time_major (optional): Whether the :attr:`inputs` tensor is\n                time major.\n                Used when :attr:`decoding_strategy=\"train_greedy\"` or\n                :attr:`hparams`-configured helper is used.\n            embedding (optional): A callable that returns embedding vectors\n                of inputs, or the `params` argument of\n                :tf_main:`tf.nn.embedding_lookup <nn/embedding_lookup>`. In the\n                later case, :attr:`inputs` (if used) must be a int Tensor\n                containing the ids to be looked up in :attr:`embedding`.\n                Required when :attr:`decoding_strategy=\"infer_greedy\"`\n                or `\"infer_sample\"`; optional when\n                :attr:`decoding_strategy=\"train_greedy\"`.\n            start_tokens (optional): A int Tensor of shape `[batch_size]`,\n                the start tokens.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            end_token (optional): A int 0D Tensor, the token that marks end\n                of decoding.\n                Used when :attr:`decoding_strategy=\"infer_greedy\"` or\n                `\"infer_sample\"`, or when :attr:`hparams`-configured\n                helper is used.\n            softmax_temperature (optional): A float 0D Tensor, value to divide\n                the logits by before computing the softmax. Larger values\n                (above 1.0) result in more random samples. Must > 0. If `None`,\n                1.0 is used. Used when :attr:`decoding_strategy=\"infer_sample\"`.\n            helper (optional): An instance of\n                :tf_main:`Helper <contrib/seq2seq/Helper>`\n                that defines the decoding strategy. If given,\n                :attr:`decoding_strategy`\n                and helper configs in :attr:`hparams` are ignored.\n            mode (str, optional): A string taking value in\n                :tf_main:`tf.estimator.ModeKeys <estimator/ModeKeys>`. If\n                `TRAIN`, training related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_train']`), otherwise,\n                inference related hyperparameters are used (e.g.,\n                :attr:`hparams['max_decoding_length_infer']`). If\n                `None` (default), `TRAIN` mode is used.\n            **kwargs: Other keyword arguments for constructing helper\n                defined by :attr:`hparams[\"helper_trainn\"]` or\n                :attr:`hparams[\"helper_infer\"]`.\n\n        Returns:\n            `(outputs, final_state, sequence_lengths)`: `outputs` is an object\n            containing the decoder output on all time steps, `final_state` is\n            the cell state of the final time step, `sequence_lengths` is a\n            Tensor of shape `[batch_size]`.\n        \"\"\"\n        # Helper\n        if helper is not None:\n            pass\n        elif decoding_strategy is not None:\n            if decoding_strategy == \"train_greedy\":\n                helper = rnn_decoder_helpers._get_training_helper(\n                    inputs, sequence_length, embedding, input_time_major)\n            elif decoding_strategy == \"infer_greedy\":\n                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                    embedding, start_tokens, end_token)\n            elif decoding_strategy == \"infer_sample\":\n                helper = tf.contrib.seq2seq.SampleEmbeddingHelper(\n                    embedding, start_tokens, end_token, softmax_temperature)\n            else:\n                raise ValueError(\n                    \"Unknown decoding strategy: {}\".format(decoding_strategy))\n        else:\n            if mode is None or mode == tf.estimator.ModeKeys.TRAIN:\n                kwargs_ = copy.copy(self._hparams.helper_train.kwargs.todict())\n                helper_type = self._hparams.helper_train.type\n            elif mode == tf.estimator.ModeKeys.EVAL or \\\n                    mode == tf.estimator.ModeKeys.PREDICT:\n                kwargs_ = copy.copy(self._hparams.helper_infer.kwargs.todict())\n                helper_type = self._hparams.helper_infer.type\n            else:\n                raise ValueError(\"Unknown mode: {}\".format(mode))\n            kwargs_.update({\n                \"inputs\": inputs,\n                \"sequence_length\": sequence_length,\n                \"time_major\": input_time_major,\n                \"embedding\": embedding,\n                \"start_tokens\": start_tokens,\n                \"end_token\": end_token,\n                \"softmax_temperature\": softmax_temperature})\n            kwargs_.update(kwargs)\n            helper = rnn_decoder_helpers.get_helper(helper_type, **kwargs_)\n        self._helper = helper\n\n        # Initial state\n        if initial_state is not None:\n            self._initial_state = initial_state\n        else:\n            self._initial_state = self.zero_state(\n                batch_size=self.batch_size, dtype=tf.float32)\n\n        # Maximum decoding length\n        max_l = max_decoding_length\n        if max_l is None:\n            max_l_train = self._hparams.max_decoding_length_train\n            if max_l_train is None:\n                max_l_train = utils.MAX_SEQ_LENGTH\n            max_l_infer = self._hparams.max_decoding_length_infer\n            if max_l_infer is None:\n                max_l_infer = utils.MAX_SEQ_LENGTH\n            max_l = tf.cond(utils.is_train_mode(mode),\n                            lambda: max_l_train, lambda: max_l_infer)\n\n        # Decode\n        outputs, final_state, sequence_lengths = dynamic_decode(\n            decoder=self, maximum_iterations=max_l,\n            output_time_major=output_time_major)\n\n        if not self._built:\n            self._add_internal_trainable_variables()\n            # Add trainable variables of `self._cell` which may be\n            # constructed externally.\n            self._add_trainable_variable(\n                layers.get_rnn_cell_trainable_variables(self._cell))\n            if isinstance(self._output_layer, tf.layers.Layer):\n                self._add_trainable_variable(\n                    self._output_layer.trainable_variables)\n            self._built = True\n\n        return outputs, final_state, sequence_lengths",
            "file_path": "commits/f86ceee1b4a5cfa7ddc728eabcffc6327e853af3/After/texar#modules#decoders#rnn_decoder_base.py"
        },
        "original_variable_name": "max_decoding_length_train",
        "new_variable_name": "max_l_infer",
        "label": "positive",
        "id": "80679862-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 15018
    },
    {
        "commit_hash": "3714d8ec80e94b062ca5d62c9575acc026bc753f",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def parse_arguments(parser: argparse.ArgumentParser) -> argparse.Namespace:\n    \"\"\"\n    Parse the arguments that the user entered\n    :param parser: the argparse command line parser\n    :return: the parsed arguments\n    \"\"\"\n    args = parser.parse_args()\n\n    # if no arg is given\n    if len(sys.argv) == 1:\n        parser.print_help()\n        exit(0)\n\n    # list available presets\n    preset_names = list_all_presets()\n    if args.list:\n        screen.log_title(\"Available Presets:\")\n        for preset in sorted(preset_names):\n            print(preset)\n        sys.exit(0)\n\n    # replace a short preset name with the full path\n    if args.preset is not None:\n        if args.preset.lower() in [p.lower() for p in preset_names]:\n            args.preset = \"{}.py:graph_manager\".format(os.path.join(get_base_dir(), 'presets', args.preset))\n        else:\n            args.preset = \"{}\".format(args.preset)\n            # if a graph manager variable was not specified, try the default of :graph_manager\n            if len(args.preset.split(\":\")) == 1:\n                args.preset += \":graph_manager\"\n\n        # verify that the preset exists\n        preset_path = args.preset.split(\":\")[0]\n        if not os.path.exists(preset_path):\n            screen.error(\"The given preset ({}) cannot be found.\".format(args.preset))\n\n        # verify that the preset can be instantiated\n        try:\n            short_dynamic_import(args.preset, ignore_module_case=True)\n        except TypeError as e:\n            traceback.print_exc()\n            screen.error('Internal Error: ' + str(e) + \"\\n\\nThe given preset ({}) cannot be instantiated.\"\n                         .format(args.preset))\n\n    # validate the checkpoints args\n    if args.checkpoint_restore_dir is not None and not os.path.exists(args.checkpoint_restore_dir):\n        screen.error(\"The requested checkpoint folder to load from does not exist.\")\n\n    # no preset was given. check if the user requested to play some environment on its own\n    if args.preset is None and args.play:\n        if args.environment_type:\n            args.agent_type = 'Human'\n        else:\n            screen.error('When no preset is given for Coach to run, and the user requests human control over '\n                         'the environment, the user is expected to input the desired environment_type and level.'\n                         '\\nAt least one of these parameters was not given.')\n    elif args.preset and args.play:\n        screen.error(\"Both the --preset and the --play flags were set. These flags can not be used together. \"\n                     \"For human control, please use the --play flag together with the environment type flag (-et)\")\n    elif args.preset is None and not args.play:\n        screen.error(\"Please choose a preset using the -p flag or use the --play flag together with choosing an \"\n                     \"environment type (-et) in order to play the game.\")\n\n    # get experiment name and path\n    args.experiment_name = logger.get_experiment_name(args.experiment_name)\n    args.experiment_path = logger.get_experiment_path(args.experiment_name)\n\n    if args.play and args.num_workers > 1:\n        screen.warning(\"Playing the game as a human is only available with a single worker. \"\n                       \"The number of workers will be reduced to 1\")\n        args.num_workers = 1\n\n    args.framework = Frameworks[args.framework.lower()]\n\n    # checkpoints\n    args.save_checkpoint_dir = os.path.join(args.experiment_path, 'checkpoint') if args.save_checkpoint_secs is not None else None\n\n    return args",
            "file_path": "commits/3714d8ec80e94b062ca5d62c9575acc026bc753f/Before/rl_coach#coach.py"
        },
        "refactored_code": {
            "source_code": "def display_all_presets_and_exit():\n    # list available presets\n    if args.list:\n        screen.log_title(\"Available Presets:\")\n        for preset in sorted(list_all_presets()):\n            print(preset)\n        sys.exit(0)",
            "file_path": "commits/3714d8ec80e94b062ca5d62c9575acc026bc753f/After/rl_coach#coach.py"
        },
        "variable_name": "preset_names",
        "label": "positive",
        "id": "806ae9d6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4217
    },
    {
        "commit_hash": "f60313e29657b2afb6a02f28dba5936bc0dd09e6",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_CSVLogger(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'log.tsv')\n    sep = '\\t'\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    # case 1, create new file with defined separator\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    assert os.path.isfile(filepath)\n    with open(filepath) as csvfile:\n        dialect = Sniffer().sniff(csvfile.read())\n    assert dialect.delimiter == sep\n    del model\n    del cbks\n\n    # case 2, append data to existing file, skip header\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep, append=True)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    # case 3, reuse of CSVLogger object\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    import re\n    with open(filepath) as csvfile:\n        output = \" \".join(csvfile.readlines())\n        assert len(re.findall('epoch', output)) == 1\n\n    os.remove(filepath)\n    assert not tmpdir.listdir()",
            "file_path": "commits/f60313e29657b2afb6a02f28dba5936bc0dd09e6/Before/tests#keras#test_callbacks.py"
        },
        "refactored_code": {
            "source_code": "def test_CSVLogger(tmpdir):\n    np.random.seed(1337)\n    filepath = str(tmpdir / 'log.tsv')\n    sep = '\\t'\n    (X_train, y_train), (X_test, y_test) = get_test_data(num_train=train_samples,\n                                                         num_test=test_samples,\n                                                         input_shape=(input_dim,),\n                                                         classification=True,\n                                                         num_classes=num_classes)\n    y_test = np_utils.to_categorical(y_test)\n    y_train = np_utils.to_categorical(y_train)\n\n    def make_model():\n        np.random.seed(1337)\n        model = Sequential()\n        model.add(Dense(num_hidden, input_dim=input_dim, activation='relu'))\n        model.add(Dense(num_classes, activation='softmax'))\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=optimizers.SGD(lr=0.1),\n                      metrics=['accuracy'])\n        return model\n\n    # case 1, create new file with defined separator\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    assert os.path.isfile(filepath)\n    with open(filepath) as csvfile:\n        dialect = Sniffer().sniff(csvfile.read())\n    assert dialect.delimiter == sep\n    del model\n    del cbks\n\n    # case 2, append data to existing file, skip header\n    model = make_model()\n    cbks = [callbacks.CSVLogger(filepath, separator=sep, append=True)]\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=1)\n\n    # case 3, reuse of CSVLogger object\n    model.fit(X_train, y_train, batch_size=batch_size,\n              validation_data=(X_test, y_test), callbacks=cbks, epochs=2)\n\n    import re\n    with open(filepath) as csvfile:\n        list_lines = csvfile.readlines()\n        for line in list_lines:\n            assert line.count(sep) == 4\n        assert len(list_lines) == 5\n        output = \" \".join(list_lines)\n        assert len(re.findall('epoch', output)) == 1\n\n    os.remove(filepath)\n    assert not tmpdir.listdir()",
            "file_path": "commits/f60313e29657b2afb6a02f28dba5936bc0dd09e6/After/tests#keras#test_callbacks.py"
        },
        "original_variable_name": "output",
        "new_variable_name": "list_lines",
        "label": "negative",
        "id": "806790a6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 4854
    },
    {
        "commit_hash": "452ba701d7d365c22764cbdf0dca46e0df5b6d8a",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "handle_play_stones",
            "container_name": "sgf_wrapper",
            "source_code": "def handle_play_stones(pos, node):\n    props = node.properties\n    if 'W' in props:\n        pos = pos.play_move('W', pc(props['W'][0]))\n    elif 'B' in props:\n        pos = pos.play_move('B', pc(props['B'][0]))\n    if node.next:\n        props = node.next.properties\n        if pos.player1turn and 'W' in props:\n            pos = pos._replace(player1turn=False)\n        elif not pos.player1turn and 'B' in props:\n            pos = pos._replace(player1turn=True)\n    return pos"
        },
        "original_method_after_refactoring": {
            "name": "handle_play_stones",
            "container_name": "sgf_wrapper",
            "source_code": "def handle_play_stones(pos, node):\n    props = node.properties\n    if 'W' in props:\n        pos = pos.play_move('W', pc(props['W'][0]))\n    elif 'B' in props:\n        pos = pos.play_move('B', pc(props['B'][0]))\n    next_player, _ = get_next_move(node)\n    if next_player == 'W' and pos.player1turn:\n        pos = pos._replace(player1turn=False)\n    elif next_player == 'B' and not pos.player1turn:\n        pos = pos._replace(player1turn=True)\n    return pos"
        },
        "newly_extracted_method": {
            "name": "get_next_move",
            "container_name": "Unknown",
            "source_code": "def get_next_move(node):\n    if not node.next:\n        return None, None\n    props = node.next.properties\n    if 'W' in props:\n        return 'W', props['W']\n    else:\n        return 'B', props['B']"
        },
        "label": "positive",
        "id": "805c00f6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1495
    },
    {
        "commit_hash": "5d943f5a75afaa14a88704230a9cf660d8a54576",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_norm(self):\n        x = self.man.rand()\n        u = self.man.randvec(x)\n        inv_x = 1./x\n        np_testing.assert_almost_equal(\n            np.sqrt(np.sum(inv_x*u*inv_x*u)), self.man.norm(x, u))",
            "file_path": "commits/5d943f5a75afaa14a88704230a9cf660d8a54576/Before/tests#test_manifolds#test_strictly_positive_vectors.py"
        },
        "refactored_code": {
            "source_code": "def test_norm(self):\n        x = self.man.rand()\n        u = self.man.randvec(x)\n        x_u = (1./x) * u\n        np_testing.assert_almost_equal(\n            la.norm(x_u, axis=0, keepdims=True),\n            self.man.norm(x, u))",
            "file_path": "commits/5d943f5a75afaa14a88704230a9cf660d8a54576/After/tests#test_manifolds#test_strictly_positive_vectors.py"
        },
        "original_variable_name": "inv_x",
        "new_variable_name": "x_u",
        "label": "positive",
        "id": "80679ab0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 844
    },
    {
        "commit_hash": "e217947a9e34adc009913fe9f1a8d94e9fbab80d",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def get_rnn_cell(cell_hparams):\n    \"\"\"Creates an RNN cell\n\n    Args:\n      cell_hparams: a dictionary of hyperparameters\n\n    Returns:\n      An instance of RNN cell\n    \"\"\"\n    cells = []\n    for _ in range(cell_hparams[\"num_layers\"]):\n        cell_type = cell_hparams[\"cell\"][\"type\"]\n        try:\n            try:\n                cell_class = getattr(custom, cell_type)\n            except:\n                cell_class = getattr(rnn, cell_type)\n        except:\n            raise ValueError(\"Cell type not found: %s\" % cell_type)\n        cell = get_instance(cell_class, cell_hparams[\"cell\"][\"args\"])\n\n        dpt_hparams = cell_hparams[\"dropout\"]\n        if dpt_hparams[\"use\"]:\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=switch_dropout(dpt_hparams[\"input_dropout_prob\"]),\n                output_keep_prob=switch_dropout(dpt_hparams[\"output_dropout_prob\"]),\n                state_keep_prob=switch_dropout(dpt_hparams[\"state_dropout_prob\"]),\n                variational_recurrent=dpt_hparams[\"variational_recurrent\"])\n\n        cells.append(cell)\n\n    if cell_hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)\n    else:\n        cell = cells[0]\n\n    if cell_hparams[\"residual\"]:\n        cell = rnn.ResidualWrapper(cell)\n    if cell_hparams[\"highway\"]:\n        cell = rnn.HighwayWrapper(cell)   # FIXME No Highway wrapper yet\n\n    return cell",
            "file_path": "commits/e217947a9e34adc009913fe9f1a8d94e9fbab80d/Before/txtgen#core#layers.py"
        },
        "refactored_code": {
            "source_code": "def get_rnn_cell(cell_hparams):\n    \"\"\"Creates an RNN cell\n\n    Args:\n      cell_hparams: a dictionary of hyperparameters\n\n    Returns:\n      An instance of RNN cell\n    \"\"\"\n    cells = []\n    for _ in range(cell_hparams[\"num_layers\"]):\n        cell_type = cell_hparams[\"cell\"][\"type\"]\n        cell_modules = ['txtgen.custom', 'tensorflow.contrib.rnn']\n        cell = get_instance(cell_type, cell_hparams[\"cell\"][\"args\"],\n                            cell_modules)\n\n        d_hp = cell_hparams[\"dropout\"]\n        if d_hp[\"use\"]:\n            cell = rnn.DropoutWrapper(\n                cell=cell,\n                input_keep_prob=switch_dropout(d_hp[\"input_dropout_prob\"]),\n                output_keep_prob=switch_dropout(d_hp[\"output_dropout_prob\"]),\n                state_keep_prob=switch_dropout(d_hp[\"state_dropout_prob\"]),\n                variational_recurrent=d_hp[\"variational_recurrent\"])\n\n        cells.append(cell)\n\n    if cell_hparams[\"num_layers\"] > 1:\n        cell = rnn.MultiRNNCell(cells)    # pylint: disable=redefined-variable-type\n    else:\n        cell = cells[0]\n\n    if cell_hparams[\"residual\"]:\n        cell = rnn.ResidualWrapper(cell)\n    if cell_hparams[\"highway\"]:\n        cell = rnn.HighwayWrapper(cell)\n\n    return cell",
            "file_path": "commits/e217947a9e34adc009913fe9f1a8d94e9fbab80d/After/txtgen#core#layers.py"
        },
        "original_variable_name": "dpt_hparams",
        "new_variable_name": "d_hp",
        "label": "positive",
        "id": "8067979a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3071
    },
    {
        "commit_hash": "f1afb5df71893ff2770c7cc7ca83d2ac68f977d7",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def phase(self, v):\n        if v.dim() == 1:\n            v = v.unsqueeze(0)\n            unsqueezed = True\n        else:\n            unsqueezed = False\n\n        phase = torch.zeros(v.shape[0])\n\n        if unsqueezed:\n            return phase.squeeze_(0)\n        else:\n            return phase",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/Before/tests#test_observables.py"
        },
        "refactored_code": {
            "source_code": "def phase(self, v):\n        return torch.zeros(v.shape[0])",
            "file_path": "commits/f1afb5df71893ff2770c7cc7ca83d2ac68f977d7/After/tests#test_observables.py"
        },
        "variable_name": "phase",
        "label": "positive",
        "id": "806ae580-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 699
    },
    {
        "commit_hash": "a124edcd95c1dcc16070e16244fdfcba6be169e3",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def sample_goal(self):\n        \"\"\"\n        Sample goals.\n\n        :return: the new sampled goal.\n        \"\"\"\n        goal = self._initial_goal.copy()\n\n        random_goal_delta = np.random.uniform(\n            -self._target_range, self._target_range, size=2)\n        goal[:2] += random_goal_delta\n        self._goal = goal\n        return goal",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/Before/garage#envs#mujoco#sawyer#reacher_env.py"
        },
        "refactored_code": {
            "source_code": "def get_obs(self):\n        gripper_pos = self.gripper_position\n        dt = self.sim.nsubsteps * self.sim.model.opt.timestep\n        grip_velp = self.sim.data.get_site_xvelp('grip') * dt\n\n        object_pos = self.object_position\n        object_velp = self.sim.data.get_site_xvelp('object0') * dt\n        object_velp -= grip_velp\n        grasped = self.has_object\n        obs = np.concatenate([gripper_pos])\n\n        achieved_goal = self._achieved_goal_fn(self)\n        desired_goal = self._desired_goal_fn(self)\n\n        achieved_goal_qpos = np.concatenate((achieved_goal, [1, 0, 0, 0]))\n        self.sim.data.set_joint_qpos('achieved_goal:joint', achieved_goal_qpos)\n        desired_goal_qpos = np.concatenate((desired_goal, [1, 0, 0, 0]))\n        self.sim.data.set_joint_qpos('desired_goal:joint', desired_goal_qpos)\n\n        return {\n            'observation': obs.copy(),\n            'achieved_goal': achieved_goal,\n            'desired_goal': desired_goal,\n            'gripper_state': self.gripper_state,\n            'gripper_pos': gripper_pos.copy(),\n            'has_object': grasped,\n            'object_pos': object_pos.copy()\n        }",
            "file_path": "commits/a124edcd95c1dcc16070e16244fdfcba6be169e3/After/garage#envs#mujoco#sawyer#reacher_env.py"
        },
        "variable_name": "goal",
        "label": "negative",
        "id": "806ae878-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1894
    },
    {
        "commit_hash": "36f4b18340e2974cfee80e5c347bf7ae7459ab88",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def __init__(self, hparams=None):\n    if FLAGS.data_dir:\n      self._hparams['data_dir'] = FLAGS.data_dir\n    if FLAGS.expt_dir:\n      self._hparams['expt_dir'] = FLAGS.expt_dir\n    if FLAGS.log_dir:\n      self._hparams['log_dir'] = FLAGS.log_dir\n\n    self._hparams = HParams(hparams, self.default_hparams())",
            "file_path": "commits/36f4b18340e2974cfee80e5c347bf7ae7459ab88/Before/examples#tsf#trainer_base.py"
        },
        "refactored_code": {
            "source_code": "def __init__(self, hparams=None):\n    flags_hparams = self.default_hparams()\n    if FLAGS.data_dir:\n      flags_hparams[\"data_dir\"] = FLAGS.data_dir\n    if FLAGS.expt_dir:\n      flags_hparams[\"expt_dir\"] = FLAGS.expt_dir\n    if FLAGS.log_dir:\n      flags_hparams[\"log_dir\"] = FLAGS.log_dir\n    if FLAGS.config:\n      flags_hparams[\"config\"] = FLAGS.config\n    if FLAGS.model:\n      flags_hparams[\"model\"] = FLAGS.model\n\n    self._hparams = HParams(self._hparams, flags_hparams)",
            "file_path": "commits/36f4b18340e2974cfee80e5c347bf7ae7459ab88/After/examples#tsf#trainer_base.py"
        },
        "variable_name": "flags_hparams",
        "label": "positive",
        "id": "8069bd18-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1158
    },
    {
        "commit_hash": "f818cffc557e032e5a61949ced8bcda96d616660",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "run",
            "container_name": "_run",
            "source_code": "def run(stream_spec, cmd='ffmpeg', **kwargs):\n    \"\"\"Run ffmpeg on node graph.\n\n    Args:\n        **kwargs: keyword-arguments passed to ``get_args()`` (e.g. ``overwrite_output=True``).\n    \"\"\"\n    if isinstance(cmd, basestring):\n        cmd = [cmd]\n    elif type(cmd) != list:\n        cmd = list(cmd)\n    args = cmd + get_args(stream_spec, **kwargs)\n    _subprocess.check_call(args)"
        },
        "original_method_after_refactoring": {
            "name": "run",
            "container_name": "_run",
            "source_code": "def run(stream_spec, cmd='ffmpeg', **kwargs):\n    \"\"\"Run ffmpeg on node graph.\n\n    Args:\n        **kwargs: keyword-arguments passed to ``get_args()`` (e.g. ``overwrite_output=True``).\n    \"\"\"\n    _subprocess.check_call(compile(stream_spec, cmd, **kwargs))"
        },
        "newly_extracted_method": {
            "name": "compile",
            "container_name": "_run",
            "source_code": "def compile(stream_spec, cmd='ffmpeg', **kwargs):\n    \"\"\"Build command-line for ffmpeg.\"\"\"\n    if isinstance(cmd, basestring):\n        cmd = [cmd]\n    elif type(cmd) != list:\n        cmd = list(cmd)\n    return cmd + get_args(stream_spec, **kwargs)"
        },
        "label": "positive",
        "id": "805be602-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1196
    },
    {
        "commit_hash": "201fb751c76de9e407507d472f21a23f86c79b2e",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "sample_idxs_of_segments",
            "container_name": "sampling",
            "source_code": "def sample_idxs_of_segments(log,\n                            job_id,\n                            n_samples,\n                            dims_of_segment,\n                            dims_of_scan,\n                            sampling_map):\n    \"\"\"\n    sampling_map: np.array of shape (H,W,D), dtype=\"int16\" or potentially float if weightmaps given by user.\n    Returns: [ idxs_of_sampled_centers, slice_idxs_of_sampled_segms ]\n             Coordinates (xyz indices) of the \"central\" voxel of sampled segments (1 voxel to the left if dimension is even).\n             Also returns the indices of the image parts, left and right indices, INCLUSIVE BOTH SIDES.\n    \n    > idxs_of_sampled_centers: array with shape: 3(xyz) x n_samples.\n        Example: [ xCoordsForCentralVoxelOfEachPart, yCoordsForCentralVoxelOfEachPart, zCoordsForCentralVoxelOfEachPart ]\n        >> x/y/z-CoordsForCentralVoxelOfEachPart: 1-dim array with n_samples, holding the x-indices of samples in image.\n    > slice_idxs_of_sampled_segms: 3(xyz) x NumberOfImagePartSamples x 2.\n        The last dimension has [0] for the lower boundary of the slice, and [1] for the higher boundary. INCLUSIVE BOTH SIDES.\n        Example: [ x-sliceCoordsOfImagePart, y-sliceCoordsOfImagePart, z-sliceCoordsOfImagePart ]\n    \"\"\"\n    # Check if the weight map is fully-zeros. In this case, return no element.\n    # Note: Currently, the caller function is checking this case already and does not let this being called.\n    # Which is still fine.\n    if np.isclose(np.sum(sampling_map), 0.):\n        log.print3(job_id + \" WARN: Sampling map for category is just zeros! \" +\\\n                   \" No samples for category from subject!\")\n        return [[[], [], []], [[], [], []]]\n\n    # Now out of these, I need to randomly select one, which will be an ImagePart's central voxel.\n    # But I need to be CAREFUL and get one that IS NOT closer to the image boundaries than the dimensions of the\n    # ImagePart permit.\n\n    # I look for lesions that are not closer to the image boundaries than the ImagePart dimensions allow.\n    # KernelDim is always odd. BUT ImagePart dimensions can be odd or even.\n    # If odd, ok, floor(dim/2) from central.\n    # If even, dim/2-1 voxels towards the begining of the axis and dim/2 towards the end.\n    # Ie, \"central\" imagePart voxel is 1 closer to begining.\n    # BTW imagePartDim takes kernel into account (ie if I want 9^3 voxels classified per imagePart with kernel 5x5,\n    # I want 13 dim ImagePart)\n\n    # number of voxels to exclude from edges of the image, left and right in each axis, when sampling...\n    # ...the center of a segment. So that the segment will be fully contained in the image. (half segm left & right)\n    # dim1: 1 row per r,c,z. Dim2: left/right width not to sample from (=half segment).\n    n_vox_excl_left_right = np.zeros((len(dims_of_segment), 2), dtype='int16')\n\n    # The below starts all zero. Will be Multiplied by other true-false arrays expressing if the relevant\n    # voxels are within boundaries.\n    # In the end, the final vector will be true only for the indices of lesions that are within all boundaries.\n    mask_excl_near_edges = np.zeros(sampling_map.shape, dtype='int8')\n\n    # This loop leads to mask_excl_near_edges to be true for the indices ...\n    # ...that allow getting an imagePart CENTERED on them, and be safely within image boundaries. Note that ...\n    # ... if the imagePart is of even dimension, the \"central\" voxel is one voxel to the left.\n    for rcz_i in range(len(dims_of_segment)):\n        if dims_of_segment[rcz_i] % 2 == 0:  # even\n            dims_div_2 = dims_of_segment[rcz_i] // 2\n            # central of ImagePart is 1 vox closer to begining of axes.\n            n_vox_excl_left_right[rcz_i] = [dims_div_2 - 1, dims_div_2]\n        else:  # odd\n            # If odd, middle voxel is the \"central\". Eg 5/2 = 2, with 3rd voxel being the central.\n            dims_div_2_floor = math.floor(dims_of_segment[rcz_i] // 2)\n            n_vox_excl_left_right[rcz_i] = [dims_div_2_floor, dims_div_2_floor]\n            # used to be [n_vox_excl_left_right[0][0]: -n_vox_excl_left_right[0][1]],\n            # but in 2D case n_vox_excl_left_right might be ==0, causes problem and you get a null slice.\n    mask_excl_near_edges[\n        n_vox_excl_left_right[0][0]: dims_of_scan[0] - n_vox_excl_left_right[0][1],\n        n_vox_excl_left_right[1][0]: dims_of_scan[1] - n_vox_excl_left_right[1][1],\n        n_vox_excl_left_right[2][0]: dims_of_scan[2] - n_vox_excl_left_right[2][1]] = 1\n\n    sampling_map_excl_near_edges = np.multiply(sampling_map, mask_excl_near_edges, dtype=sampling_map.dtype)\n    # normalize the probabilities to sum to 1, cause the function needs it as so.\n    sum_sampl_map = np.sum(sampling_map_excl_near_edges)\n    if np.isclose(sum_sampl_map, 0.) : # is zero\n        log.print3(job_id + \" WARN: AFTER EXCLUDING NEAR EDGES, sampling map for category is just zeros! \" +\\\n                   \" No samples for category from subject!\")\n        return [ [[],[],[]], [[],[],[]] ]\n    \n    # Sample indexes of pixels around which we should extract sample segments.\n    idxs_of_sampled_centers = sample_with_appropriate_algorithm(n_samples, sampling_map_excl_near_edges, sum_sampl_map)\n    \n    # Array with shape: 3(rcz) x NumberOfImagePartSamples x 2.\n    # Last dimension has [0] for lowest boundary of slice, and [1] for highest boundary. INCLUSIVE BOTH SIDES.\n    slice_idxs_of_sampled_segms = np.zeros(list(idxs_of_sampled_centers.shape) + [2], dtype='int32')\n    # below, np.newaxis broadcasts. To broadcast the -+.\n    slice_idxs_of_sampled_segms[:, :, 0] = idxs_of_sampled_centers - n_vox_excl_left_right[:, np.newaxis, 0]\n    slice_idxs_of_sampled_segms[:, :, 1] = idxs_of_sampled_centers + n_vox_excl_left_right[:, np.newaxis, 1]\n\n    # idxs_of_sampled_centers: Array of dimensions 3(rcz) x NumberOfImagePartSamples.\n    # slice_idxs_of_sampled_segms: Array of dimensions 3(rcz) x NumberOfImagePartSamples x 2. ...\n    # ... The last dim has [0] for the lower boundary of the slice, and [1] for the higher boundary.\n    # ... The slice coordinates returned are INCLUSIVE BOTH sides.\n    return (idxs_of_sampled_centers, slice_idxs_of_sampled_segms)"
        },
        "original_method_after_refactoring": {
            "name": "sample_idxs_of_segments",
            "container_name": "sampling",
            "source_code": "def sample_idxs_of_segments(log,\n                            job_id,\n                            n_samples,\n                            dims_of_segment,\n                            sampling_map):\n    \"\"\"\n    sampling_map: np.array of shape (H,W,D), dtype=\"int16\" or potentially float if weightmaps given by user.\n    Returns: [ idxs_of_sampled_centers, slice_idxs_of_sampled_segms ]\n             Coordinates (xyz indices) of the \"central\" voxel of sampled segments (1 voxel to the left if dimension is even).\n             Also returns the indices of the image parts, left and right indices, INCLUSIVE BOTH SIDES.\n    \n    > idxs_of_sampled_centers: array with shape: 3(xyz) x n_samples.\n        Example: [ xCoordsForCentralVoxelOfEachPart, yCoordsForCentralVoxelOfEachPart, zCoordsForCentralVoxelOfEachPart ]\n        >> x/y/z-CoordsForCentralVoxelOfEachPart: 1-dim array with n_samples, holding the x-indices of samples in image.\n    > slice_idxs_of_sampled_segms: 3(xyz) x NumberOfImagePartSamples x 2.\n        The last dimension has [0] for the lower boundary of the slice, and [1] for the higher boundary. INCLUSIVE BOTH SIDES.\n        Example: [ x-sliceCoordsOfImagePart, y-sliceCoordsOfImagePart, z-sliceCoordsOfImagePart ]\n    \"\"\"\n    # Check if the weight map is fully-zeros. In this case, return no element.\n    # Note: Currently, the caller function is checking this case already and does not let this being called.\n    # Which is still fine.\n    if np.isclose(np.sum(sampling_map), 0.):\n        log.print3(job_id + \" WARN: Sampling map for category is just zeros! \" +\\\n                   \" No samples for category from subject!\")\n        return [[[], [], []], [[], [], []]]\n    \n    # Now out of these, I need to randomly select one, which will be an ImagePart's central voxel.\n    # But I need to be CAREFUL and get one that IS NOT closer to the image boundaries than the dimensions of the\n    # ImagePart permit.\n    mask_excl_near_edges = comp_valid_sampling_mask_excluding_edges(dims_of_segment, sampling_map.shape)\n    sampling_map_excl_near_edges = np.multiply(sampling_map, mask_excl_near_edges, dtype=sampling_map.dtype)\n    # normalize the probabilities to sum to 1, cause the function needs it as so.\n    sum_sampl_map = np.sum(sampling_map_excl_near_edges)\n    if np.isclose(sum_sampl_map, 0.) : # is zero\n        log.print3(job_id + \" WARN: AFTER EXCLUDING NEAR EDGES, sampling map for category is just zeros! \" +\\\n                   \" No samples for category from subject!\")\n        return [ [[],[],[]], [[],[],[]] ]\n    \n    # Sample indexes of pixels around which we should extract sample segments.\n    idxs_of_sampled_centers = sample_with_appropriate_algorithm(n_samples, sampling_map_excl_near_edges, sum_sampl_map)\n    \n    return idxs_of_sampled_centers"
        },
        "newly_extracted_method": {
            "name": "comp_valid_sampling_mask_excluding_edges",
            "container_name": "sampling",
            "source_code": "def comp_valid_sampling_mask_excluding_edges(dims_of_segment, shape):\n    # I look for lesions that are not closer to the image boundaries than the ImagePart dimensions allow.\n    # KernelDim is always odd. BUT ImagePart dimensions can be odd or even.\n    # If odd, ok, floor(dim/2) from central.\n    # If even, dim/2-1 voxels towards the begining of the axis and dim/2 towards the end.\n    # Ie, \"central\" imagePart voxel is 1 closer to begining.\n    # BTW imagePartDim takes kernel into account (ie if I want 9^3 voxels classified per imagePart with kernel 5x5,\n    # I want 13 dim ImagePart)\n    \n    # number of voxels to exclude from edges of the image, left and right in each axis, when sampling...\n    # ...the center of a segment. So that the segment will be fully contained in the image. (half segm left & right)\n    # dim1: 1 row per r,c,z. Dim2: left/right width not to sample from (=half segment).\n    n_vox_excl_left_right = np.zeros((len(dims_of_segment), 2), dtype='int16')\n\n    # The below starts all zero. Will be Multiplied by other true-false arrays expressing if the relevant\n    # voxels are within boundaries.\n    # In the end, the final vector will be true only for the indices of lesions that are within all boundaries.\n    mask_excl_near_edges = np.zeros(shape, dtype='int8')\n\n    # This loop leads to mask_excl_near_edges to be true for the indices ...\n    # ...that allow getting an imagePart CENTERED on them, and be safely within image boundaries. Note that ...\n    # ... if the imagePart is of even dimension, the \"central\" voxel is one voxel to the left.\n    for rcz_i in range(len(dims_of_segment)):\n        if dims_of_segment[rcz_i] % 2 == 0:  # even\n            dims_div_2 = dims_of_segment[rcz_i] // 2\n            # central of ImagePart is 1 vox closer to begining of axes.\n            n_vox_excl_left_right[rcz_i] = [dims_div_2 - 1, dims_div_2]\n        else:  # odd\n            # If odd, middle voxel is the \"central\". Eg 5/2 = 2, with 3rd voxel being the central.\n            dims_div_2_floor = math.floor(dims_of_segment[rcz_i] // 2)\n            n_vox_excl_left_right[rcz_i] = [dims_div_2_floor, dims_div_2_floor]\n            # used to be [n_vox_excl_left_right[0][0]: -n_vox_excl_left_right[0][1]],\n            # but in 2D case n_vox_excl_left_right might be ==0, causes problem and you get a null slice.\n    mask_excl_near_edges[\n        n_vox_excl_left_right[0][0]: shape[0] - n_vox_excl_left_right[0][1],\n        n_vox_excl_left_right[1][0]: shape[1] - n_vox_excl_left_right[1][1],\n        n_vox_excl_left_right[2][0]: shape[2] - n_vox_excl_left_right[2][1]] = 1\n        \n    return mask_excl_near_edges"
        },
        "label": "positive",
        "id": "805be8a0-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 12197
    },
    {
        "commit_hash": "cb2f63f02d81e6decd55fda364b2215d70b3c090",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def test_validate_boolean3():\n    nan = ['maybe', 2, 0.5]\n    for value in nan:\n        assert_raises(ValueError, validate_boolean, value)",
            "file_path": "commits/cb2f63f02d81e6decd55fda364b2215d70b3c090/Before/dit#tests#test_params.py"
        },
        "refactored_code": {
            "source_code": "def test_validate_boolean3():\n    not_valid = ['maybe', 2, 0.5]\n    for value in not_valid:\n        assert_raises(ValueError, validate_boolean, value)",
            "file_path": "commits/cb2f63f02d81e6decd55fda364b2215d70b3c090/After/dit#tests#test_params.py"
        },
        "original_variable_name": "nan",
        "new_variable_name": "not_valid",
        "label": "positive",
        "id": "8067a276-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 636
    },
    {
        "commit_hash": "b864b6c2fb100beac26176117305df5d3bb57b6e",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def load_testdata(filename):\n    path = os.path.join(os.path.dirname(__file__),\n                        'test_files',\n                        filename)\n    with open(path) as f:\n        return f.read()",
            "file_path": "commits/b864b6c2fb100beac26176117305df5d3bb57b6e/Before/tests#xml2#XMLBearTest.py"
        },
        "refactored_code": {
            "source_code": "def get_testfile_path(filename):\n    return os.path.join(os.path.dirname(__file__),\n                        'test_files',\n                        filename)",
            "file_path": "commits/b864b6c2fb100beac26176117305df5d3bb57b6e/After/tests#xml2#XMLBearTest.py"
        },
        "variable_name": "path",
        "label": "positive",
        "id": "806aeaf8-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 700
    },
    {
        "commit_hash": "0271d384741c32b3fe53bc7bce7b155059a55704",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def draw(self, **kwargs):\n        \"\"\"\n        Called from the fit method, this method creates the canvas and\n        draws the distribution plot on it.\n\n        Parameters\n        ----------\n        kwargs: generic keyword arguments.\n\n        \"\"\"\n        # Plot the top 50 most frequent words\n        y_pos = np.arange(self.N)\n        self.ax.bar(y_pos, self.counts[:self.N], align='center', alpha=0.5)\n\n        # Set the tick marks\n        self.ax.set_xticks(y_pos)",
            "file_path": "commits/0271d384741c32b3fe53bc7bce7b155059a55704/Before/yellowbrick#text#freqdist.py"
        },
        "refactored_code": {
            "source_code": "def draw(self, **kwargs):\n        \"\"\"\n        Called from the fit method, this method creates the canvas and\n        draws the distribution plot on it.\n\n        Parameters\n        ----------\n        kwargs: generic keyword arguments.\n\n        \"\"\"\n        # Prepare the data\n        bins  = np.arange(self.N)\n        words = [self.features[i] for i in self.sorted_[:self.N]]\n        freqs = {}\n\n        # Set up the bar plots\n        if self.conditional_freqdist_:\n            for label, values in sorted(self.conditional_freqdist_.items(), key=itemgetter(0)):\n                freqs[label] = [\n                    values[i] for i in self.sorted_[:self.N]\n                ]\n        else:\n            freqs['corpus'] = [\n                self.freqdist_[i] for i in self.sorted_[:self.N]\n            ]\n\n        # Draw a horizontal barplot\n        if self.orient == 'h':\n            # Add the barchart, stacking if necessary\n            for label, freq in freqs.items():\n                self.ax.barh(bins, freq, label=label, align='center')\n\n            # Set the y ticks to the words\n            self.ax.set_yticks(bins)\n            self.ax.set_yticklabels(words)\n\n            # Order the features from top to bottom on the y axis\n            self.ax.invert_yaxis()\n\n            # Turn off y grid lines and turn on x grid lines\n            self.ax.yaxis.grid(False)\n            self.ax.xaxis.grid(True)\n\n        # Draw a vertical barplot\n        elif self.orient == 'v':\n            # Add the barchart, stacking if necessary\n            for label, freq in freqs.items():\n                self.ax.bar(bins, freq, label=label, align='edge')\n\n            # Set the y ticks to the words\n            self.ax.set_xticks(bins)\n            self.ax.set_xticklabels(words, rotation=90)\n\n            # Turn off x grid lines and turn on y grid lines\n            self.ax.yaxis.grid(True)\n            self.ax.xaxis.grid(False)\n\n        # Unknown state\n        else:\n            raise YellowbrickValueError(\n                \"Orientation must be 'h' or 'v'\"\n            )",
            "file_path": "commits/0271d384741c32b3fe53bc7bce7b155059a55704/After/yellowbrick#text#freqdist.py"
        },
        "original_variable_name": "y_pos",
        "new_variable_name": "bins",
        "label": "negative",
        "id": "8067934e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2954
    },
    {
        "commit_hash": "04827eee84c7d5707d8c33b3013b7391acf8ab9c",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def load_yolo_v3(file, model):\n    for i, link in enumerate(model.extractor):\n        load_link(file, link)\n        if i in {33, 39, 45}:\n            subnet = model.subnet[(i - 33) // 6]\n            load_link(file, subnet)\n\n    # xy -> yx\n    for subnet in model.subnet:\n        final = subnet[-1]\n        for data in (final.W.array, final.b.array):\n            data = data.reshape(\n                (-1, 4 + 1 + model.n_fg_class) + data.shape[1:])\n            data[:, [1, 0, 3, 2]] = data[:, :4].copy()",
            "file_path": "commits/04827eee84c7d5707d8c33b3013b7391acf8ab9c/Before/examples#yolo#darknet2npz.py"
        },
        "refactored_code": {
            "source_code": "def load_yolo_v3(file, model):\n    for i, link in enumerate(model.extractor):\n        load_link(file, link)\n        if i in {33, 39, 45}:\n            subnet = model.subnet[(i - 33) // 6]\n            load_link(file, subnet)\n\n    for subnet in model.subnet:\n        reorder_loc(subnet[-1], model.n_fg_class)",
            "file_path": "commits/04827eee84c7d5707d8c33b3013b7391acf8ab9c/After/examples#yolo#darknet2npz.py"
        },
        "variable_name": "final",
        "label": "positive",
        "id": "806ae99a-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 1171
    },
    {
        "commit_hash": "f8e0ecb710fdcb8bf0e657a962a4e11e4c7c7365",
        "refactoring_type": "Inline Variable",
        "original_code": {
            "source_code": "def period_index(request):\n    \"\"\"\n    A fixture to provide PeriodIndex objects with different frequencies.\n\n    Most PeriodArray behavior is already tested in PeriodIndex tests,\n    so here we just test that the PeriodArray behavior matches\n    the PeriodIndex behavior.\n    \"\"\"\n    freqstr = request.param\n    # TODO: non-monotone indexes; NaTs, different start dates\n    pi = pd.period_range(start=pd.Timestamp(\"2000-01-01\"), periods=100, freq=freqstr)\n    return pi",
            "file_path": "commits/f8e0ecb710fdcb8bf0e657a962a4e11e4c7c7365/Before/pandas#tests#arrays#test_datetimelike.py"
        },
        "refactored_code": {
            "source_code": "def freqstr(request):\n    return request.param",
            "file_path": "commits/f8e0ecb710fdcb8bf0e657a962a4e11e4c7c7365/After/pandas#tests#arrays#test_datetimelike.py"
        },
        "variable_name": "freqstr",
        "label": "positive",
        "id": "806ae97c-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 896
    },
    {
        "commit_hash": "1b9217971cd6e907f35ba0eff0a4c17c34bda160",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "__init__",
            "container_name": "main",
            "source_code": "def __init__(self):\n        parser = argparse.ArgumentParser(\n            description='Python package for streaming, recording, and visualizing EEG data from the Muse 2016 headset.',\n            usage='''muselsl <command> [<args>]\n    Available commands:\n    list        List available Muse devices.\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n\n    stream      Start an LSL stream from Muse headset.\n                -a --address    Device MAC address.\n                -n --name       Device name (e.g. Muse-41D2).\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n\n    view     Visualize EEG data from an LSL stream.\n                -w --window     Window length to display in seconds.\n                -s --scale      Scale in uV.\n                -r --refresh    Refresh rate in seconds.\n                -f --figure     Window size.\n                -v --version    Viewer version (1 or 2) - 1 is the default stable version, 2 is in development (and takes no arguments).\n\n    record   Record EEG data from an LSL stream.\n                -d --duration   Duration of the recording in seconds.\n                -f --filename   Name of the recording file.\n                -dj --dejitter  Whether to apply dejitter correction to timestamps.\n\n    record_direct      Record data directly from Muse headset (no LSL).\n                -a --address    Device MAC address.\n                -n --name       Device name (e.g. Muse-41D2).\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n        ''')\n\n        parser.add_argument('command', help='Command to run.')\n\n        # parse_args defaults to [1:] for args, but you need to\n        # exclude the rest of the args too, or validation will fail\n        args = parser.parse_args(sys.argv[1:2])\n        if not hasattr(self, args.command):\n            print('Incorrect usage. See help below.')\n            parser.print_help()\n            exit(1)\n\n        # use dispatch pattern to invoke method with same name\n        getattr(self, args.command)()"
        },
        "original_method_after_refactoring": {
            "name": "__init__",
            "container_name": "CLI",
            "source_code": "def __init__(self, command):\n        # use dispatch pattern to invoke method with same name\n        getattr(self, command)()"
        },
        "newly_extracted_method": {
            "name": "main",
            "container_name": "__main__",
            "source_code": "def main():\n    parser = argparse.ArgumentParser(\n        description='Python package for streaming, recording, and visualizing EEG data from the Muse 2016 headset.',\n        usage='''muselsl <command> [<args>]\n    Available commands:\n    list        List available Muse devices.\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n\n    stream      Start an LSL stream from Muse headset.\n                -a --address    Device MAC address.\n                -n --name       Device name (e.g. Muse-41D2).\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n\n    view     Visualize EEG data from an LSL stream.\n                -w --window     Window length to display in seconds.\n                -s --scale      Scale in uV.\n                -r --refresh    Refresh rate in seconds.\n                -f --figure     Window size.\n                -v --version    Viewer version (1 or 2) - 1 is the default stable version, 2 is in development (and takes no arguments).\n\n    record   Record EEG data from an LSL stream.\n                -d --duration   Duration of the recording in seconds.\n                -f --filename   Name of the recording file.\n                -dj --dejitter  Whether to apply dejitter correction to timestamps.\n\n    record_direct      Record data directly from Muse headset (no LSL).\n                -a --address    Device MAC address.\n                -n --name       Device name (e.g. Muse-41D2).\n                -b --backend    BLE backend to use. can be auto, bluemuse, gatt or bgapi.\n                -i --interface  The interface to use, 'hci0' for gatt or a com port for bgapi.\n        ''')\n\n    parser.add_argument('command', help='Command to run.')\n\n    # parse_args defaults to [1:] for args, but you need to\n    # exclude the rest of the args too, or validation will fail\n    args = parser.parse_args(sys.argv[1:2])\n\n    if not hasattr(CLI, args.command):\n            print('Incorrect usage. See help below.')\n            parser.print_help()\n            exit(1)\n\n    cli = CLI(args.command)"
        },
        "label": "positive",
        "id": "805be2ec-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 5177
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            if not (has_arg(tf.Session.run, key, True) or has_arg(Function.__init__, key, True)):\n                msg = 'Invalid argument \"%s\" passed to K.function with TensorFlow backend' % key\n                raise ValueError(msg)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def function(inputs, outputs, updates=None, **kwargs):\n    \"\"\"Instantiates a Keras function.\n\n    # Arguments\n        inputs: List of placeholder tensors.\n        outputs: List of output tensors.\n        updates: List of update ops.\n        **kwargs: Passed to `tf.Session.run`.\n\n    # Returns\n        Output values as Numpy arrays.\n\n    # Raises\n        ValueError: if invalid kwargs are passed in.\n    \"\"\"\n    if kwargs:\n        for key in kwargs:\n            session_has_key = has_arg(tf.Session.run, key, True)\n            function_has_key = has_arg(Function.__init__, key, True)\n            if not (session_has_key or function_has_key):\n                raise ValueError('Invalid argument \"%s\" passed to K.function '\n                                 'with TensorFlow backend' % key)\n    return Function(inputs, outputs, updates=updates, **kwargs)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "session_has_key",
        "label": "positive",
        "id": "8069bbf6-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2012
    },
    {
        "commit_hash": "9f12ca095ab6e3295bd03fd1e50130a12b11569c",
        "refactoring_type": "Inline Method",
        "caller_before": {
            "name": "append",
            "container_name": "HookResultStore",
            "source_code": "def append(self, result, dataloader_idx: Optional[int] = None, extra_info: Optional[dict] = None) -> None:\n        if not isinstance(result, Result):\n            raise TypeError(f'{result} must be Result')\n\n        if dataloader_idx is None:\n            dataloader_idx = 0\n\n        if extra_info is None:\n            extra_info = {}\n\n        # [dataloader_idx][optimizer_idx][training_step_idx] is a list\n        if len(extra_info) > 0:\n            self._internal_type = ResultStoreType.INSIDE_BATCH_TRAIN_LOOP\n            # initialize dictionary\n            if dataloader_idx not in self._internals:\n                self._internals[dataloader_idx] = {}\n                self._internals_reduced[dataloader_idx] = defaultdict(dict)\n                self._latest_ref[dataloader_idx] = {}\n\n            # extract infos\n            opt_idx = extra_info[\"opt_idx\"]\n            batch_idx = extra_info[\"batch_idx\"]\n\n            self._append_to_structure(self._internals[dataloader_idx], opt_idx, batch_idx, result)\n\n            self._latest_ref[dataloader_idx][opt_idx] = result\n\n        # [dataloader_idx] is a list\n        else:\n            self._internal_type = ResultStoreType.OUTSIDE_BATCH_TRAIN_LOOP\n            self._internals.setdefault(dataloader_idx, [])\n            self._internals[dataloader_idx].append(result)\n\n            if dataloader_idx not in self._latest_ref:\n                self._latest_ref[dataloader_idx] = {}\n                self._latest_ref[dataloader_idx][0] = {}\n\n            self._latest_ref[dataloader_idx][0] = result",
            "file_path": "commits/9f12ca095ab6e3295bd03fd1e50130a12b11569c/Before/pytorch_lightning#trainer#connectors#logger_connector#epoch_result_store.py"
        },
        "inlined_method": {
            "name": "_append_to_structure",
            "container_name": "HookResultStore",
            "source_code": "def _append_to_structure(primary_dict, opt_idx, batch_idx, result) -> None:\n        primary_dict.setdefault(opt_idx, {})\n        primary_dict[opt_idx].setdefault(batch_idx, [])\n        primary_dict[opt_idx][batch_idx].append(result)",
            "file_path": "commits/9f12ca095ab6e3295bd03fd1e50130a12b11569c/Before/pytorch_lightning#trainer#connectors#logger_connector#epoch_result_store.py"
        },
        "caller": {
            "name": "append",
            "container_name": "HookResultStore",
            "source_code": "def append(self, result: Result, info: Dict) -> None:\n        dataloader_idx = info[\"dataloader_idx\"]\n        self._internal_type = info[\"type\"]\n        opt_idx = info[\"opt_idx\"]\n\n        if self._internal_type == ResultStoreType.INSIDE_BATCH_TRAIN_LOOP:\n            if dataloader_idx not in self._internals:\n                self._internals_reduced[dataloader_idx] = defaultdict(dict)\n                self._latest_ref[dataloader_idx] = {}\n            self._internals.setdefault(dataloader_idx, {})\n\n            batch_idx = info[\"batch_idx\"]\n            self._internals[dataloader_idx].setdefault(opt_idx, {})\n            self._internals[dataloader_idx][opt_idx].setdefault(batch_idx, [])\n            self._internals[dataloader_idx][opt_idx][batch_idx].append(result)\n        else:\n            self._internals.setdefault(dataloader_idx, [])\n            self._internals[dataloader_idx].append(result)\n            self._latest_ref.setdefault(dataloader_idx, {})\n\n        self._latest_ref[dataloader_idx].setdefault(opt_idx, {})\n        self._latest_ref[dataloader_idx][opt_idx] = result",
            "file_path": "commits/9f12ca095ab6e3295bd03fd1e50130a12b11569c/After/pytorch_lightning#trainer#connectors#logger_connector#epoch_result_store.py"
        },
        "label": "positive",
        "id": "805ed93e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3691
    },
    {
        "commit_hash": "4a744f5768490d9cfd45c33a011476a509f6810c",
        "refactoring_type": "Rename Variable",
        "original_code": {
            "source_code": "def _process_dataset(self, dataset):\n        dataset_hparams = self._hparams.dataset\n\n        # Create data decoder\n        decoder = TextDataDecoder(\n            delimiter=dataset_hparams[\"delimiter\"],\n            bos_token=dataset_hparams[\"bos_token\"],\n            eos_token=dataset_hparams[\"eos_token\"],\n            max_seq_length=dataset_hparams[\"max_seq_length\"],\n            token_to_id_map=self._vocab.token_to_id_map)\n\n        # Process data\n        num_parallel_calls = self._hparams.num_parallel_calls\n        dataset = dataset.map(\n            decoder, num_parallel_calls=num_parallel_calls)\n\n        other_trans = dataset_hparams[\"other_transformations\"]\n        if len(other_trans) > 0:\n            for tran in other_trans:\n                tran_fn = utils.get_function(tran, [\"texar.custom\"])\n                other_trans.append(tran_fn)\n                dataset = dataset.map(\n                    lambda x: other_trans[-1](x, self),\n                    num_parallel_calls=num_parallel_calls)\n\n        return dataset, decoder",
            "file_path": "commits/4a744f5768490d9cfd45c33a011476a509f6810c/Before/texar#data#data#mono_text_data.py"
        },
        "refactored_code": {
            "source_code": "def _process_dataset(self, dataset):\n        dataset_hparams = self._hparams.dataset\n\n        # Create data decoder\n        decoder = TextDataDecoder(\n            delimiter=dataset_hparams[\"delimiter\"],\n            bos_token=dataset_hparams[\"bos_token\"],\n            eos_token=dataset_hparams[\"eos_token\"],\n            max_seq_length=dataset_hparams[\"max_seq_length\"],\n            token_to_id_map=self._vocab.token_to_id_map)\n\n        # Process data\n        num_parallel_calls = self._hparams.num_parallel_calls\n        dataset = dataset.map(\n            decoder, num_parallel_calls=num_parallel_calls)\n\n        return dataset, decoder",
            "file_path": "commits/4a744f5768490d9cfd45c33a011476a509f6810c/After/texar#data#data#mono_text_data.py"
        },
        "original_variable_name": "tran_fn",
        "new_variable_name": "tran",
        "label": "positive",
        "id": "80679a38-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2071
    },
    {
        "commit_hash": "1073d248e60808a94fbe6c24fb717528529360af",
        "refactoring_type": "Extract Method",
        "original_method_before_refactoring": {
            "name": "gc",
            "container_name": "gcloud",
            "source_code": "def gc(job_id, project_id, service_account_json, bucket_name, config, dataset):\n    args = []\n\n    if not job_id:\n        job_id = 'train_{}'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n\n    # Define path in bucket to store job's config, logs, etc.\n    base_path = 'lumi_{}'.format(job_id)\n\n    # Check if absolute or relative dataset path\n    if not dataset.startswith('gs://'):\n        dataset = 'gs://{}'.format(dataset)\n\n    args.extend([\n        '--log-dir', 'gs://{}/{}/logs'.format(bucket_name, base_path),\n        '--model-dir', 'gs://{}/{}/model'.format(bucket_name, base_path),\n        '--override', 'dataset.dir={}'.format(dataset)\n    ])\n\n    # Creates bucket for logs and models if it doesn't exist\n    bucket = get_bucket(service_account_json, bucket_name)\n\n    if config:\n        # Upload config file to be used by the training job.\n        path = upload_file(bucket, base_path, config)\n        args.extend(['--config', 'gs://{}/{}'.format(bucket_name, path)])\n\n    credentials = service_account.Credentials.from_service_account_file(\n        service_account_json)\n    cloudml = discovery.build('ml', 'v1', credentials=credentials)\n\n    training_inputs = {\n        'scaleTier': 'BASIC_GPU',\n        'packageUris': ['gs://luminoth-config/luminoth-0.0.1-py2-none-any.whl'],\n        'pythonModule': 'luminoth.train',\n        'args': args,\n        'region': 'us-central1',\n        'jobDir': 'gs://{}/{}/train/'.format(bucket_name, base_path),\n        'runtimeVersion': '1.2'\n    }\n\n    job_spec = {\n        'jobId': job_id,\n        'trainingInput': training_inputs\n    }\n\n    request = cloudml.projects().jobs().create(\n        body=job_spec, parent='projects/{}'.format(project_id))\n\n    try:\n        click.echo('Submitting training job.')\n        request.execute()\n        click.echo('Job {} submitted successfully.'.format(job_id))\n    except Exception as err:\n        click.echo(\n            'There was an error creating the training job. '\n            'Check the details: \\n{}'.format(err._get_reason())\n        )"
        },
        "original_method_after_refactoring": {
            "name": "gc",
            "container_name": "gcloud",
            "source_code": "def gc():\n    pass"
        },
        "newly_extracted_method": {
            "name": "cloud_service",
            "container_name": "Unknown",
            "source_code": "def cloud_service(credentials, service, version='v1'):\n    return discovery.build(service, version, credentials=credentials)"
        },
        "label": "positive",
        "id": "805bff52-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 2599
    },
    {
        "commit_hash": "48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def __call__(self, inputs):\n        if hasattr(get_session(), '_make_callable_from_options'):\n            if py_any(is_sparse(x) for x in self.inputs):\n                if py_any(is_tensor(x) for x in inputs):\n                    raise ValueError(\n                        'Feeding from symbolic tensors is not '\n                        'supported with sparse inputs.')\n                return self._legacy_call(inputs)\n\n            # callable generated by Session._make_callable_from_options accepts\n            # `run_metadata` keyword argument since TF 1.10\n            if (self.run_metadata and\n                    StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.10.0')):\n                if py_any(is_tensor(x) for x in inputs):\n                    raise ValueError(\n                        'In order to feed symbolic tensors to a Keras model and set '\n                        '`run_metadata`, you need tensorflow 1.10 or higher.')\n                return self._legacy_call(inputs)\n\n            return self._call(inputs)\n        else:\n            if py_any(is_tensor(x) for x in inputs):\n                raise ValueError(\n                    'In order to feed symbolic tensors to a Keras model '\n                    'in TensorFlow, you need tensorflow 1.8 or higher.')\n            return self._legacy_call(inputs)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/Before/keras#backend#tensorflow_backend.py"
        },
        "refactored_code": {
            "source_code": "def __call__(self, inputs):\n        if hasattr(get_session(), '_make_callable_from_options'):\n            if py_any(is_sparse(x) for x in self.inputs):\n                if py_any(is_tensor(x) for x in inputs):\n                    raise ValueError(\n                        'Feeding from symbolic tensors is not '\n                        'supported with sparse inputs.')\n                return self._legacy_call(inputs)\n\n            # callable generated by Session._make_callable_from_options accepts\n            # `run_metadata` keyword argument since TF 1.10\n            if self.run_metadata:\n                current_version = StrictVersion(tf.__version__.split('-')[0])\n                if current_version < StrictVersion('1.10.0'):\n                    if py_any(is_tensor(x) for x in inputs):\n                        raise ValueError(\n                            'In order to feed symbolic tensors '\n                            'to a Keras model and set '\n                            '`run_metadata`, you need tensorflow 1.10 or higher.')\n                    return self._legacy_call(inputs)\n\n            return self._call(inputs)\n        else:\n            if py_any(is_tensor(x) for x in inputs):\n                raise ValueError(\n                    'In order to feed symbolic tensors to a Keras model '\n                    'in TensorFlow, you need tensorflow 1.8 or higher.')\n            return self._legacy_call(inputs)",
            "file_path": "commits/48c1c96ac4cfec5580a5feb7eb7ef7c25c6db234/After/keras#backend#tensorflow_backend.py"
        },
        "variable_name": "current_version",
        "label": "positive",
        "id": "8069bc28-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3171
    },
    {
        "commit_hash": "445387698dad8bcdccb53b7708aba564c1a5c319",
        "refactoring_type": "Extract Variable",
        "original_code": {
            "source_code": "def get_variant_spec(universe, domain, task, policy):\n    variant_spec = {\n        'domain': domain,\n        'task': task,\n        'universe': universe,\n        'git_sha': get_git_rev(),\n\n        'env_params': ENV_PARAMS.get(domain, {}).get(task, {}),\n        'policy_params': deep_update(\n            POLICY_PARAMS_BASE[policy],\n            POLICY_PARAMS_FOR_DOMAIN[policy].get(domain, {})\n        ),\n        'Q_params': {\n            'type': 'double_feedforward_Q_function',\n            'kwargs': {\n                'hidden_layer_sizes': (M, M),\n            }\n        },\n        'algorithm_params': deep_update(\n            ALGORITHM_PARAMS_BASE,\n            ALGORITHM_PARAMS_PER_DOMAIN.get(domain, {})\n        ),\n        'replay_pool_params': {\n            'type': 'SimpleReplayPool',\n            'kwargs': {\n                'max_size': 1e6,\n            }\n        },\n        'sampler_params': {\n            'type': 'SimpleSampler',\n            'kwargs': {\n                'max_path_length': MAX_PATH_LENGTH_PER_DOMAIN.get(\n                    domain, DEFAULT_MAX_PATH_LENGTH),\n                'min_pool_size': MAX_PATH_LENGTH_PER_DOMAIN.get(\n                    domain, DEFAULT_MAX_PATH_LENGTH),\n                'batch_size': 256,\n            }\n        },\n        'run_params': {\n            'seed': tune.sample_from(\n                lambda spec: np.random.randint(0, 10000)),\n            'checkpoint_at_end': True,\n            'checkpoint_frequency': NUM_EPOCHS_PER_DOMAIN.get(\n                domain, DEFAULT_NUM_EPOCHS) // NUM_CHECKPOINTS,\n            'checkpoint_replay_pool': False,\n        },\n    }\n\n    return variant_spec",
            "file_path": "commits/445387698dad8bcdccb53b7708aba564c1a5c319/Before/examples#development#variants.py"
        },
        "refactored_code": {
            "source_code": "def get_variant_spec(universe, domain, task, policy, algorithm):\n    algorithm_params = deep_update(\n        ALGORITHM_PARAMS_BASE,\n        ALGORITHM_PARAMS_PER_DOMAIN.get(domain, {})\n    )\n    algorithm_params = deep_update(\n        algorithm_params,\n        ALGORITHM_PARAMS_ADDITIONAL.get(algorithm, {})\n    )\n    variant_spec = {\n        'domain': domain,\n        'task': task,\n        'universe': universe,\n        'git_sha': get_git_rev(),\n\n        'env_params': ENV_PARAMS.get(domain, {}).get(task, {}),\n        'policy_params': deep_update(\n            POLICY_PARAMS_BASE[policy],\n            POLICY_PARAMS_FOR_DOMAIN[policy].get(domain, {})\n        ),\n        'Q_params': {\n            'type': 'double_feedforward_Q_function',\n            'kwargs': {\n                'hidden_layer_sizes': (M, M),\n            }\n        },\n        'algorithm_params': algorithm_params,\n        'replay_pool_params': {\n            'type': 'SimpleReplayPool',\n            'kwargs': {\n                'max_size': 1e6,\n            }\n        },\n        'sampler_params': {\n            'type': 'SimpleSampler',\n            'kwargs': {\n                'max_path_length': MAX_PATH_LENGTH_PER_DOMAIN.get(\n                    domain, DEFAULT_MAX_PATH_LENGTH),\n                'min_pool_size': MAX_PATH_LENGTH_PER_DOMAIN.get(\n                    domain, DEFAULT_MAX_PATH_LENGTH),\n                'batch_size': 256,\n            }\n        },\n        'run_params': {\n            'seed': tune.sample_from(\n                lambda spec: np.random.randint(0, 10000)),\n            'checkpoint_at_end': True,\n            'checkpoint_frequency': NUM_EPOCHS_PER_DOMAIN.get(\n                domain, DEFAULT_NUM_EPOCHS) // NUM_CHECKPOINTS,\n            'checkpoint_replay_pool': False,\n        },\n    }\n\n    return variant_spec",
            "file_path": "commits/445387698dad8bcdccb53b7708aba564c1a5c319/After/examples#development#variants.py"
        },
        "variable_name": "algorithm_params",
        "label": "positive",
        "id": "8069b80e-a8b9-11f0-b5a3-72eebd022d08",
        "total_letters": 3888
    }
]